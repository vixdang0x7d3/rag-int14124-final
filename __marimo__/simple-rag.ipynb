{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# What we're going to build?\n",
    "\n",
    "A simple RAG pipeline that's able to process a PDF document - [nutrition-textbook](https://pressbooks.oer.hawaii.edu/humannutrition2/),\n",
    "\n",
    "We'll write the code to:\n",
    "\n",
    "1. Open a PDF document & extract the text.\n",
    "2. Format the text into appropriate chunks for feeeding them into an embedding model.\n",
    "3. Embed the text aka. turn them into numerical representation which we can store for later use.\n",
    "4. Build a **retrieval system** that finds relevant chunks of text based on a query\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "6. Generate an answer to the query based on texts from the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if \"COLAB_GPU\" in os.environ:\n",
    "#     print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
    "#     !pip install torch==2.6.0 # requires torch 2.1.1+ (for efficient sdpa implementation)\n",
    "#     !pip install PyMuPDF # for reading PDFs with Python\n",
    "#     !pip install tqdm # for progress bars\n",
    "#     !pip install sentence-transformers # for embedding models\n",
    "#     !pip install accelerate # for quantization model loading\n",
    "#     !pip install bitsandbytes # for quantizing models (less storage space)\n",
    "#     !pip install flash-attn --no-build-isolation # for faster attention mechanism = faster LLM inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Document/Text Processing and Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pdf_path = Path(os.getcwd()) / \"data\" / \"human-nutrition-text.pdf\"\n",
    "\n",
    "if not pdf_path.parent.exists():\n",
    "    print(f\"Creating directory {pdf_path.parent}\")\n",
    "    pdf_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not pdf_path.exists():\n",
    "    print(\"File not found, downloading...\")\n",
    "\n",
    "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "\n",
    "    filename = pdf_path.name\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        pdf_path.write_bytes(response.content)\n",
    "        print(f\"Downloaded {filename} to {pdf_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"File already exists at {pdf_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def extract_text(pdf_path: Path) -> list[dict]:\n",
    "    with pymupdf.open(pdf_path) as doc:\n",
    "        text_data = []\n",
    "\n",
    "        for pageno, page in tqdm(enumerate(doc), desc=\"Extracting text\", total=len(doc)):\n",
    "            text = page.get_text(\"text\")\n",
    "            text = clean_text(text)\n",
    "\n",
    "            # Content start after page 42\n",
    "            # 1 token = 4 characters\n",
    "            text_data.append({\n",
    "                \"page_number\": pageno - 42,\n",
    "                \"page_char_count\" : len(text),\n",
    "                \"page_word_count\" : len(text.split()),\n",
    "                \"page_sentence_count_raw\" : len(text.split(\".\")),\n",
    "                \"page_token_count\" : len(text) / 4,\n",
    "                \"text\": text\n",
    "            })\n",
    "\n",
    "        return text_data\n",
    "\n",
    "text_data = extract_text(pdf_path)\n",
    "text_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "pprint(\n",
    "    random.sample(text_data, k=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Get some stat on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(text_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Splitting pages into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "doc = nlp(\"This is a sentence. This is anothere sentence\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Perform transformation on our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(text_data):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    item[\"sentences\"] = [str(sent) for sent in item[\"sentences\"]]\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(text_data, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(text_data)\n",
    "df_1.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Create chunks from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_per_chunk = 10\n",
    "\n",
    "def split_list(input_list: list[str], chunk_size: int) -> list[list[str]]:\n",
    "    \"\"\"Split list of sentences into chunk lenght sub-lists\"\"\"\n",
    "    return [input_list[i:i + chunk_size] for i in range(0, len(input_list), chunk_size)]\n",
    "for item_1 in tqdm(text_data):\n",
    "    item_1['chunks'] = split_list(item_1['sentences'], chunk_size=sent_per_chunk)\n",
    "    item_1['num_chunks'] = len(item_1['chunks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(text_data, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(text_data)\n",
    "df_2.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Merging chunks from list to a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chunk_data = []\n",
    "for item_2 in tqdm(text_data):\n",
    "    for chunk in item_2['chunks']:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict['page_number'] = item_2['page_number']\n",
    "        merged_chunk = ''.join(chunk).replace('  ', ' ').strip()\n",
    "        merged_chunk = re.sub('\\\\.([A-Z])', '. \\\\1', merged_chunk)\n",
    "        chunk_dict['chunk'] = merged_chunk\n",
    "        chunk_dict['chunk_char_count'] = len(merged_chunk)\n",
    "        chunk_dict['chunk_word_count'] = len([word for word in merged_chunk.split(' ')])\n",
    "        chunk_dict['chunk_token_count'] = len(merged_chunk) / 4\n",
    "        chunk_data.append(chunk_dict)\n",
    "len(chunk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(chunk_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame(chunk_data)\n",
    "df_3.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBYS",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Some of the chunks have quite low token count. We will filter out samples with less than 30 tokens and see if they are worth keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_token_length = 30\n",
    "for row in df_3[df_3['chunk_token_count'] <= min_token_length].sample(5).iterrows():\n",
    "    print(f\"Token count: {row[1]['chunk_token_count']}\\nText: {row[1]['chunk']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfw",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Many of these are page headers and footers, they don't seem to offer much information. \\\n",
    "We can remove them and keep only chunk dicts with over 30 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data_1 = df_3[df_3['chunk_token_count'] > min_token_length].to_dict(orient='records')\n",
    "pprint(chunk_data_1[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AjVT",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Embedding text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pHFh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# TODO(vi): Research SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    model_name_or_path=\"all-mpnet-base-v2\",\n",
    ")\n",
    "\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "embedding_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "for sent, emb, in embedding_dict.items():\n",
    "    print(f\"Sentence: {sent}\\n\")\n",
    "    print(f\"Embedding: {emb}\\n\")\n",
    "    print(\"-----------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NCOB",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Using a GPU can significantly speed up this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aqbW",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using CUDA? {'YES' if device=='cuda' else 'NO'}\")\n",
    "if device:\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TRpd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.to(device)\n",
    "_ = embedding_model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXez",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = [item['chunk'] for item in chunk_data_1]\n",
    "embeddings_1 = embedding_model.encode(text_chunks, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dNNg",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk_1, emb_1 in zip(chunk_data_1, embeddings_1):\n",
    "    chunk_1['embedding'] = emb_1\n",
    "chunk_data_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yCnT",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embedding_df = pd.DataFrame(chunk_data_1)\n",
    "save_path = 'chunk_embedding_df.parquet'\n",
    "chunk_embedding_df.to_parquet(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wlCL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Try loading them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kqZH",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embedding_df_1 = pd.read_parquet(save_path)\n",
    "chunk_embedding_df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wAgl",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Storing as CSV requires objects get serialized into strings so we used parquet format instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rEll",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embedding_df_1.loc[0, 'embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dGlV",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Retrieval\n",
    "\n",
    "At the moment, we have our document index ready in the form of a simple dataframe. \\\n",
    "In this stage, we'll convert our embedding into tensor for GPU accelerated computation and define a similarity search function that can retrieve $k$ relevant text passages based on a user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SdmI",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "device_1 = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "embeddings_2 = torch.tensor(np.array(chunk_embedding_df_1['embedding'].tolist()), dtype=torch.float32).to(device_1)\n",
    "embeddings_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lgWD",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yOPj",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_1 = SentenceTransformer(model_name_or_path='all-mpnet-base-v2', device=device_1)\n",
    "\n",
    "embedding_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fwwy",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'macronutrients functions'\n",
    "query_embedding = embedding_model_1.encode(query, convert_to_tensor=True)\n",
    "from time import perf_counter as timer\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, embeddings_2)[0]\n",
    "end_time = timer()\n",
    "print(f'Query: {query}')\n",
    "print(f'Time taken to get scores on {len(embeddings_2)} embeddings: {end_time - start_time:.5f} seconds.')\n",
    "top_5 = torch.topk(dot_scores, k=5)\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LJZf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urSm",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Query: '{query}'\")\n",
    "print('Result:')\n",
    "for score, idx in zip(top_5[0], top_5[1]):\n",
    "    print(f'Score: {score:.4f}')\n",
    "    print('Text: ')\n",
    "    print_wrapped(chunk_data_1[idx]['chunk'])\n",
    "    print(f\"Page No. : {chunk_data_1[idx]['page_number']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jxvo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Define similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mWxS",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vec_1, vec_2):\n",
    "    return torch.dot(vec_1, vec_2)\n",
    "\n",
    "\n",
    "def cosine_similarity(vec_1, vec_2):\n",
    "    dot_product = torch.dot(vec_1, vec_2)\n",
    "\n",
    "    norm_vec_1 = torch.sqrt(torch.sum(vec_1 ** 2))\n",
    "    norm_vec_2 = torch.sqrt(torch.sum(vec_2 ** 2))\n",
    "\n",
    "    return dot_product / (norm_vec_1 * norm_vec_2)\n",
    "\n",
    "\n",
    "# Example tensors\n",
    "vector1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "vector2 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "vector3 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "vector4 = torch.tensor([-1, -2, -3], dtype=torch.float32)\n",
    "\n",
    "# Calculate dot product\n",
    "print(\"Dot product between vector1 and vector2:\", dot_product(vector1, vector2))\n",
    "print(\"Dot product between vector1 and vector3:\", dot_product(vector1, vector3))\n",
    "print(\"Dot product between vector1 and vector4:\", dot_product(vector1, vector4))\n",
    "\n",
    "# Calculate cosine similarity\n",
    "print(\n",
    "    \"Cosine similarity between vector1 and vector2:\",\n",
    "    cosine_similarity(vector1, vector2),\n",
    ")\n",
    "print(\n",
    "    \"Cosine similarity between vector1 and vector3:\",\n",
    "    cosine_similarity(vector1, vector3),\n",
    ")\n",
    "print(\n",
    "    \"Cosine similarity between vector1 and vector4:\",\n",
    "    cosine_similarity(vector1, vector4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CcZR",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Functionizing the semantic search pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YWSi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(\n",
    "    query: str, emdeddings: torch.tensor, \n",
    "    model: SentenceTransformer, \n",
    "    topk: int=5\n",
    "):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings_2)[0]\n",
    "    scores, indices = torch.topk(dot_scores, k=topk)\n",
    "    return (scores, indices)\n",
    "\n",
    "def print_topk(\n",
    "    query: str, \n",
    "    embeddings: torch.tensor, \n",
    "    document_index: list[dict], \n",
    "    model: SentenceTransformer, \n",
    "    topk: int=5\n",
    "):\n",
    "    scores, indices = retrieve_chunks(query, embeddings, model)\n",
    "    print(f'Query: {query}')\n",
    "    print('Result: ')\n",
    "    for score, idx in zip(scores, indices):\n",
    "        print(f'Score: {score:.4f}')\n",
    "        print_wrapped(document_index[idx]['chunk'])\n",
    "        print(f\"Page No. : {document_index[idx]['page_number']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zlud",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = 'symtomps of pellagra'\n",
    "scores, indices = retrieve_chunks(query_1, embeddings_2, embedding_model_1)\n",
    "(scores, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tZnO",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embedding_data = chunk_embedding_df_1.to_dict(orient='records')\n",
    "print_topk(query_1, embeddings_2, chunk_embedding_data, embedding_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xvXZ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Prepare LLM for local generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CLip",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"COLAB_GPU\" in os.environ:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YECM",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_mem_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_mem_gb = round(gpu_mem_bytes / (2 ** 30))\n",
    "\n",
    "print(f'Available GPU Memory: {gpu_mem_gb} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cEAS",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_mem_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_mem_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_mem_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_mem_gb} GB | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True\n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_mem_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_mem_gb} GB | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False\n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_mem_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_mem_gb} GB | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False\n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iXej",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "if is_flash_attn_2_available() and torch.cuda.get_device_capability(0)[0] > 8:\n",
    "    attn_implementation = 'flash_attention_2'\n",
    "else:\n",
    "    attn_implementation = 'sdpa'\n",
    "print(f'[INFO] Using attention implementation: {attn_implementation}')\n",
    "model_id_1 = model_id\n",
    "print(f'[INFO] Using model id: {model_id_1}')\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id_1)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id_1, torch_dtype=torch.float16, quantization_config=quantization_config if use_quantization_config else None, low_cpu_mem_usage=False, attn_implementation=attn_implementation)\n",
    "if not use_quantization_config:\n",
    "    llm_model.to(device_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EJmg",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UmEG",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_nparam(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "\n",
    "def get_model_memsize(model: torch.nn.Module):\n",
    "    \"\"\"Get how much memory a model takes up\"\"\"\n",
    "\n",
    "    mem_params = sum(\n",
    "        [param.nelement() * param.element_size() for param in model.parameters()]\n",
    "    )\n",
    "    mem_buffers = sum(\n",
    "        [buf.nelement() * buf.element_size() for buf in model.buffers()]\n",
    "    )\n",
    "\n",
    "    model_mem_bytes = mem_params + mem_buffers\n",
    "    model_mem_mb = model_mem_bytes / (1024 ** 2)\n",
    "    model_mem_gb = model_mem_bytes / (1024 ** 3)\n",
    "\n",
    "    return {\n",
    "        \"model_mem_bytes\" : model_mem_bytes,\n",
    "        \"model_mem_mb\" : round(model_mem_mb, 2),\n",
    "        \"model_mem_gb\" : round(model_mem_gb, 2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vEBW",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of parameters in our model\n",
    "get_model_nparam(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kLmu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the memory requirement of our model\n",
    "get_model_memsize(llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IpqN",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Generating text with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dxZZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = (\n",
    "    \"What are the macronutrients,\"\n",
    "    \" and what roles do they play in the human body?\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Query: {input_text}\"\n",
    ")\n",
    "\n",
    "dialog_template = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : input_text,\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    conversation=dialog_template,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nPrompt (formatted):\\n{prompt}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dlnW",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors='pt').to(device_1)\n",
    "print(f'Model input (tokenized):\\n{input_ids}')\n",
    "outputs = llm_model.generate(**input_ids, max_new_tokens=256)\n",
    "print(f'Model output (tokens):\\n{outputs[0]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TTti",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(\n",
    "    f\"Model output (decoded):\\n{outputs_decoded}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RKFZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_output = (\n",
    "    lambda text: text\n",
    "        .replace(prompt, '')\n",
    "        .replace('<bos>', '')\n",
    "        .replace('<eos>', '')\n",
    ")\n",
    "\n",
    "print(f\"Input Text: {input_text}\\n\")\n",
    "print(f\"Output Text:\\n{format_output(outputs_decoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IaQp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Augmenting prompt with contextual chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IWgg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wrapped_1(text, wrap_length=79):\n",
    "    \"\"\"\n",
    "    New print_wrapped version that respect the\n",
    "    indentations of the LLM output and the prompt\n",
    "    \"\"\"\n",
    "    for line in text.splitlines():\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "        wrapped = textwrap.fill(line, width=wrap_length, subsequent_indent=' ' * indent, replace_whitespace=False, drop_whitespace=False)\n",
    "        print(wrapped)\n",
    "\n",
    "def prompt_builder(query: str, context: list[dict], tokenizer: AutoTokenizer) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context.\n",
    "    \"\"\"\n",
    "    context = '- ' + '\\n- '.join([item['chunk'] for item in context])\n",
    "    base_prompt = \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context items to answer the user query:\\n{context}\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: {query}\\nAnswer:\"\n",
    "    augmented = base_prompt.format(context=context, query=query)\n",
    "    dialog_template = [{'role': 'user', 'content': augmented}]\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialog_template, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fCoF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutrition-style questions generated with GPT4\n",
    "gpt4_questions = [\n",
    "    \"What are the macronutrients, and what roles do they play in the human body?\",\n",
    "    \"How do vitamins and minerals differ in their roles and importance for health?\",\n",
    "    \"Describe the process of digestion and absorption of nutrients in the human body.\",\n",
    "    \"What role does fibre play in digestion? Name five fibre containing foods.\",\n",
    "    \"Explain the concept of energy balance and its importance in weight management.\"\n",
    "]\n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"How often should infants be breastfed?\",\n",
    "    \"What are symptoms of pellagra?\",\n",
    "    \"How does saliva help with digestion?\",\n",
    "    \"What is the RDI for protein per day?\",\n",
    "    \"water soluble vitamins\"\n",
    "]\n",
    "\n",
    "query_list = gpt4_questions + manual_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LkGn",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = random.choice(query_list)\n",
    "print(f'Query: {query_2}')\n",
    "scores_1, indices_1 = retrieve_chunks(query_2, embeddings_2, embedding_model_1)\n",
    "context = [chunk_embedding_data[i] for i in indices_1]\n",
    "prompt_1 = prompt_builder(query_2, context, tokenizer)\n",
    "print_wrapped_1(prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zVRe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_1 = tokenizer(prompt_1, return_tensors='pt').to(device_1)\n",
    "outputs_1 = llm_model.generate(**input_ids_1, temperature=0.7, do_sample=True, max_new_tokens=512)\n",
    "output_text = tokenizer.decode(outputs_1[0])\n",
    "print(f'Query: {query_2}\\n')\n",
    "print_wrapped_1(f'RAG answer:\\n{format_output(output_text)}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
