{
  "version": "1",
  "metadata": {
    "marimo_version": "0.13.15"
  },
  "cells": [
    {
      "id": "setup",
      "code_hash": "3d86a23c92ae148f55deb2520f8c7213",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "Hbol",
      "code_hash": "96379d387ddac03d5f7158a0722bdd34",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h1 id=\"machine-specs\">Machine Specs</h1></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "MJUe",
      "code_hash": "ccc69ea4b1a214f77cfa56ce9a9b5eb2",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><span>CUDA is available</span><span>GPU: NVIDIA GeForce GTX 1660 Ti</span></div>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vblA",
      "code_hash": "782498b0da05787845794c82603cda96",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"ray-docs-pre-processing\">Ray docs Pre-processing</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "bkHC",
      "code_hash": "21c6af9480efce46be2e059757311fb4",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "lEQa",
      "code_hash": "e36741b5c2e6093130f6cc9bcc1e2580",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "PKri",
      "code_hash": "e087442121df9caacfdf7fdfdf13c6db",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "Xref",
      "code_hash": "51856b8b619ddb395f9d72dd6ad1cf87",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'System Info\n      Using FIFO scheduling algorithm.Logical resource usage: 1.0/12 CPUs, 0/0 GPUs\n    \n\n\n\nTrial Status\n\n\nTrial name                     status    loc                    eta  max_depth  min_child_weight  subsample     acc  iter  total time (s)\n\n\ntrain_breast_cancer_31c9f_00000TERMINATED127.0.0.1:897350.0434196            8                 1   0.5303510.909091     1      0.0114911 \ntrain_breast_cancer_31c9f_00001TERMINATED127.0.0.1:897340.0115669            6                 2   0.9965190.615385     1      0.01138   \ntrain_breast_cancer_31c9f_00002TERMINATED127.0.0.1:897400.00124339           7                 3   0.5360780.629371     1      0.0096581 \ntrain_breast_cancer_31c9f_00003TERMINATED127.0.0.1:897420.000400434          6                 3   0.90014 0.601399     1      0.0103199 \ntrain_breast_cancer_31c9f_00004TERMINATED127.0.0.1:897380.0121308            6                 3   0.8431560.629371     1      0.00843   \ntrain_breast_cancer_31c9f_00005TERMINATED127.0.0.1:897330.0344144            2                 3   0.5130710.895105     1      0.00800109\ntrain_breast_cancer_31c9f_00006TERMINATED127.0.0.1:897370.0530037            7                 2   0.9208010.965035     1      0.0117419 \ntrain_breast_cancer_31c9f_00007TERMINATED127.0.0.1:897410.000230442          3                 3   0.9468520.608392     1      0.00917387\ntrain_breast_cancer_31c9f_00008TERMINATED127.0.0.1:897390.00166323           4                 1   0.5888790.636364     1      0.011095  \ntrain_breast_cancer_31c9f_00009TERMINATED127.0.0.1:897360.0753618            3                 3   0.55103 0.909091     1      0.00776482\n\n\n\n\n\n2025-02-11 16:13:34,649\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/rdecal/ray_results/train_breast_cancer_2025-02-11_16-13-31' in 0.0057s.\n2025-02-11 16:13:34,652\tINFO tune.py:1041 -- Total run time: 1.88 seconds (1.86 seconds for the tuning loop).\n\n\n\n\n\nAs you can see, the changes in the actual training function are minimal. Instead of\nreturning the accuracy value, we report it back to Tune using session.report().\nOur config dictionary only changed slightly. Instead of passing hard-coded\nparameters, we tell Tune to choose values from a range of valid options. There are\na number of options we have here, all of which are explained in\nthe Tune docs.\nFor a brief explanation, this is what they do:\n\ntune.randint(min, max) chooses a random integer value between min and max.\nNote that max is exclusive, so it will not be sampled.\ntune.choice([a, b, c]) chooses one of the items of the list at random. Each item\nhas the same chance to be sampled.\ntune.uniform(min, max) samples a floating point number between min and max.\nNote that max is exclusive here, too.\ntune.loguniform(min, max, base=10) samples a floating point number between min and max,\nbut applies a logarithmic transformation to these boundaries first. Thus, this makes\nit easy to sample values from different orders of magnitude.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '2025-02-24 16:22:06,309\tINFO pbt.py:878 -- \n\n[PopulationBasedTraining] [Exploit] Cloning trial 74757_00001 (score = 1.199924) into trial 74757_00000 (score = 1.199920)\n\n2025-02-24 16:22:06,310\tINFO pbt.py:905 -- \n\n[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial74757_00000:\nlr : 0.062784 --- (resample) --> 0.006500000000000001\nh0 : 1.1144501835013578 --- (* 0.8) --> 0.8915601468010863\nh1 : 0.25894972559062557 --- (resample) --> 0.4494584110928429\n\n2025-02-24 16:22:07,944\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/rdecal/ray_results/train_func_2025-02-24_16-21-28' in 0.0049s.\n2025-02-24 16:22:07,946\tINFO tune.py:1041 -- Total run time: 39.88 seconds (39.86 seconds for the tuning loop).\n\n\n\n\n\n\n\nVisualize results#\nUsing some helper functions from here, we can create some visuals to help us understand the training progression of PBT.\n\n\nfig, axs = plt.subplots(1, 2, figsize=(13, 6), gridspec_kw=dict(width_ratios=[1.5, 1]))\n\ncolors = [\"red\", \"black\"]\nlabels = [\"h = [1, 0]\", \"h = [0, 1]\"]\n\nplot_parameter_history(\n    pbt_results,\n    colors,\n    labels,\n    perturbation_interval=perturbation_interval,\n    fig=fig,\n    ax=axs[0],\n)\nplot_Q_history(pbt_results, colors, labels, ax=axs[1])\n\n\n\n\n\n\n\nThe plot on the right shows the true function value Q(theta) as training progresses for both trials. Both trials reach the maximum value of 1.2. This demonstrates PBT\u2019s ability to find optimal solutions regardless of the initial hyperparameter configuration.\nHere\u2019s how to understand the plot on the left:\n\nThe plot on the left shows the parameter values (theta0, theta1) on every training iteration, for both trials. As the training iteration increases, the size of the point gets smaller.\nWe see the iteration shown as a label next to points at every perturbation_interval training iterations. Let\u2019s zoom into the transition from iteration 4 to 5 for both the trials.\n\nWe see that a trial either continues (see how iteration 4 to 5 for the red trial just continues training) or exploits and perturbs the other trial and then performs a train step (see how iteration 4 to 5 for the black trial jumps to the parameter value of the red trial).\nThe gradient direction also changes at this step for the red trial due to the hyperparameters changing from the exploit and explore steps of PBT. Remember that the gradient of the estimator Qhat depends on the hyperparameters (h0, h1).\nThe varying size of jumps between training iterations shows that the learning rate is also changing, since we included lr in the set of hyperparameters to mutate.\n\n\n\n\nAnimate the training progress#\n\n\nmake_animation(\n    pbt_results,\n    colors,\n    labels,\n    perturbation_interval=perturbation_interval,\n    filename=\"pbt.gif\",\n)\n\n\n\n\nWe can also animate the training progress to see what\u2019s happening to the model parameters at each step. The animation shows:\n\nHow parameters move through space during training\nWhen exploitation occurs (jumps in parameter space)\nHow gradient directions change after hyperparameter perturbation\nBoth trials eventually converging to the optimal parameter region\n\n\n\n\n\nGrid Search Comparison#\nThe paper includes a comparison to a grid search of 2 trials, using the same initial hyperparameter configurations (h = [1, 0], h = [0, 1]) as the PBT experiment. The only difference in the code below is removing the PBT scheduler from the TuneConfig.\n\n\nif ray.is_initialized():\n    ray.shutdown()\nray.init()': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '2025-02-24 16:22:06,309\tINFO pbt.py:878 -- \n\n[PopulationBasedTraining] [Exploit] Cloning trial 74757_00001 (score = 1.199924) into trial 74757_00000 (score = 1.199920)\n\n2025-02-24 16:22:06,310\tINFO pbt.py:905 -- \n\n[PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial74757_00000:\nlr : 0.062784 --- (resample) --> 0.006500000000000001\nh0 : 1.1144501835013578 --- (* 0.8) --> 0.8915601468010863\nh1 : 0.25894972559062557 --- (resample) --> 0.4494584110928429\n\n2025-02-24 16:22:07,944\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/rdecal/ray_results/train_func_2025-02-24_16-21-28' in 0.0049s.\n2025-02-24 16:22:07,946\tINFO tune.py:1041 -- Total run time: 39.88 seconds (39.86 seconds for the tuning loop).\n\n\n\n\n\n\n\nVisualize results#\nUsing some helper functions from here, we can create some visuals to help us understand the training progression of PBT.\n\n\nfig, axs = plt.subplots(1, 2, figsize=(13, 6), gridspec_kw=dict(width_ratios=[1.5, 1]))\n\ncolors = [\"red\", \"black\"]\nlabels = [\"h = [1, 0]\", \"h = [0, 1]\"]\n\nplot_parameter_history(\n    pbt_results,\n    colors,\n    labels,\n    perturbation_interval=perturbation_interval,\n    fig=fig,\n    ax=axs[0],\n)\nplot_Q_history(pbt_results, colors, labels, ax=axs[1])\n\n\n\n\n\n\n\nThe plot on the right shows the true function value Q(theta) as training progresses for both trials. Both trials reach the maximum value of 1.2. This demonstrates PBT\u2019s ability to find optimal solutions regardless of the initial hyperparameter configuration.\nHere\u2019s how to understand the plot on the left:\n\nThe plot on the left shows the parameter values (theta0, theta1) on every training iteration, for both trials. As the training iteration increases, the size of the point gets smaller.\nWe see the iteration shown as a label next to points at every perturbation_interval training iterations. Let\u2019s zoom into the transition from iteration 4 to 5 for both the trials.\n\nWe see that a trial either continues (see how iteration 4 to 5 for the red trial just continues training) or exploits and perturbs the other trial and then performs a train step (see how iteration 4 to 5 for the black trial jumps to the parameter value of the red trial).\nThe gradient direction also changes at this step for the red trial due to the hyperparameters changing from the exploit and explore steps of PBT. Remember that the gradient of the estimator Qhat depends on the hyperparameters (h0, h1).\nThe varying size of jumps between training iterations shows that the learning rate is also changing, since we included lr in the set of hyperparameters to mutate.\n\n\n\n\nAnimate the training progress#\n\n\nmake_animation(\n    pbt_results,\n    colors,\n    labels,\n    perturbation_interval=perturbation_interval,\n    filename=\"pbt.gif\",\n)\n\n\n\n\nWe can also animate the training progress to see what\u2019s happening to the model parameters at each step. The animation shows:\n\nHow parameters move through space during training\nWhen exploitation occurs (jumps in parameter space)\nHow gradient directions change after hyperparameter perturbation\nBoth trials eventually converging to the optimal parameter region\n\n\n\n\n\nGrid Search Comparison#\nThe paper includes a comparison to a grid search of 2 trials, using the same initial hyperparameter configurations (h = [1, 0], h = [0, 1]) as the PBT experiment. The only difference in the code below is removing the PBT scheduler from the TuneConfig.\n\n\nif ray.is_initialized():\n    ray.shutdown()\nray.init()': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Grid Search Comparison#\nThe paper includes a comparison to a grid search of 2 trials, using the same initial hyperparameter configurations (h = [1, 0], h = [0, 1]) as the PBT experiment. The only difference in the code below is removing the PBT scheduler from the TuneConfig.\n\n\nif ray.is_initialized():\n    ray.shutdown()\nray.init()\n\ntuner = Tuner(\n    train_func,\n    param_space={\n        \"lr\": tune.qloguniform(1e-2, 1e-1, 5e-3),\n        \"h0\": tune.grid_search([0.0, 1.0]),\n        \"h1\": tune.sample_from(lambda spec: 1.0 - spec.config[\"h0\"]),\n    },\n    tune_config=tune.TuneConfig(\n        num_samples=1,\n        metric=\"Q\",\n        mode=\"max\",\n    ),\n    run_config=tune.RunConfig(\n        stop={\"training_iteration\": 100},\n        failure_config=tune.FailureConfig(max_failures=3),\n    ),\n)\n\ngrid_results = tuner.fit()\nif grid_results.errors:\n    raise RuntimeError\n\n\n\n\n\nShow code cell output\nHide code cell output\n\n\n\n\n\nTune Status\n\n\nCurrent time:2025-02-24 16:22:18\nRunning for: 00:00:01.24        \nMemory:      21.5/36.0 GiB      \n\n\n\n\n\nSystem Info\n      Using FIFO scheduling algorithm.Logical resource usage: 1.0/12 CPUs, 0/0 GPUs\n    \n\n\n\nTrial Status\n\n\nTrial name            status    loc              h0   lr  iter  total time (s)       Q     theta0   theta1\n\n\ntrain_func_91d06_00000TERMINATED127.0.0.1:23610   00.015   100       0.068691 0.5906680.9        0.0427973\ntrain_func_91d06_00001TERMINATED127.0.0.1:23609   10.045   100       0.06599690.3899990.0008300930.9      \n\n\n\n\n\n\n\n\n\nAs we can see, neither trial makes it to the optimum, since the search configs are stuck with their original values. This illustrates a key advantage of PBT: while traditional hyperparameter search methods (like grid search) keep fixed search values throughout training, PBT can adapt the search dynamically, allowing it to find better solutions with the same computational budget.\n\n\nfig, axs = plt.subplots(1, 2, figsize=(13, 6), gridspec_kw=dict(width_ratios=[1.5, 1]))\n\ncolors = [\"red\", \"black\"]\nlabels = [\"h = [1, 0]\", \"h = [0, 1]\"]\n\nplot_parameter_history(\n    grid_results,\n    colors,\n    labels,\n    perturbation_interval=perturbation_interval,\n    fig=fig,\n    ax=axs[0],\n)\nplot_Q_history(grid_results, colors, labels, ax=axs[1])\n\n\n\n\n\n\n\nCompare the two plots we generated with Figure 2 from the PBT paper (in particular, we produced the top-left and bottom-right plots).\n\n\n\nIncrease PBT population size#\nOne last experiment: what does it look like if we increase the PBT population size? Now, low-performing trials will sample one of the multiple high-performing trials to exploit, and it should result in some more interesting behavior.\nWith a larger population:\n\nThere\u2019s more diversity in the exploration space\nMultiple \u201cgood\u201d solutions can be discovered simultaneously\nDifferent exploitation patterns emerge as trials may choose from multiple well-performing configurations\nThe population as a whole can develop more robust strategies for optimization': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '2022-07-22 15:41:24,693\tINFO plugin_schema_manager.py:52 -- Loading the default runtime env schemas: ['/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/working_dir_schema.json', '/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/pip_schema.json'].\nCOMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\nCOMET ERROR: The given API key abc is invalid, please check it against the dashboard. Your experiment would not be logged \nFor more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors/\nCOMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\nCOMET ERROR: The given API key abc is invalid, please check it against the dashboard. Your experiment would not be logged \nFor more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors/\nCOMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\nCOMET ERROR: The given API key abc is invalid, please check it against the dashboard. Your experiment would not be logged \nFor more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors/\n\n\n2022-07-22 15:41:31,290\tINFO tune.py:738 -- Total run time: 7.36 seconds (6.72 seconds for the tuning loop).\n\n\n{'mean': 1, 'sd': 0.40575843135279466}\n\n\n\n\n\n\nTune Comet Logger#\nRay Tune offers an integration with Comet through the CometLoggerCallback,\nwhich automatically logs metrics and parameters reported to Tune to the Comet UI.\nClick on the following dropdown to see this callback API in detail:\n\n\nclass ray.air.integrations.comet.CometLoggerCallback(online: bool = True, tags: List[str] = None, save_checkpoints: bool = False, **experiment_kwargs)[source]\nCometLoggerCallback for logging Tune results to Comet.\nComet (https://comet.ml/site/) is a tool to manage and optimize the\nentire ML lifecycle, from experiment tracking, model optimization\nand dataset versioning to model production monitoring.\nThis Ray Tune LoggerCallback sends metrics and parameters to\nComet for tracking.\nIn order to use the CometLoggerCallback you must first install Comet\nvia pip install comet_ml\nThen set the following environment variables\nexport COMET_API_KEY=<Your API Key>\nAlternatively, you can also pass in your API Key as an argument to the\nCometLoggerCallback constructor.\nCometLoggerCallback(api_key=<Your API Key>)\n\nParameters:\n\nonline \u2013 Whether to make use of an Online or\nOffline Experiment. Defaults to True.\ntags \u2013 Tags to add to the logged Experiment.\nDefaults to None.\nsave_checkpoints \u2013 If True, model checkpoints will be saved to\nComet ML as artifacts. Defaults to False.\n**experiment_kwargs \u2013 Other keyword arguments will be passed to the\nconstructor for comet_ml.Experiment (or OfflineExperiment if\nonline=False).\n\n\n\nPlease consult the Comet ML documentation for more information on the\nExperiment and OfflineExperiment classes: https://comet.ml/site/\nExample:\nfrom ray.air.integrations.comet import CometLoggerCallback\ntune.run(\n    train,\n    config=config\n    callbacks=[CometLoggerCallback(\n        True,\n        ['tag1', 'tag2'],\n        workspace='my_workspace',\n        project_name='my_project_name'\n        )]\n)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(objective pid=45370) 2022-07-22 15:11:20,826\tINFO trainable.py:655 -- Restored on 127.0.0.1 from checkpoint: /Users/kai/ray_results/bohb_exp_2/objective_2397442c_1_activation=tanh,height=32.8422,steps=100,width=12.1847_2022-07-22_15-11-11/checkpoint_tmpf4b290\n(objective pid=45370) 2022-07-22 15:11:20,826\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 0.10108494758605957, '_episodes_total': 0}\n\n\nResult for objective_25b4a998:\n  date: 2022-07-22_15-11-24\n  done: false\n  episodes_total: 0\n  experiment_id: 20a5d76dc18749e4b1c9f15c5d8b43cf\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 22.028519616352035\n  neg_mean_loss: -22.028519616352035\n  node_ip: 127.0.0.1\n  pid: 45401\n  time_since_restore: 0.10445284843444824\n  time_this_iter_s: 0.10445284843444824\n  time_total_s: 0.2087719440460205\n  timestamp: 1658499084\n  timesteps_since_restore: 0\n  timesteps_total: 0\n  training_iteration: 1\n  trial_id: 25b4a998\n  warmup_time: 0.010488033294677734\n  \n\n\n(objective pid=45424) 2022-07-22 15:11:24,383\tINFO trainable.py:655 -- Restored on 127.0.0.1 from checkpoint: /Users/kai/ray_results/bohb_exp_2/objective_27b7e2be_9_activation=relu,height=-51.2093,steps=100,width=8.9495_2022-07-22_15-11-18/checkpoint_tmp996dec\n(objective pid=45424) 2022-07-22 15:11:24,384\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 0.10371994972229004, '_episodes_total': 0}\n\n\nResult for objective_27b7e2be:\n  date: 2022-07-22_15-11-24\n  done: false\n  episodes_total: 0\n  experiment_id: fdc43ca37ed44cde857ca150a8f1e84f\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 14.879072389639937\n  neg_mean_loss: -14.879072389639937\n  node_ip: 127.0.0.1\n  pid: 45424\n  time_since_restore: 0.1031639575958252\n  time_this_iter_s: 0.1031639575958252\n  time_total_s: 0.20688390731811523\n  timestamp: 1658499084\n  timesteps_since_restore: 0\n  timesteps_total: 0\n  training_iteration: 1\n  trial_id: 27b7e2be\n  warmup_time: 0.0069200992584228516': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(objective pid=45370) 2022-07-22 15:11:20,826\tINFO trainable.py:655 -- Restored on 127.0.0.1 from checkpoint: /Users/kai/ray_results/bohb_exp_2/objective_2397442c_1_activation=tanh,height=32.8422,steps=100,width=12.1847_2022-07-22_15-11-11/checkpoint_tmpf4b290\n(objective pid=45370) 2022-07-22 15:11:20,826\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 0.10108494758605957, '_episodes_total': 0}\n\n\nResult for objective_25b4a998:\n  date: 2022-07-22_15-11-24\n  done: false\n  episodes_total: 0\n  experiment_id: 20a5d76dc18749e4b1c9f15c5d8b43cf\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 22.028519616352035\n  neg_mean_loss: -22.028519616352035\n  node_ip: 127.0.0.1\n  pid: 45401\n  time_since_restore: 0.10445284843444824\n  time_this_iter_s: 0.10445284843444824\n  time_total_s: 0.2087719440460205\n  timestamp: 1658499084\n  timesteps_since_restore: 0\n  timesteps_total: 0\n  training_iteration: 1\n  trial_id: 25b4a998\n  warmup_time: 0.010488033294677734\n  \n\n\n(objective pid=45424) 2022-07-22 15:11:24,383\tINFO trainable.py:655 -- Restored on 127.0.0.1 from checkpoint: /Users/kai/ray_results/bohb_exp_2/objective_27b7e2be_9_activation=relu,height=-51.2093,steps=100,width=8.9495_2022-07-22_15-11-18/checkpoint_tmp996dec\n(objective pid=45424) 2022-07-22 15:11:24,384\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 0.10371994972229004, '_episodes_total': 0}\n\n\nResult for objective_27b7e2be:\n  date: 2022-07-22_15-11-24\n  done: false\n  episodes_total: 0\n  experiment_id: fdc43ca37ed44cde857ca150a8f1e84f\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 14.879072389639937\n  neg_mean_loss: -14.879072389639937\n  node_ip: 127.0.0.1\n  pid: 45424\n  time_since_restore: 0.1031639575958252\n  time_this_iter_s: 0.1031639575958252\n  time_total_s: 0.20688390731811523\n  timestamp: 1658499084\n  timesteps_since_restore: 0\n  timesteps_total: 0\n  training_iteration: 1\n  trial_id: 27b7e2be\n  warmup_time: 0.0069200992584228516': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(objective pid=45454) 2022-07-22 15:11:29,879\tINFO trainable.py:655 -- Restored on 127.0.0.1 from checkpoint: /Users/kai/ray_results/bohb_exp_2/objective_278eba4c_6_activation=relu,height=-27.0179,steps=100,width=13.5770_2022-07-22_15-11-18/checkpoint_tmp2835d4\n(objective pid=45454) 2022-07-22 15:11:29,879\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 0.5807228088378906, '_episodes_total': 0}\n(objective pid=45455) 2022-07-22 15:11:29,909\tINFO trainable.py:655 -- Restored on 127.0.0.1 from checkpoint: /Users/kai/ray_results/bohb_exp_2/objective_27b7e2be_9_activation=relu,height=-51.2093,steps=100,width=8.9495_2022-07-22_15-11-18/checkpoint_tmpd7ea63\n(objective pid=45455) 2022-07-22 15:11:29,910\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 0.9150340557098389, '_episodes_total': 0}\n(objective pid=45453) 2022-07-22 15:11:29,930\tINFO trainable.py:655 -- Restored on 127.0.0.1 from checkpoint: /Users/kai/ray_results/bohb_exp_2/objective_25b64488_3_activation=tanh,height=-48.4518,steps=100,width=10.1191_2022-07-22_15-11-14/checkpoint_tmp11824e\n(objective pid=45453) 2022-07-22 15:11:29,930\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 0.5960800647735596, '_episodes_total': 0}\n\n\n\n\nHere again are the hyperparameters found to minimize the mean loss of the\ndefined objective.\n\n\nprint(\"Best hyperparameters found were: \", results.get_best_result().config)\n\n\n\n\nBest hyperparameters found were:  {'activation': 'tanh', 'height': -48.451797714080236, 'steps': 100, 'width': 10.119125894538891}': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Returns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring training behavior#\n\n\nAlgorithmConfig.training(*, gamma: float | None = <ray.rllib.utils.from_config._NotProvided object>, lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip: float | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip_by: str | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_epochs: int | None = <ray.rllib.utils.from_config._NotProvided object>, minibatch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, shuffle_batch_per_epoch: bool | None = <ray.rllib.utils.from_config._NotProvided object>, model: dict | None = <ray.rllib.utils.from_config._NotProvided object>, optimizer: dict | None = <ray.rllib.utils.from_config._NotProvided object>, learner_class: ~typing.Type[Learner] | None = <ray.rllib.utils.from_config._NotProvided object>, learner_connector: ~typing.Callable[[RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_learner_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, learner_config_dict: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, num_aggregator_actors_per_learner=-1, max_requests_in_flight_per_aggregator_actor=-1, num_sgd_iter=-1, max_requests_in_flight_per_sampler_worker=-1) \u2192 AlgorithmConfig[source]\nSets the training related configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#\n\n\nAlgorithmConfig.env_runners(*, env_runner_cls: type | None = <ray.rllib.utils.from_config._NotProvided object>, num_env_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, create_local_env_runner: bool | None = <ray.rllib.utils.from_config._NotProvided object>, create_env_on_local_worker: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_envs_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, gym_env_vectorize_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_env_runner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_resources_per_env_runner: dict | None = <ray.rllib.utils.from_config._NotProvided object>, validate_env_runners_after_construction: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sample_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, env_to_module_connector: ~typing.Callable[[~typing.Any | gymnasium.Env], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, module_to_env_connector: ~typing.Callable[[~typing.Any | gymnasium.Env, RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_env_to_module_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_module_to_env_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episode_lookback_horizon: int | None = <ray.rllib.utils.from_config._NotProvided object>, merge_env_runner_states: str | bool | None = <ray.rllib.utils.from_config._NotProvided object>, broadcast_env_runner_states: bool | None = <ray.rllib.utils.from_config._NotProvided object>, compress_observations: bool | None = <ray.rllib.utils.from_config._NotProvided object>, rollout_fragment_length: int | str | None = <ray.rllib.utils.from_config._NotProvided object>, batch_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, explore: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episodes_to_numpy: bool | None = <ray.rllib.utils.from_config._NotProvided object>, use_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, update_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, exploration_config: dict | None = <ray.rllib.utils.from_config._NotProvided object>, sample_collector: ~typing.Type[~ray.rllib.evaluation.collectors.sample_collector.SampleCollector] | None = <ray.rllib.utils.from_config._NotProvided object>, remote_worker_envs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, remote_env_batch_wait_ms: float | None = <ray.rllib.utils.from_config._NotProvided object>, preprocessor_pref: str | None = <ray.rllib.utils.from_config._NotProvided object>, observation_filter: str | None = <ray.rllib.utils.from_config._NotProvided object>, enable_tf1_exec_eagerly: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sampler_perf_stats_ema_coef: float | None = <ray.rllib.utils.from_config._NotProvided object>, num_rollout_workers=-1, num_envs_per_worker=-1, validate_workers_after_construction=-1, ignore_worker_failures=-1, recreate_failed_workers=-1, restart_failed_sub_environments=-1, num_consecutive_worker_failures_tolerance=-1, worker_health_probe_timeout_s=-1, worker_restore_timeout_s=-1, synchronize_filter=-1, enable_connectors=-1) \u2192 AlgorithmConfig[source]\nSets the rollout worker configuration.\n\nParameters:': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Returns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring training behavior#\n\n\nAlgorithmConfig.training(*, gamma: float | None = <ray.rllib.utils.from_config._NotProvided object>, lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip: float | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip_by: str | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_epochs: int | None = <ray.rllib.utils.from_config._NotProvided object>, minibatch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, shuffle_batch_per_epoch: bool | None = <ray.rllib.utils.from_config._NotProvided object>, model: dict | None = <ray.rllib.utils.from_config._NotProvided object>, optimizer: dict | None = <ray.rllib.utils.from_config._NotProvided object>, learner_class: ~typing.Type[Learner] | None = <ray.rllib.utils.from_config._NotProvided object>, learner_connector: ~typing.Callable[[RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_learner_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, learner_config_dict: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, num_aggregator_actors_per_learner=-1, max_requests_in_flight_per_aggregator_actor=-1, num_sgd_iter=-1, max_requests_in_flight_per_sampler_worker=-1) \u2192 AlgorithmConfig[source]\nSets the training related configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#\n\n\nAlgorithmConfig.env_runners(*, env_runner_cls: type | None = <ray.rllib.utils.from_config._NotProvided object>, num_env_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, create_local_env_runner: bool | None = <ray.rllib.utils.from_config._NotProvided object>, create_env_on_local_worker: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_envs_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, gym_env_vectorize_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_env_runner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_resources_per_env_runner: dict | None = <ray.rllib.utils.from_config._NotProvided object>, validate_env_runners_after_construction: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sample_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, env_to_module_connector: ~typing.Callable[[~typing.Any | gymnasium.Env], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, module_to_env_connector: ~typing.Callable[[~typing.Any | gymnasium.Env, RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_env_to_module_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_module_to_env_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episode_lookback_horizon: int | None = <ray.rllib.utils.from_config._NotProvided object>, merge_env_runner_states: str | bool | None = <ray.rllib.utils.from_config._NotProvided object>, broadcast_env_runner_states: bool | None = <ray.rllib.utils.from_config._NotProvided object>, compress_observations: bool | None = <ray.rllib.utils.from_config._NotProvided object>, rollout_fragment_length: int | str | None = <ray.rllib.utils.from_config._NotProvided object>, batch_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, explore: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episodes_to_numpy: bool | None = <ray.rllib.utils.from_config._NotProvided object>, use_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, update_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, exploration_config: dict | None = <ray.rllib.utils.from_config._NotProvided object>, sample_collector: ~typing.Type[~ray.rllib.evaluation.collectors.sample_collector.SampleCollector] | None = <ray.rllib.utils.from_config._NotProvided object>, remote_worker_envs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, remote_env_batch_wait_ms: float | None = <ray.rllib.utils.from_config._NotProvided object>, preprocessor_pref: str | None = <ray.rllib.utils.from_config._NotProvided object>, observation_filter: str | None = <ray.rllib.utils.from_config._NotProvided object>, enable_tf1_exec_eagerly: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sampler_perf_stats_ema_coef: float | None = <ray.rllib.utils.from_config._NotProvided object>, num_rollout_workers=-1, num_envs_per_worker=-1, validate_workers_after_construction=-1, ignore_worker_failures=-1, recreate_failed_workers=-1, restart_failed_sub_environments=-1, num_consecutive_worker_failures_tolerance=-1, worker_health_probe_timeout_s=-1, worker_restore_timeout_s=-1, synchronize_filter=-1, enable_connectors=-1) \u2192 AlgorithmConfig[source]\nSets the rollout worker configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring LearnerGroup and Learner actors#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring LearnerGroup and Learner actors#\n\n\nAlgorithmConfig.learners(*, num_learners: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_learner: str | float | int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_learner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, num_aggregator_actors_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_aggregator_actor: float | None = <ray.rllib.utils.from_config._NotProvided object>, local_gpu_idx: int | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>)[source]\nSets LearnerGroup and Learner worker related configurations.\n\nParameters:\n\nnum_learners \u2013 Number of Learner workers used for updating the RLModule.\nA value of 0 means training takes place on a local Learner on main\nprocess CPUs or 1 GPU (determined by num_gpus_per_learner).\nFor multi-gpu training, you have to set num_learners to > 1 and set\nnum_gpus_per_learner accordingly (e.g., 4 GPUs total and model fits on\n1 GPU: num_learners=4; num_gpus_per_learner=1 OR 4 GPUs total and\nmodel requires 2 GPUs: num_learners=2; num_gpus_per_learner=2).\nnum_cpus_per_learner \u2013 Number of CPUs allocated per Learner worker.\nIf \u201cauto\u201d (default), use 1 if num_gpus_per_learner=0, otherwise 0.\nOnly necessary for custom processing pipeline inside each Learner\nrequiring multiple CPU cores.\nIf num_learners=0, RLlib creates only one local Learner instance and\nthe number of CPUs on the main process is\nmax(num_cpus_per_learner, num_cpus_for_main_process).\nnum_gpus_per_learner \u2013 Number of GPUs allocated per Learner worker. If\nnum_learners=0, any value greater than 0 runs the\ntraining on a single GPU on the main process, while a value of 0 runs\nthe training on main process CPUs.\nnum_aggregator_actors_per_learner \u2013 The number of aggregator actors per\nLearner (if num_learners=0, one local learner is created). Must be at\nleast 1. Aggregator actors perform the task of a) converting episodes\ninto a train batch and b) move that train batch to the same GPU that\nthe corresponding learner is located on. Good values are 1 or 2, but\nthis strongly depends on your setup and EnvRunner throughput.\nmax_requests_in_flight_per_aggregator_actor \u2013 How many in-flight requests\nare allowed per aggregator actor before new requests are dropped?\nlocal_gpu_idx \u2013 If num_gpus_per_learner > 0, and\nnum_learners < 2, then RLlib uses this GPU index for training. This is\nan index into the available\nCUDA devices. For example if os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nand local_gpu_idx=0, RLlib uses the GPU with ID=1 on the node.\nmax_requests_in_flight_per_learner \u2013 Max number of in-flight requests\nto each Learner (actor). You normally do not have to tune this setting\n(default is 3), however, for asynchronous algorithms, this determines\nthe \u201cqueue\u201d size for incoming batches (or lists of episodes) into each\nLearner worker, thus also determining, how much off-policy\u2019ness would be\nacceptable. The off-policy\u2019ness is the difference between the numbers of\nupdates a policy has undergone on the Learner vs the EnvRunners.\nSee the ray.rllib.utils.actor_manager.FaultTolerantActorManager class\nfor more details.\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring custom callbacks#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Returns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring training behavior#\n\n\nAlgorithmConfig.training(*, gamma: float | None = <ray.rllib.utils.from_config._NotProvided object>, lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip: float | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip_by: str | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_epochs: int | None = <ray.rllib.utils.from_config._NotProvided object>, minibatch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, shuffle_batch_per_epoch: bool | None = <ray.rllib.utils.from_config._NotProvided object>, model: dict | None = <ray.rllib.utils.from_config._NotProvided object>, optimizer: dict | None = <ray.rllib.utils.from_config._NotProvided object>, learner_class: ~typing.Type[Learner] | None = <ray.rllib.utils.from_config._NotProvided object>, learner_connector: ~typing.Callable[[RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_learner_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, learner_config_dict: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, num_aggregator_actors_per_learner=-1, max_requests_in_flight_per_aggregator_actor=-1, num_sgd_iter=-1, max_requests_in_flight_per_sampler_worker=-1) \u2192 AlgorithmConfig[source]\nSets the training related configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#\n\n\nAlgorithmConfig.env_runners(*, env_runner_cls: type | None = <ray.rllib.utils.from_config._NotProvided object>, num_env_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, create_local_env_runner: bool | None = <ray.rllib.utils.from_config._NotProvided object>, create_env_on_local_worker: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_envs_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, gym_env_vectorize_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_env_runner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_resources_per_env_runner: dict | None = <ray.rllib.utils.from_config._NotProvided object>, validate_env_runners_after_construction: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sample_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, env_to_module_connector: ~typing.Callable[[~typing.Any | gymnasium.Env], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, module_to_env_connector: ~typing.Callable[[~typing.Any | gymnasium.Env, RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_env_to_module_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_module_to_env_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episode_lookback_horizon: int | None = <ray.rllib.utils.from_config._NotProvided object>, merge_env_runner_states: str | bool | None = <ray.rllib.utils.from_config._NotProvided object>, broadcast_env_runner_states: bool | None = <ray.rllib.utils.from_config._NotProvided object>, compress_observations: bool | None = <ray.rllib.utils.from_config._NotProvided object>, rollout_fragment_length: int | str | None = <ray.rllib.utils.from_config._NotProvided object>, batch_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, explore: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episodes_to_numpy: bool | None = <ray.rllib.utils.from_config._NotProvided object>, use_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, update_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, exploration_config: dict | None = <ray.rllib.utils.from_config._NotProvided object>, sample_collector: ~typing.Type[~ray.rllib.evaluation.collectors.sample_collector.SampleCollector] | None = <ray.rllib.utils.from_config._NotProvided object>, remote_worker_envs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, remote_env_batch_wait_ms: float | None = <ray.rllib.utils.from_config._NotProvided object>, preprocessor_pref: str | None = <ray.rllib.utils.from_config._NotProvided object>, observation_filter: str | None = <ray.rllib.utils.from_config._NotProvided object>, enable_tf1_exec_eagerly: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sampler_perf_stats_ema_coef: float | None = <ray.rllib.utils.from_config._NotProvided object>, num_rollout_workers=-1, num_envs_per_worker=-1, validate_workers_after_construction=-1, ignore_worker_failures=-1, recreate_failed_workers=-1, restart_failed_sub_environments=-1, num_consecutive_worker_failures_tolerance=-1, worker_health_probe_timeout_s=-1, worker_restore_timeout_s=-1, synchronize_filter=-1, enable_connectors=-1) \u2192 AlgorithmConfig[source]\nSets the rollout worker configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring LearnerGroup and Learner actors#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring LearnerGroup and Learner actors#\n\n\nAlgorithmConfig.learners(*, num_learners: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_learner: str | float | int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_learner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, num_aggregator_actors_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_aggregator_actor: float | None = <ray.rllib.utils.from_config._NotProvided object>, local_gpu_idx: int | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>)[source]\nSets LearnerGroup and Learner worker related configurations.\n\nParameters:\n\nnum_learners \u2013 Number of Learner workers used for updating the RLModule.\nA value of 0 means training takes place on a local Learner on main\nprocess CPUs or 1 GPU (determined by num_gpus_per_learner).\nFor multi-gpu training, you have to set num_learners to > 1 and set\nnum_gpus_per_learner accordingly (e.g., 4 GPUs total and model fits on\n1 GPU: num_learners=4; num_gpus_per_learner=1 OR 4 GPUs total and\nmodel requires 2 GPUs: num_learners=2; num_gpus_per_learner=2).\nnum_cpus_per_learner \u2013 Number of CPUs allocated per Learner worker.\nIf \u201cauto\u201d (default), use 1 if num_gpus_per_learner=0, otherwise 0.\nOnly necessary for custom processing pipeline inside each Learner\nrequiring multiple CPU cores.\nIf num_learners=0, RLlib creates only one local Learner instance and\nthe number of CPUs on the main process is\nmax(num_cpus_per_learner, num_cpus_for_main_process).\nnum_gpus_per_learner \u2013 Number of GPUs allocated per Learner worker. If\nnum_learners=0, any value greater than 0 runs the\ntraining on a single GPU on the main process, while a value of 0 runs\nthe training on main process CPUs.\nnum_aggregator_actors_per_learner \u2013 The number of aggregator actors per\nLearner (if num_learners=0, one local learner is created). Must be at\nleast 1. Aggregator actors perform the task of a) converting episodes\ninto a train batch and b) move that train batch to the same GPU that\nthe corresponding learner is located on. Good values are 1 or 2, but\nthis strongly depends on your setup and EnvRunner throughput.\nmax_requests_in_flight_per_aggregator_actor \u2013 How many in-flight requests\nare allowed per aggregator actor before new requests are dropped?\nlocal_gpu_idx \u2013 If num_gpus_per_learner > 0, and\nnum_learners < 2, then RLlib uses this GPU index for training. This is\nan index into the available\nCUDA devices. For example if os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nand local_gpu_idx=0, RLlib uses the GPU with ID=1 on the node.\nmax_requests_in_flight_per_learner \u2013 Max number of in-flight requests\nto each Learner (actor). You normally do not have to tune this setting\n(default is 3), however, for asynchronous algorithms, this determines\nthe \u201cqueue\u201d size for incoming batches (or lists of episodes) into each\nLearner worker, thus also determining, how much off-policy\u2019ness would be\nacceptable. The off-policy\u2019ness is the difference between the numbers of\nupdates a policy has undergone on the Learner vs the EnvRunners.\nSee the ray.rllib.utils.actor_manager.FaultTolerantActorManager class\nfor more details.\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring custom callbacks#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Returns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring offline RL specific settings#\n\n\nAlgorithmConfig.offline_data(*, input_: str | ~typing.Callable[[~ray.rllib.offline.io_context.IOContext], ~ray.rllib.offline.input_reader.InputReader] | None = <ray.rllib.utils.from_config._NotProvided object>, offline_data_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_method: str | ~typing.Callable | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_method_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_schema: ~typing.Dict[str, str] | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_episodes: bool | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_sample_batches: bool | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_batch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, input_filesystem: str | None = <ray.rllib.utils.from_config._NotProvided object>, input_filesystem_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, input_compress_columns: ~typing.List[str] | None = <ray.rllib.utils.from_config._NotProvided object>, materialize_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, materialize_mapped_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, map_batches_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, iter_batches_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, ignore_final_observation: bool | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_buffer_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_buffer_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_module_synch_period: int | None = <ray.rllib.utils.from_config._NotProvided object>, dataset_num_iters_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, input_config: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, actions_in_input_normalized: bool | None = <ray.rllib.utils.from_config._NotProvided object>, postprocess_inputs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, shuffle_buffer_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, output: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_config: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_compress_columns: ~typing.List[str] | None = <ray.rllib.utils.from_config._NotProvided object>, output_max_file_size: float | None = <ray.rllib.utils.from_config._NotProvided object>, output_max_rows_per_file: int | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_remaining_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_method: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_method_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_filesystem: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_filesystem_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_episodes: bool | None = <ray.rllib.utils.from_config._NotProvided object>, offline_sampling: str | None = <ray.rllib.utils.from_config._NotProvided object>) \u2192 AlgorithmConfig[source]\nSets the config\u2019s offline data settings.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring evaluation settings#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring evaluation settings#\n\n\nAlgorithmConfig.evaluation(*, evaluation_interval: int | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_duration: int | str | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_duration_unit: str | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_auto_duration_min_env_steps_per_sample: int | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_auto_duration_max_env_steps_per_sample: int | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_sample_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_parallel_to_training: bool | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_force_reset_envs_before_iteration: bool | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_config: ~ray.rllib.algorithms.algorithm_config.AlgorithmConfig | dict | None = <ray.rllib.utils.from_config._NotProvided object>, off_policy_estimation_methods: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, ope_split_batch_by_episode: bool | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_num_env_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_evaluation_function: ~typing.Callable | None = <ray.rllib.utils.from_config._NotProvided object>, offline_evaluation_interval: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_offline_eval_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, offline_loss_for_module_fn: ~typing.Callable | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_batch_size_per_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, dataset_num_iters_per_offline_eval_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_rl_module_inference_only: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_offline_eval_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_resources_per_offline_eval_runner: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, offline_evaluation_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_offline_eval_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, broadcast_offline_eval_runner_states: bool | None = <ray.rllib.utils.from_config._NotProvided object>, validate_offline_eval_runners_after_construction: bool | None = <ray.rllib.utils.from_config._NotProvided object>, restart_failed_offline_eval_runners: bool | None = <ray.rllib.utils.from_config._NotProvided object>, ignore_offline_eval_runner_failures: bool | None = <ray.rllib.utils.from_config._NotProvided object>, max_num_offline_eval_runner_restarts: int | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_runner_health_probe_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_runner_restore_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, always_attach_evaluation_results=-1, evaluation_num_workers=-1) \u2192 AlgorithmConfig[source]\nSets the config\u2019s evaluation settings.\n\nParameters:': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Returns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring training behavior#\n\n\nAlgorithmConfig.training(*, gamma: float | None = <ray.rllib.utils.from_config._NotProvided object>, lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip: float | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip_by: str | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, train_batch_size_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_epochs: int | None = <ray.rllib.utils.from_config._NotProvided object>, minibatch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, shuffle_batch_per_epoch: bool | None = <ray.rllib.utils.from_config._NotProvided object>, model: dict | None = <ray.rllib.utils.from_config._NotProvided object>, optimizer: dict | None = <ray.rllib.utils.from_config._NotProvided object>, learner_class: ~typing.Type[Learner] | None = <ray.rllib.utils.from_config._NotProvided object>, learner_connector: ~typing.Callable[[RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_learner_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, learner_config_dict: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, num_aggregator_actors_per_learner=-1, max_requests_in_flight_per_aggregator_actor=-1, num_sgd_iter=-1, max_requests_in_flight_per_sampler_worker=-1) \u2192 AlgorithmConfig[source]\nSets the training related configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring EnvRunnerGroup and EnvRunner actors#\n\n\nAlgorithmConfig.env_runners(*, env_runner_cls: type | None = <ray.rllib.utils.from_config._NotProvided object>, num_env_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, create_local_env_runner: bool | None = <ray.rllib.utils.from_config._NotProvided object>, create_env_on_local_worker: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_envs_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, gym_env_vectorize_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_env_runner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_resources_per_env_runner: dict | None = <ray.rllib.utils.from_config._NotProvided object>, validate_env_runners_after_construction: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sample_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, env_to_module_connector: ~typing.Callable[[~typing.Any | gymnasium.Env], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, module_to_env_connector: ~typing.Callable[[~typing.Any | gymnasium.Env, RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_env_to_module_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_module_to_env_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episode_lookback_horizon: int | None = <ray.rllib.utils.from_config._NotProvided object>, merge_env_runner_states: str | bool | None = <ray.rllib.utils.from_config._NotProvided object>, broadcast_env_runner_states: bool | None = <ray.rllib.utils.from_config._NotProvided object>, compress_observations: bool | None = <ray.rllib.utils.from_config._NotProvided object>, rollout_fragment_length: int | str | None = <ray.rllib.utils.from_config._NotProvided object>, batch_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, explore: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episodes_to_numpy: bool | None = <ray.rllib.utils.from_config._NotProvided object>, use_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, update_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, exploration_config: dict | None = <ray.rllib.utils.from_config._NotProvided object>, sample_collector: ~typing.Type[~ray.rllib.evaluation.collectors.sample_collector.SampleCollector] | None = <ray.rllib.utils.from_config._NotProvided object>, remote_worker_envs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, remote_env_batch_wait_ms: float | None = <ray.rllib.utils.from_config._NotProvided object>, preprocessor_pref: str | None = <ray.rllib.utils.from_config._NotProvided object>, observation_filter: str | None = <ray.rllib.utils.from_config._NotProvided object>, enable_tf1_exec_eagerly: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sampler_perf_stats_ema_coef: float | None = <ray.rllib.utils.from_config._NotProvided object>, num_rollout_workers=-1, num_envs_per_worker=-1, validate_workers_after_construction=-1, ignore_worker_failures=-1, recreate_failed_workers=-1, restart_failed_sub_environments=-1, num_consecutive_worker_failures_tolerance=-1, worker_health_probe_timeout_s=-1, worker_restore_timeout_s=-1, synchronize_filter=-1, enable_connectors=-1) \u2192 AlgorithmConfig[source]\nSets the rollout worker configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring LearnerGroup and Learner actors#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring LearnerGroup and Learner actors#\n\n\nAlgorithmConfig.learners(*, num_learners: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_learner: str | float | int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_learner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, num_aggregator_actors_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_aggregator_actor: float | None = <ray.rllib.utils.from_config._NotProvided object>, local_gpu_idx: int | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>)[source]\nSets LearnerGroup and Learner worker related configurations.\n\nParameters:\n\nnum_learners \u2013 Number of Learner workers used for updating the RLModule.\nA value of 0 means training takes place on a local Learner on main\nprocess CPUs or 1 GPU (determined by num_gpus_per_learner).\nFor multi-gpu training, you have to set num_learners to > 1 and set\nnum_gpus_per_learner accordingly (e.g., 4 GPUs total and model fits on\n1 GPU: num_learners=4; num_gpus_per_learner=1 OR 4 GPUs total and\nmodel requires 2 GPUs: num_learners=2; num_gpus_per_learner=2).\nnum_cpus_per_learner \u2013 Number of CPUs allocated per Learner worker.\nIf \u201cauto\u201d (default), use 1 if num_gpus_per_learner=0, otherwise 0.\nOnly necessary for custom processing pipeline inside each Learner\nrequiring multiple CPU cores.\nIf num_learners=0, RLlib creates only one local Learner instance and\nthe number of CPUs on the main process is\nmax(num_cpus_per_learner, num_cpus_for_main_process).\nnum_gpus_per_learner \u2013 Number of GPUs allocated per Learner worker. If\nnum_learners=0, any value greater than 0 runs the\ntraining on a single GPU on the main process, while a value of 0 runs\nthe training on main process CPUs.\nnum_aggregator_actors_per_learner \u2013 The number of aggregator actors per\nLearner (if num_learners=0, one local learner is created). Must be at\nleast 1. Aggregator actors perform the task of a) converting episodes\ninto a train batch and b) move that train batch to the same GPU that\nthe corresponding learner is located on. Good values are 1 or 2, but\nthis strongly depends on your setup and EnvRunner throughput.\nmax_requests_in_flight_per_aggregator_actor \u2013 How many in-flight requests\nare allowed per aggregator actor before new requests are dropped?\nlocal_gpu_idx \u2013 If num_gpus_per_learner > 0, and\nnum_learners < 2, then RLlib uses this GPU index for training. This is\nan index into the available\nCUDA devices. For example if os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nand local_gpu_idx=0, RLlib uses the GPU with ID=1 on the node.\nmax_requests_in_flight_per_learner \u2013 Max number of in-flight requests\nto each Learner (actor). You normally do not have to tune this setting\n(default is 3), however, for asynchronous algorithms, this determines\nthe \u201cqueue\u201d size for incoming batches (or lists of episodes) into each\nLearner worker, thus also determining, how much off-policy\u2019ness would be\nacceptable. The off-policy\u2019ness is the difference between the numbers of\nupdates a policy has undergone on the Learner vs the EnvRunners.\nSee the ray.rllib.utils.actor_manager.FaultTolerantActorManager class\nfor more details.\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring custom callbacks#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Returns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring offline RL specific settings#\n\n\nAlgorithmConfig.offline_data(*, input_: str | ~typing.Callable[[~ray.rllib.offline.io_context.IOContext], ~ray.rllib.offline.input_reader.InputReader] | None = <ray.rllib.utils.from_config._NotProvided object>, offline_data_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_method: str | ~typing.Callable | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_method_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_schema: ~typing.Dict[str, str] | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_episodes: bool | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_sample_batches: bool | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_batch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, input_filesystem: str | None = <ray.rllib.utils.from_config._NotProvided object>, input_filesystem_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, input_compress_columns: ~typing.List[str] | None = <ray.rllib.utils.from_config._NotProvided object>, materialize_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, materialize_mapped_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, map_batches_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, iter_batches_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, ignore_final_observation: bool | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_buffer_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_buffer_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_module_synch_period: int | None = <ray.rllib.utils.from_config._NotProvided object>, dataset_num_iters_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, input_config: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, actions_in_input_normalized: bool | None = <ray.rllib.utils.from_config._NotProvided object>, postprocess_inputs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, shuffle_buffer_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, output: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_config: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_compress_columns: ~typing.List[str] | None = <ray.rllib.utils.from_config._NotProvided object>, output_max_file_size: float | None = <ray.rllib.utils.from_config._NotProvided object>, output_max_rows_per_file: int | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_remaining_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_method: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_method_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_filesystem: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_filesystem_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_episodes: bool | None = <ray.rllib.utils.from_config._NotProvided object>, offline_sampling: str | None = <ray.rllib.utils.from_config._NotProvided object>) \u2192 AlgorithmConfig[source]\nSets the config\u2019s offline data settings.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring evaluation settings#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring evaluation settings#\n\n\nAlgorithmConfig.evaluation(*, evaluation_interval: int | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_duration: int | str | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_duration_unit: str | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_auto_duration_min_env_steps_per_sample: int | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_auto_duration_max_env_steps_per_sample: int | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_sample_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_parallel_to_training: bool | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_force_reset_envs_before_iteration: bool | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_config: ~ray.rllib.algorithms.algorithm_config.AlgorithmConfig | dict | None = <ray.rllib.utils.from_config._NotProvided object>, off_policy_estimation_methods: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, ope_split_batch_by_episode: bool | None = <ray.rllib.utils.from_config._NotProvided object>, evaluation_num_env_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_evaluation_function: ~typing.Callable | None = <ray.rllib.utils.from_config._NotProvided object>, offline_evaluation_interval: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_offline_eval_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, offline_loss_for_module_fn: ~typing.Callable | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_batch_size_per_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, dataset_num_iters_per_offline_eval_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_rl_module_inference_only: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_offline_eval_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_resources_per_offline_eval_runner: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, offline_evaluation_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_offline_eval_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, broadcast_offline_eval_runner_states: bool | None = <ray.rllib.utils.from_config._NotProvided object>, validate_offline_eval_runners_after_construction: bool | None = <ray.rllib.utils.from_config._NotProvided object>, restart_failed_offline_eval_runners: bool | None = <ray.rllib.utils.from_config._NotProvided object>, ignore_offline_eval_runner_failures: bool | None = <ray.rllib.utils.from_config._NotProvided object>, max_num_offline_eval_runner_restarts: int | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_runner_health_probe_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, offline_eval_runner_restore_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, always_attach_evaluation_results=-1, evaluation_num_workers=-1) \u2192 AlgorithmConfig[source]\nSets the config\u2019s evaluation settings.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring deep learning framework settings#': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\nConfiguring deep learning framework settings#\n\n\nAlgorithmConfig.framework(framework: str | None = <ray.rllib.utils.from_config._NotProvided object>, *, eager_tracing: bool | None = <ray.rllib.utils.from_config._NotProvided object>, eager_max_retraces: int | None = <ray.rllib.utils.from_config._NotProvided object>, tf_session_args: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, local_tf_session_args: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, torch_compile_learner: bool | None = <ray.rllib.utils.from_config._NotProvided object>, torch_compile_learner_what_to_compile: str | None = <ray.rllib.utils.from_config._NotProvided object>, torch_compile_learner_dynamo_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, torch_compile_learner_dynamo_backend: str | None = <ray.rllib.utils.from_config._NotProvided object>, torch_compile_worker: bool | None = <ray.rllib.utils.from_config._NotProvided object>, torch_compile_worker_dynamo_backend: str | None = <ray.rllib.utils.from_config._NotProvided object>, torch_compile_worker_dynamo_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, torch_ddp_kwargs: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, torch_skip_nan_gradients: bool | None = <ray.rllib.utils.from_config._NotProvided object>) \u2192 AlgorithmConfig[source]\nSets the config\u2019s DL framework settings.\n\nParameters:': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Environment variables used by Ray Tune#\nSome of Ray Tune\u2019s behavior can be configured using environment variables.\nThese are the environment variables Ray Tune currently considers:\n\nThere are some environment variables that are mostly relevant for integrated libraries:\n\nWANDB_API_KEY: Weights and Biases API key. You can also use wandb login\ninstead.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data#\n\n\nAlgorithmConfig.offline_data(*, input_: str | ~typing.Callable[[~ray.rllib.offline.io_context.IOContext], ~ray.rllib.offline.input_reader.InputReader] | None = <ray.rllib.utils.from_config._NotProvided object>, offline_data_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_method: str | ~typing.Callable | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_method_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_schema: ~typing.Dict[str, str] | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_episodes: bool | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_sample_batches: bool | None = <ray.rllib.utils.from_config._NotProvided object>, input_read_batch_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, input_filesystem: str | None = <ray.rllib.utils.from_config._NotProvided object>, input_filesystem_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, input_compress_columns: ~typing.List[str] | None = <ray.rllib.utils.from_config._NotProvided object>, materialize_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, materialize_mapped_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, map_batches_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, iter_batches_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, ignore_final_observation: bool | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_buffer_class: ~typing.Type | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_buffer_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, prelearner_module_synch_period: int | None = <ray.rllib.utils.from_config._NotProvided object>, dataset_num_iters_per_learner: int | None = <ray.rllib.utils.from_config._NotProvided object>, input_config: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, actions_in_input_normalized: bool | None = <ray.rllib.utils.from_config._NotProvided object>, postprocess_inputs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, shuffle_buffer_size: int | None = <ray.rllib.utils.from_config._NotProvided object>, output: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_config: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_compress_columns: ~typing.List[str] | None = <ray.rllib.utils.from_config._NotProvided object>, output_max_file_size: float | None = <ray.rllib.utils.from_config._NotProvided object>, output_max_rows_per_file: int | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_remaining_data: bool | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_method: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_method_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_filesystem: str | None = <ray.rllib.utils.from_config._NotProvided object>, output_filesystem_kwargs: ~typing.Dict | None = <ray.rllib.utils.from_config._NotProvided object>, output_write_episodes: bool | None = <ray.rllib.utils.from_config._NotProvided object>, offline_sampling: str | None = <ray.rllib.utils.from_config._NotProvided object>) \u2192 AlgorithmConfig[source]#\nSets the config\u2019s offline data settings.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Converting Datasets to other Python libraries#\n\nConverting Datasets to pandas#\nTo convert a Dataset to a pandas DataFrame, call\nDataset.to_pandas(). Your data must fit in memory\non the head node.\nimport ray\n\nds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")\n\ndf = ds.to_pandas()\nprint(df)\n\n\n     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n0                  5.1               3.5  ...               0.2       0\n1                  4.9               3.0  ...               0.2       0\n2                  4.7               3.2  ...               0.2       0\n3                  4.6               3.1  ...               0.2       0\n4                  5.0               3.6  ...               0.2       0\n..                 ...               ...  ...               ...     ...\n145                6.7               3.0  ...               2.3       2\n146                6.3               2.5  ...               1.9       2\n147                6.5               3.0  ...               2.0       2\n148                6.2               3.4  ...               2.3       2\n149                5.9               3.0  ...               1.8       2\n<BLANKLINE>\n[150 rows x 5 columns]\n\n\n\n\nConverting Datasets to distributed DataFrames#\nRay Data interoperates with distributed data processing frameworks like Daft,\nDask, Spark, Modin, and\nMars.\n\n\n\nDaft\nTo convert a Dataset to a Daft Dataframe, call\nDataset.to_daft().\nimport ray\n\nds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")\n\ndf = ds.to_daft()\n\n\n\n\n\nDask\nTo convert a Dataset to a\nDask DataFrame, call\nDataset.to_dask().\nimport ray\n\nds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")\n\ndf = ds.to_dask()\n\ndf\n\n(Showing first 8 of 150 rows)\n\n\n\n\n\nSpark\nTo convert a Dataset to a Spark DataFrame,\ncall Dataset.to_spark().\nimport ray\nimport raydp\n\nspark = raydp.init_spark(\n    app_name = \"example\",\n    num_executors = 1,\n    executor_cores = 4,\n    executor_memory = \"512M\"\n)\n\nds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")\ndf = ds.to_spark(spark)\n\n\n\n\n\nModin\nTo convert a Dataset to a Modin DataFrame, call\nDataset.to_modin().\nimport ray\n\nds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")\n\nmdf = ds.to_modin()\n\n\n\n\n\nMars\nTo convert a Dataset from a Mars DataFrame, call\nDataset.to_mars().\nimport ray\n\nds = ray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")\n\nmdf = ds.to_mars()': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'See also\nCheck out the KubeRay guide on GCS fault tolerance to learn more about how Serve leverages the external Redis cluster to provide head node fault tolerance.\n\n\n\n\nSpreading replicas across nodes#\nOne way to improve the availability of your Serve application is to spread deployment replicas across multiple nodes so that you still have enough running\nreplicas to serve traffic even after a certain number of node failures.\nBy default, Serve soft spreads all deployment replicas but it has a few limitations:\n\nThe spread is soft and best-effort with no guarantee that the it\u2019s perfectly even.\nServe tries to spread replicas among the existing nodes if possible instead of launching new nodes.\nFor example, if you have a big enough single node cluster, Serve schedules all replicas on that single node assuming\nit has enough resources. However, that node becomes the single point of failure.\n\nYou can change the spread behavior of your deployment with the max_replicas_per_node\ndeployment option, which hard limits the number of replicas of a given deployment that can run on a single node.\nIf you set it to 1 then you\u2019re effectively strict spreading the deployment replicas. If you don\u2019t set it then there\u2019s no hard spread constraint and Serve uses the default soft spread mentioned in the preceding paragraph. max_replicas_per_node option is per deployment and only affects the spread of replicas within a deployment. There\u2019s no spread between replicas of different deployments.\nThe following code example shows how to set max_replicas_per_node deployment option:\nimport ray\nfrom ray import serve\n\n@serve.deployment(max_replicas_per_node=1)\nclass Deployment1:\n  def __call__(self, request):\n    return \"hello\"\n\n@serve.deployment(max_replicas_per_node=2)\nclass Deployment2:\n  def __call__(self, request):\n    return \"world\"\n\n\nThis example has two Serve deployments with different max_replicas_per_node: Deployment1 can have at most one replica on each node and Deployment2 can have at most two replicas on each node. If you schedule two replicas of Deployment1 and two replicas of Deployment2, Serve runs a cluster with at least two nodes, each running one replica of Deployment1. The two replicas of Deployment2 may run on either a single node or across two nodes because either satisfies the max_replicas_per_node constraint.\n\n\n\nServe\u2019s recovery procedures#\nThis section explains how Serve recovers from system failures. It uses the following Serve application and config as a working example.\n\n\n\nPython Code\n# File name: sleepy_pid.py\n\nfrom ray import serve\n\n\n@serve.deployment\nclass SleepyPid:\n    def __init__(self):\n        import time\n\n        time.sleep(10)\n\n    def __call__(self) -> int:\n        import os\n\n        return os.getpid()\n\n\napp = SleepyPid.bind()\n\n\n\n\n\nKubernetes Config\n# File name: config.yaml\n\n\n\n\nFollow the KubeRay quickstart guide to:\n\nInstall kubectl and Helm\nPrepare a Kubernetes cluster\nDeploy a KubeRay operator\n\nThen, deploy the Serve application above:\n$ kubectl apply -f config.yaml\n\n\n\nWorker node failure#\nYou can simulate a worker node failure in the working example. First, take a look at the nodes and pods running in your Kubernetes cluster:\n$ kubectl get nodes\n\nNAME                                        STATUS   ROLES    AGE     VERSION\ngke-serve-demo-default-pool-ed597cce-nvm2   Ready    <none>   3d22h   v1.22.12-gke.1200\ngke-serve-demo-default-pool-ed597cce-m888   Ready    <none>   3d22h   v1.22.12-gke.1200\ngke-serve-demo-default-pool-ed597cce-pu2q   Ready    <none>   3d22h   v1.22.12-gke.1200\n\n$ kubectl get pods -o wide': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Resuming from checkpoint#\nIn the event of a failed job, you can use the latest checkpoint to resume training of the model. This example configures TorchTrainer to automatically resume\nfrom the latest checkpoint:\nexperiment_path = os.path.expanduser(\"/mnt/cluster_storage/finetune-resnet\")\nif TorchTrainer.can_restore(experiment_path):\n    trainer = TorchTrainer.restore(experiment_path,\n        train_loop_per_worker=train_loop_per_worker,\n        train_loop_config=train_loop_config,\n        scaling_config=scaling_config,\n        run_config=run_config,\n    )\nelse:\n    trainer = TorchTrainer(\n        train_loop_per_worker=train_loop_per_worker,\n        train_loop_config=train_loop_config,\n        scaling_config=scaling_config,\n        run_config=run_config,\n    )\n\n\nYou can verify automatic checkpoint recovery by redeploying the same RayJob:\nkubectl create -f ray-job.pytorch-image-classifier.yaml\n\n\nIf the previous job succeeded, the training job should restore the checkpoint state from the checkpoint_000009 directory\nand then immediately complete training with 0 iterations:\n2024-04-29 15:51:32,528 INFO experiment_state.py:366 -- Trying to find and download experiment checkpoint at /mnt/cluster_storage/finetune-resnet\n2024-04-29 15:51:32,651 INFO experiment_state.py:396 -- A remote experiment checkpoint was found and will be used to restore the previous experiment state.\n2024-04-29 15:51:32,652 INFO tune_controller.py:404 -- Using the newest experiment state file found within the experiment directory: experiment_state-2024-04-29_15-43-40.json\n\nView detailed results here: /mnt/cluster_storage/finetune-resnet\nTo visualize your results with TensorBoard, run: `tensorboard --logdir /home/ray/ray_results/finetune-resnet`\n\nResult(\n  metrics={'loss': 0.070047477101968, 'acc': 0.23529411764705882},\n  path='/mnt/cluster_storage/finetune-resnet/TorchTrainer_ecc04_00000_0_2024-04-29_15-43-40',\n  filesystem='local',\n  checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/finetune-resnet/TorchTrainer_ecc04_00000_0_2024-04-29_15-43-40/checkpoint_000009)\n)\n\nTraining finished iteration 8 at 2024-04-29 17:27:29. Total running time: 54s\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Training result                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 checkpoint_dir_name   checkpoint_000007 \u2502\n\u2502 time_this_iter_s               40.46113 \u2502\n\u2502 time_total_s                   95.00043 \u2502\n\u2502 training_iteration                    8 \u2502\n\u2502 acc                             0.23529 \u2502\n\u2502 loss                            0.08811 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTraining saved a checkpoint for iteration 8 at: (local)/mnt/cluster_storage/finetune-resnet/TorchTrainer_96923_00000_0_2024-04-29_17-21-29/checkpoint_000007\n(RayTrainWorker pid=671, ip=10.108.2.65) Epoch 8-train Loss: 0.0893 Acc: 0.2459\n(RayTrainWorker pid=671, ip=10.108.2.65) Epoch 8-val Loss: 0.0859 Acc: 0.2353\n(RayTrainWorker pid=589, ip=10.108.1.83) Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/finetune-resnet/TorchTrainer_96923_00000_0_2024-04-29_17-21-29/checkpoint_000008) [repeated 4x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Progress\n\n\nTrial name                date               done  episodes_total  experiment_id                   experiment_tag    hostname                iterations_since_restore   lossnode_ip    pid  time_since_restore  time_this_iter_s  time_total_s  timestamp  timesteps_since_restoretimesteps_total    training_iterationtrial_id     warmup_time\n\n\n\n\n2023-02-07 00:04:19,366\tINFO tune.py:798 -- Total run time: 7.38 seconds (6.85 seconds for the tuning loop).\n\n\n<ray.tune.result_grid.ResultGrid at 0x137de07c0>\n\n\n\n\nWhen the script executes, a grid-search is carried out and the results are saved to the Aim repo,\nstored at the default location \u2013 the experiment log directory (in this case, it\u2019s at /tmp/ray_results/aim_example).\n\nMore Configuration Options for Aim#\nIn the example above, we used the default configuration for the AimLoggerCallback.\nThere are a few options that can be configured as arguments to the callback. For example,\nsetting AimLoggerCallback(repo=\"/path/to/repo\") will log results to the Aim repo at that\nfilepath, which could be useful if you have a central location where the results of multiple\nTune experiments are stored. Relative paths to the working directory where Tune script is\nlaunched can be used as well. By default, the repo will be set to the experiment log\ndirectory. See the API reference for more configurations.\n\n\n\nLaunching the Aim UI#\nNow that we have logged our results to the Aim repository, we can view it in Aim\u2019s web UI.\nTo do this, we first find the directory where the Aim repository lives, then we use\nthe Aim CLI to launch the web interface.\n\n\n# Uncomment the following line to launch the Aim UI!\n#!aim up --repo=/tmp/ray_results/aim_example\n\n\n\n\n--------------------------------------------------------------------------\n                Aim UI collects anonymous usage analytics.                \n                        Read how to opt-out here:                         \n    https://aimstack.readthedocs.io/en/latest/community/telemetry.html    \n--------------------------------------------------------------------------\nRunning Aim UI on repo `<Repo#-5734997863388805469 path=/tmp/ray_results/aim_example/.aim read_only=None>`\nOpen http://127.0.0.1:43800\nPress Ctrl+C to exit\n^C\n\n\n\n\nAfter launching the Aim UI, we can open the web interface at localhost:43800.\n\nThe next sections contain more in-depth information on the API of the Tune-Aim integration.\n\n\nTune Aim Logger API#\n\n\nclass ray.tune.logger.aim.AimLoggerCallback(repo: str | None = None, experiment_name: str | None = None, metrics: List[str] | None = None, **aim_run_kwargs)[source]\nAim Logger: logs metrics in Aim format.\nAim is an open-source, self-hosted ML experiment tracking tool.\nIt\u2019s good at tracking lots (thousands) of training runs, and it allows you to\ncompare them with a performant and well-designed UI.\nSource: aimhubio/aim\n\nParameters:\n\nrepo \u2013 Aim repository directory or a Repo object that the Run object will\nlog results to. If not provided, a default repo will be set up in the\nexperiment directory (one level above trial directories).\nexperiment \u2013 Sets the experiment property of each Run object, which is the\nexperiment name associated with it. Can be used later to query\nruns/sequences.\nIf not provided, the default will be the Tune experiment name set\nby RunConfig(name=...).\nmetrics \u2013 List of metric names (out of the metrics reported by Tune) to\ntrack in Aim. If no metric are specified, log everything that\nis reported.\naim_run_kwargs \u2013 Additional arguments that will be passed when creating the\nindividual Run objects for each trial. For the full list of arguments,\nplease see the Aim documentation:\nhttps://aimstack.readthedocs.io/en/latest/refs/sdk.html': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\n\nSoft Actor Critic (SAC)#\n[original paper],\n[follow up paper],\n[implementation].\n\n\n\nSAC architecture: SAC uses a replay buffer to temporarily store episode samples that RLlib collects from the environment.\nThroughout different training iterations, these episodes and episode fragments are re-sampled from the buffer and re-used\nfor updating the model, before eventually being discarded when the buffer has reached capacity and new samples keep coming in (FIFO).\nThis reuse of training data makes DQN very sample-efficient and off-policy.\nSAC scales out on both axes, supporting multiple EnvRunners for sample collection and multiple GPU- or CPU-based Learners\nfor updating the model.#\n\n\nTuned examples:\nPendulum-v1,\nHalfCheetah-v3,\nSAC-specific configs (see also generic algorithm settings):\n\n\nclass ray.rllib.algorithms.sac.sac.SACConfig(algo_class=None)[source]#\nDefines a configuration class from which an SAC Algorithm can be built.\nconfig = (\n    SACConfig()\n    .environment(\"Pendulum-v1\")\n    .env_runners(num_env_runners=1)\n    .training(\n        gamma=0.9,\n        actor_lr=0.001,\n        critic_lr=0.002,\n        train_batch_size_per_learner=32,\n    )\n)\n# Build the SAC algo object from the config and run 1 training iteration.\nalgo = config.build()\nalgo.train()\n\n\n\n\ntraining(*, twin_q: bool | None = <ray.rllib.utils.from_config._NotProvided object>, q_model_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, policy_model_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, tau: float | None = <ray.rllib.utils.from_config._NotProvided object>, initial_alpha: float | None = <ray.rllib.utils.from_config._NotProvided object>, target_entropy: str | float | None = <ray.rllib.utils.from_config._NotProvided object>, n_step: int | ~typing.Tuple[int, int] | None = <ray.rllib.utils.from_config._NotProvided object>, store_buffer_in_checkpoints: bool | None = <ray.rllib.utils.from_config._NotProvided object>, replay_buffer_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, training_intensity: float | None = <ray.rllib.utils.from_config._NotProvided object>, clip_actions: bool | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip: float | None = <ray.rllib.utils.from_config._NotProvided object>, optimization_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, actor_lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, critic_lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, alpha_lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, target_network_update_freq: int | None = <ray.rllib.utils.from_config._NotProvided object>, _deterministic_loss: bool | None = <ray.rllib.utils.from_config._NotProvided object>, _use_beta_distribution: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_steps_sampled_before_learning_starts: int | None = <ray.rllib.utils.from_config._NotProvided object>, **kwargs) \u2192 SACConfig[source]#\nSets the training related configuration.\n\nParameters:': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\n\nSoft Actor Critic (SAC)#\n[original paper],\n[follow up paper],\n[implementation].\n\n\n\nSAC architecture: SAC uses a replay buffer to temporarily store episode samples that RLlib collects from the environment.\nThroughout different training iterations, these episodes and episode fragments are re-sampled from the buffer and re-used\nfor updating the model, before eventually being discarded when the buffer has reached capacity and new samples keep coming in (FIFO).\nThis reuse of training data makes DQN very sample-efficient and off-policy.\nSAC scales out on both axes, supporting multiple EnvRunners for sample collection and multiple GPU- or CPU-based Learners\nfor updating the model.#\n\n\nTuned examples:\nPendulum-v1,\nHalfCheetah-v3,\nSAC-specific configs (see also generic algorithm settings):\n\n\nclass ray.rllib.algorithms.sac.sac.SACConfig(algo_class=None)[source]#\nDefines a configuration class from which an SAC Algorithm can be built.\nconfig = (\n    SACConfig()\n    .environment(\"Pendulum-v1\")\n    .env_runners(num_env_runners=1)\n    .training(\n        gamma=0.9,\n        actor_lr=0.001,\n        critic_lr=0.002,\n        train_batch_size_per_learner=32,\n    )\n)\n# Build the SAC algo object from the config and run 1 training iteration.\nalgo = config.build()\nalgo.train()\n\n\n\n\ntraining(*, twin_q: bool | None = <ray.rllib.utils.from_config._NotProvided object>, q_model_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, policy_model_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, tau: float | None = <ray.rllib.utils.from_config._NotProvided object>, initial_alpha: float | None = <ray.rllib.utils.from_config._NotProvided object>, target_entropy: str | float | None = <ray.rllib.utils.from_config._NotProvided object>, n_step: int | ~typing.Tuple[int, int] | None = <ray.rllib.utils.from_config._NotProvided object>, store_buffer_in_checkpoints: bool | None = <ray.rllib.utils.from_config._NotProvided object>, replay_buffer_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, training_intensity: float | None = <ray.rllib.utils.from_config._NotProvided object>, clip_actions: bool | None = <ray.rllib.utils.from_config._NotProvided object>, grad_clip: float | None = <ray.rllib.utils.from_config._NotProvided object>, optimization_config: ~typing.Dict[str, ~typing.Any] | None = <ray.rllib.utils.from_config._NotProvided object>, actor_lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, critic_lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, alpha_lr: float | ~typing.List[~typing.List[int | float]] | ~typing.List[~typing.Tuple[int, int | float]] | None = <ray.rllib.utils.from_config._NotProvided object>, target_network_update_freq: int | None = <ray.rllib.utils.from_config._NotProvided object>, _deterministic_loss: bool | None = <ray.rllib.utils.from_config._NotProvided object>, _use_beta_distribution: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_steps_sampled_before_learning_starts: int | None = <ray.rllib.utils.from_config._NotProvided object>, **kwargs) \u2192 SACConfig[source]#\nSets the training related configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\n\n\nHigh-Throughput On- and Off-Policy#\n\nAsynchronous Proximal Policy Optimization (APPO)#\n\nTip\nAPPO was originally published under the name \u201cIMPACT\u201d. RLlib\u2019s APPO exactly matches the algorithm described in the paper.\n\n[paper]\n[implementation]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Parameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.\n\n\n\n\n\n\n\nHigh-Throughput On- and Off-Policy#\n\nAsynchronous Proximal Policy Optimization (APPO)#\n\nTip\nAPPO was originally published under the name \u201cIMPACT\u201d. RLlib\u2019s APPO exactly matches the algorithm described in the paper.\n\n[paper]\n[implementation]\n\n\n\nAPPO architecture: APPO is an asynchronous variant of Proximal Policy Optimization (PPO) based on the IMPALA architecture,\nbut using a surrogate policy loss with clipping, allowing for multiple SGD passes per collected train batch.\nIn a training iteration, APPO requests samples from all EnvRunners asynchronously and the collected episode\nsamples are returned to the main algorithm process as Ray references rather than actual objects available on the local process.\nAPPO then passes these episode references to the Learners for asynchronous updates of the model.\nRLlib doesn\u2019t always synch back the weights to the EnvRunners right after a new model version is available.\nTo account for the EnvRunners being off-policy, APPO uses a procedure called v-trace,\ndescribed in the IMPALA paper.\nAPPO scales out on both axes, supporting multiple EnvRunners for sample collection and multiple GPU- or CPU-based Learners\nfor updating the model.#\n\n\nTuned examples:\nPong-v5\nHalfCheetah-v4\nAPPO-specific configs (see also generic algorithm settings):\n\n\nclass ray.rllib.algorithms.appo.appo.APPOConfig(algo_class=None)[source]#\nDefines a configuration class from which an APPO Algorithm can be built.\nfrom ray.rllib.algorithms.appo import APPOConfig\nconfig = (\n    APPOConfig()\n    .training(lr=0.01, grad_clip=30.0, train_batch_size_per_learner=50)\n)\nconfig = config.learners(num_learners=1)\nconfig = config.env_runners(num_env_runners=1)\nconfig = config.environment(\"CartPole-v1\")\n\n# Build an Algorithm object from the config and run 1 training iteration.\nalgo = config.build()\nalgo.train()\ndel algo\n\n\nfrom ray.rllib.algorithms.appo import APPOConfig\nfrom ray import tune\n\nconfig = APPOConfig()\n# Update the config object.\nconfig = config.training(lr=tune.grid_search([0.001,]))\n# Set the config object's env.\nconfig = config.environment(env=\"CartPole-v1\")\n# Use to_dict() to get the old-style python config dict when running with tune.\ntune.Tuner(\n    \"APPO\",\n    run_config=tune.RunConfig(\n        stop={\"training_iteration\": 1},\n        verbose=0,\n    ),\n    param_space=config.to_dict(),\n\n).fit()\n\n\n\n\ntraining(*, vtrace: bool | None = <ray.rllib.utils.from_config._NotProvided object>, use_gae: bool | None = <ray.rllib.utils.from_config._NotProvided object>, lambda_: float | None = <ray.rllib.utils.from_config._NotProvided object>, clip_param: float | None = <ray.rllib.utils.from_config._NotProvided object>, use_kl_loss: bool | None = <ray.rllib.utils.from_config._NotProvided object>, kl_coeff: float | None = <ray.rllib.utils.from_config._NotProvided object>, kl_target: float | None = <ray.rllib.utils.from_config._NotProvided object>, target_network_update_freq: int | None = <ray.rllib.utils.from_config._NotProvided object>, tau: float | None = <ray.rllib.utils.from_config._NotProvided object>, target_worker_clipping: float | None = <ray.rllib.utils.from_config._NotProvided object>, circular_buffer_num_batches: int | None = <ray.rllib.utils.from_config._NotProvided object>, circular_buffer_iterations_per_batch: int | None = <ray.rllib.utils.from_config._NotProvided object>, target_update_frequency=-1, use_critic=-1, **kwargs) \u2192 APPOConfig[source]#\nSets the training related configuration.\n\nParameters:': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '# [Actors] will raise `RuntimeEnvSetupError`.\na = A.options(runtime_env=bad_env).remote()\ntry:\n  ray.get(a.f.remote())\nexcept ray.exceptions.RuntimeEnvSetupError:\n  print(\"Actor fails with RuntimeEnvSetupError\")\n\n\nTask fails with RuntimeEnvSetupError\nActor fails with RuntimeEnvSetupError\n\n\nFull logs can always be found in the file runtime_env_setup-[job_id].log for per-actor, per-task and per-job environments, or in\nruntime_env_setup-ray_client_server_[port].log for per-job environments when using Ray Client.\nYou can also enable runtime_env debugging log streaming by setting an environment variable RAY_RUNTIME_ENV_LOG_TO_DRIVER_ENABLED=1 on each node before starting Ray, for example using setup_commands in the Ray Cluster configuration file (reference).\nThis will print the full runtime_env setup log messages to the driver (the script that calls ray.init()).\nExample log output:\nray.init(runtime_env={\"pip\": [\"requests\"]})\n\n\nSee Logging Directory Structure for more details.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'tuner = tune.Tuner(\n    objective,\n    tune_config=tune.TuneConfig(\n        metric=\"mean_loss\",\n        mode=\"min\",\n        search_alg=algo,\n        num_samples=num_samples,\n    ),\n    param_space=search_space,\n)\nresults = tuner.fit()\n\n\n\n\n\n\n\n== Status ==Current time: 2022-07-22 15:30:53 (running for 00:00:43.91)Memory usage on this node: 10.4/16.0 GiBUsing FIFO scheduling algorithm.Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.47 GiB heap, 0.0/2.0 GiB objectsCurrent best trial: d42ac71c with mean_loss=-9.536507956046009 and parameters={'steps': 100, 'width': 19.398197043239886, 'height': -95.88310114083951}Result logdir: /Users/kai/ray_results/objective_2022-07-22_15-30-08Number of trials: 10/10 (10 TERMINATED)\n\nTrial name        status    loc              height   width    loss  iter  total time (s)  iterations  neg_mean_loss\n\n\nobjective_c9daa5d4TERMINATED127.0.0.1:46960-25.092 19.0143 -2.45636   100         10.9865          99        2.45636\nobjective_cb9bc830TERMINATED127.0.0.1:46968 46.398811.9732  4.72354   100         11.5661          99       -4.72354\nobjective_cb9d338cTERMINATED127.0.0.1:46969-68.7963 3.11989-6.56602   100         11.648           99        6.56602\nobjective_cb9e97e0TERMINATED127.0.0.1:46970-88.383317.3235 -8.78036   100         11.6948          99        8.78036\nobjective_d229961eTERMINATED127.0.0.1:47009 20.223 14.1615  2.09312   100         10.8549          99       -2.09312\nobjective_d42ac71cTERMINATED127.0.0.1:47036-95.883119.3982 -9.53651   100         10.7931          99        9.53651\nobjective_d43ca61cTERMINATED127.0.0.1:47039 66.4885 4.24678 6.88118   100         10.7606          99       -6.88118\nobjective_d43fb190TERMINATED127.0.0.1:47040-63.635  3.66809-6.09551   100         10.7997          99        6.09551\nobjective_da1ff46cTERMINATED127.0.0.1:47057-39.151610.4951 -3.81983   100         10.7762          99        3.81983\nobjective_dc25c796TERMINATED127.0.0.1:47062-13.611  5.82458-1.19064   100         10.7213          99        1.19064\n\n\n\n\nHere are the hyperparamters found to minimize the mean loss of the defined objective.\n\n\nprint(\"Best hyperparameters found were: \", results.get_best_result().config)\n\n\n\n\nBest hyperparameters found were:  {'steps': 100, 'width': 19.398197043239886, 'height': -95.88310114083951}': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Global configuration#\n\n\nclass ray.data.DataContext(target_max_block_size: int = 134217728, target_shuffle_max_block_size: int = 1073741824, target_min_block_size: int = 1048576, streaming_read_buffer_size: int = 33554432, enable_pandas_block: bool = True, actor_prefetcher_enabled: bool = False, use_push_based_shuffle: bool = False, _shuffle_strategy: ~ray.data.context.ShuffleStrategy = ShuffleStrategy.SORT_SHUFFLE_PULL_BASED, pipeline_push_based_shuffle_reduce_tasks: bool = True, max_hash_shuffle_aggregators: int | None = 64, max_hash_shuffle_finalization_batch_size: int | None = None, join_operator_actor_num_cpus_per_partition_override: float = None, hash_shuffle_operator_actor_num_cpus_per_partition_override: float = None, hash_aggregate_operator_actor_num_cpus_per_partition_override: float = None, scheduling_strategy: None | str | ~ray.util.scheduling_strategies.PlacementGroupSchedulingStrategy | ~ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy | ~ray.util.scheduling_strategies.NodeLabelSchedulingStrategy = 'SPREAD', scheduling_strategy_large_args: None | str | ~ray.util.scheduling_strategies.PlacementGroupSchedulingStrategy | ~ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy | ~ray.util.scheduling_strategies.NodeLabelSchedulingStrategy = 'DEFAULT', large_args_threshold: int = 52428800, use_polars: bool = False, eager_free: bool = True, decoding_size_estimation: bool = True, min_parallelism: int = 200, read_op_min_num_blocks: int = 200, enable_tensor_extension_casting: bool = True, use_arrow_tensor_v2: bool = True, enable_fallback_to_arrow_object_ext_type: bool | None = None, enable_auto_log_stats: bool = False, verbose_stats_logs: bool = False, trace_allocations: bool = False, execution_options: ExecutionOptions = <factory>, use_ray_tqdm: bool = True, enable_progress_bars: bool = True, enable_operator_progress_bars: bool = True, enable_progress_bar_name_truncation: bool = True, enable_get_object_locations_for_metrics: bool = False, write_file_retry_on_errors: ~typing.List[str] = ('AWS Error INTERNAL_FAILURE', 'AWS Error NETWORK_CONNECTION', 'AWS Error SLOW_DOWN', 'AWS Error UNKNOWN (HTTP status 503)'), warn_on_driver_memory_usage_bytes: int = 2147483648, actor_task_retry_on_errors: bool | ~typing.List[BaseException] = False, op_resource_reservation_enabled: bool = True, op_resource_reservation_ratio: float = 0.5, max_errored_blocks: int = 0, log_internal_stack_trace_to_stdout: bool = False, raise_original_map_exception: bool = False, print_on_execution_start: bool = True, s3_try_create_dir: bool = False, wait_for_min_actors_s: int = 600, retried_io_errors: ~typing.List[str] = <factory>, enable_per_node_metrics: bool = False, override_object_store_memory_limit_fraction: float = None, memory_usage_poll_interval_s: float | None = 1, dataset_logger_id: str | None = None)[source]#\nGlobal settings for Ray Data.\nConfigure this class to enable advanced features and tune performance.\n\nWarning\nApply changes before creating a Dataset. Changes made after\nwon\u2019t take effect.\n\n\nNote\nThis object is automatically propagated to workers. Access it from the driver\nand remote workers with DataContext.get_current().\n\nExamples\n>>> from ray.data import DataContext\n>>> DataContext.get_current().enable_progress_bars = False\n\n\n\nParameters:\n\n\n\nDeveloperAPI: This API may change across minor Ray releases.\n\n\n\nDataContext.get_current\nGet or create the current DataContext.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'tuner = tune.Tuner(\n    objective,\n    tune_config=tune.TuneConfig(\n        metric=\"mean_loss\",\n        mode=\"min\",\n        search_alg=algo,\n        num_samples=num_samples,\n    ),\n    param_space=search_config,\n)\nresults = tuner.fit()\n\n\n\n\nWARNING:ray.tune.trainable.function_trainable:\n\n\n== Status ==Current time: 2022-07-22 15:24:44 (running for 00:00:43.69)Memory usage on this node: 10.4/16.0 GiBUsing FIFO scheduling algorithm.Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.61 GiB heap, 0.0/2.0 GiB objectsCurrent best trial: 004f499a with mean_loss=-7.595329711238255 and parameters={'steps': 100, 'width': 2.1174116156230918, 'height': -90.50653873694615, 'activation': 'relu, tanh'}Result logdir: /Users/kai/ray_results/objective_2022-07-22_15-23-59Number of trials: 10/10 (10 TERMINATED)\n\nTrial name        status    loc            activation     height    width    loss  iter  total time (s)  iterations  neg_mean_loss\n\n\nobjective_ee2ca136TERMINATED127.0.0.1:46434relu, tanh    0      10        1.1       100         10.942           99       -1.1    \nobjective_efe1626eTERMINATED127.0.0.1:46441relu, tanh  -31.0013  9.28761 -1.99254   100         11.5354          99        1.99254\nobjective_efe34e4eTERMINATED127.0.0.1:46442relu, tanh    5.21403 9.48974  1.62672   100         11.6606          99       -1.62672\nobjective_efe55c2aTERMINATED127.0.0.1:46443relu, tanh  -20.8721 11.3958  -0.99935   100         11.6083          99        0.99935\nobjective_f6688086TERMINATED127.0.0.1:46467relu, tanh   57.2829 17.7296   6.78493   100         10.716           99       -6.78493\nobjective_f85ed926TERMINATED127.0.0.1:46478relu, tanh   40.5543 19.0813   5.10809   100         10.7158          99       -5.10809\nobjective_f86ee276TERMINATED127.0.0.1:46481relu, tanh   93.8686  1.60757 10.9781    100         10.7415          99      -10.9781 \nobjective_f880a02eTERMINATED127.0.0.1:46484relu, tanh  -80.5769  5.84852 -6.88791   100         10.7335          99        6.88791\nobjective_fe4e7a44TERMINATED127.0.0.1:46499relu, tanh    9.62911 0.622909 3.35823   100         13.1428          99       -3.35823\nobjective_004f499aTERMINATED127.0.0.1:46504relu, tanh  -90.5065  2.11741 -7.59533   100         10.7688          99        7.59533\n\nINFO:ray._private.runtime_env.plugin_schema_manager:Loading the default runtime env schemas: ['/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/working_dir_schema.json', '/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/pip_schema.json'].\n\n\nINFO:ray.tune.tune:Total run time: 44.70 seconds (43.68 seconds for the tuning loop).\n\n\n\n\nHere are the hyperparamters found to minimize the mean loss of the defined objective.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'tuner = tune.Tuner(\n    objective,\n    tune_config=tune.TuneConfig(\n        metric=\"mean_loss\",\n        mode=\"min\",\n        search_alg=algo,\n        num_samples=num_samples,\n    ),\n    param_space=search_config,\n)\nresults = tuner.fit()\n\n\n\n\nWARNING:ray.tune.trainable.function_trainable:\n\n\n== Status ==Current time: 2022-07-22 15:24:44 (running for 00:00:43.69)Memory usage on this node: 10.4/16.0 GiBUsing FIFO scheduling algorithm.Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.61 GiB heap, 0.0/2.0 GiB objectsCurrent best trial: 004f499a with mean_loss=-7.595329711238255 and parameters={'steps': 100, 'width': 2.1174116156230918, 'height': -90.50653873694615, 'activation': 'relu, tanh'}Result logdir: /Users/kai/ray_results/objective_2022-07-22_15-23-59Number of trials: 10/10 (10 TERMINATED)\n\nTrial name        status    loc            activation     height    width    loss  iter  total time (s)  iterations  neg_mean_loss\n\n\nobjective_ee2ca136TERMINATED127.0.0.1:46434relu, tanh    0      10        1.1       100         10.942           99       -1.1    \nobjective_efe1626eTERMINATED127.0.0.1:46441relu, tanh  -31.0013  9.28761 -1.99254   100         11.5354          99        1.99254\nobjective_efe34e4eTERMINATED127.0.0.1:46442relu, tanh    5.21403 9.48974  1.62672   100         11.6606          99       -1.62672\nobjective_efe55c2aTERMINATED127.0.0.1:46443relu, tanh  -20.8721 11.3958  -0.99935   100         11.6083          99        0.99935\nobjective_f6688086TERMINATED127.0.0.1:46467relu, tanh   57.2829 17.7296   6.78493   100         10.716           99       -6.78493\nobjective_f85ed926TERMINATED127.0.0.1:46478relu, tanh   40.5543 19.0813   5.10809   100         10.7158          99       -5.10809\nobjective_f86ee276TERMINATED127.0.0.1:46481relu, tanh   93.8686  1.60757 10.9781    100         10.7415          99      -10.9781 \nobjective_f880a02eTERMINATED127.0.0.1:46484relu, tanh  -80.5769  5.84852 -6.88791   100         10.7335          99        6.88791\nobjective_fe4e7a44TERMINATED127.0.0.1:46499relu, tanh    9.62911 0.622909 3.35823   100         13.1428          99       -3.35823\nobjective_004f499aTERMINATED127.0.0.1:46504relu, tanh  -90.5065  2.11741 -7.59533   100         10.7688          99        7.59533\n\nINFO:ray._private.runtime_env.plugin_schema_manager:Loading the default runtime env schemas: ['/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/working_dir_schema.json', '/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/pip_schema.json'].\n\n\nINFO:ray.tune.tune:Total run time: 44.70 seconds (43.68 seconds for the tuning loop).\n\n\n\n\nHere are the hyperparamters found to minimize the mean loss of the defined objective.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'tuner = tune.Tuner(\n    objective,\n    tune_config=tune.TuneConfig(\n        metric=\"mean_loss\",\n        mode=\"min\",\n        search_alg=algo,\n        num_samples=num_samples,\n    ),\n    param_space=search_config,\n)\nresults = tuner.fit()\n\n\n\n\nWARNING:ray.tune.trainable.function_trainable:\n\n\n== Status ==Current time: 2022-07-22 15:24:44 (running for 00:00:43.69)Memory usage on this node: 10.4/16.0 GiBUsing FIFO scheduling algorithm.Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.61 GiB heap, 0.0/2.0 GiB objectsCurrent best trial: 004f499a with mean_loss=-7.595329711238255 and parameters={'steps': 100, 'width': 2.1174116156230918, 'height': -90.50653873694615, 'activation': 'relu, tanh'}Result logdir: /Users/kai/ray_results/objective_2022-07-22_15-23-59Number of trials: 10/10 (10 TERMINATED)\n\nTrial name        status    loc            activation     height    width    loss  iter  total time (s)  iterations  neg_mean_loss\n\n\nobjective_ee2ca136TERMINATED127.0.0.1:46434relu, tanh    0      10        1.1       100         10.942           99       -1.1    \nobjective_efe1626eTERMINATED127.0.0.1:46441relu, tanh  -31.0013  9.28761 -1.99254   100         11.5354          99        1.99254\nobjective_efe34e4eTERMINATED127.0.0.1:46442relu, tanh    5.21403 9.48974  1.62672   100         11.6606          99       -1.62672\nobjective_efe55c2aTERMINATED127.0.0.1:46443relu, tanh  -20.8721 11.3958  -0.99935   100         11.6083          99        0.99935\nobjective_f6688086TERMINATED127.0.0.1:46467relu, tanh   57.2829 17.7296   6.78493   100         10.716           99       -6.78493\nobjective_f85ed926TERMINATED127.0.0.1:46478relu, tanh   40.5543 19.0813   5.10809   100         10.7158          99       -5.10809\nobjective_f86ee276TERMINATED127.0.0.1:46481relu, tanh   93.8686  1.60757 10.9781    100         10.7415          99      -10.9781 \nobjective_f880a02eTERMINATED127.0.0.1:46484relu, tanh  -80.5769  5.84852 -6.88791   100         10.7335          99        6.88791\nobjective_fe4e7a44TERMINATED127.0.0.1:46499relu, tanh    9.62911 0.622909 3.35823   100         13.1428          99       -3.35823\nobjective_004f499aTERMINATED127.0.0.1:46504relu, tanh  -90.5065  2.11741 -7.59533   100         10.7688          99        7.59533\n\nINFO:ray._private.runtime_env.plugin_schema_manager:Loading the default runtime env schemas: ['/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/working_dir_schema.json', '/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/pip_schema.json'].\n\n\nINFO:ray.tune.tune:Total run time: 44.70 seconds (43.68 seconds for the tuning loop).\n\n\n\n\nHere are the hyperparamters found to minimize the mean loss of the defined objective.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'tuner = tune.Tuner(\n    objective,\n    tune_config=tune.TuneConfig(\n        metric=\"mean_loss\",\n        mode=\"min\",\n        search_alg=algo,\n        num_samples=num_samples,\n    ),\n    param_space=search_config,\n)\nresults = tuner.fit()\n\n\n\n\nWARNING:ray.tune.trainable.function_trainable:\n\n\n== Status ==Current time: 2022-07-22 15:24:44 (running for 00:00:43.69)Memory usage on this node: 10.4/16.0 GiBUsing FIFO scheduling algorithm.Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.61 GiB heap, 0.0/2.0 GiB objectsCurrent best trial: 004f499a with mean_loss=-7.595329711238255 and parameters={'steps': 100, 'width': 2.1174116156230918, 'height': -90.50653873694615, 'activation': 'relu, tanh'}Result logdir: /Users/kai/ray_results/objective_2022-07-22_15-23-59Number of trials: 10/10 (10 TERMINATED)\n\nTrial name        status    loc            activation     height    width    loss  iter  total time (s)  iterations  neg_mean_loss\n\n\nobjective_ee2ca136TERMINATED127.0.0.1:46434relu, tanh    0      10        1.1       100         10.942           99       -1.1    \nobjective_efe1626eTERMINATED127.0.0.1:46441relu, tanh  -31.0013  9.28761 -1.99254   100         11.5354          99        1.99254\nobjective_efe34e4eTERMINATED127.0.0.1:46442relu, tanh    5.21403 9.48974  1.62672   100         11.6606          99       -1.62672\nobjective_efe55c2aTERMINATED127.0.0.1:46443relu, tanh  -20.8721 11.3958  -0.99935   100         11.6083          99        0.99935\nobjective_f6688086TERMINATED127.0.0.1:46467relu, tanh   57.2829 17.7296   6.78493   100         10.716           99       -6.78493\nobjective_f85ed926TERMINATED127.0.0.1:46478relu, tanh   40.5543 19.0813   5.10809   100         10.7158          99       -5.10809\nobjective_f86ee276TERMINATED127.0.0.1:46481relu, tanh   93.8686  1.60757 10.9781    100         10.7415          99      -10.9781 \nobjective_f880a02eTERMINATED127.0.0.1:46484relu, tanh  -80.5769  5.84852 -6.88791   100         10.7335          99        6.88791\nobjective_fe4e7a44TERMINATED127.0.0.1:46499relu, tanh    9.62911 0.622909 3.35823   100         13.1428          99       -3.35823\nobjective_004f499aTERMINATED127.0.0.1:46504relu, tanh  -90.5065  2.11741 -7.59533   100         10.7688          99        7.59533\n\nINFO:ray._private.runtime_env.plugin_schema_manager:Loading the default runtime env schemas: ['/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/working_dir_schema.json', '/Users/kai/coding/ray/python/ray/_private/runtime_env/../../runtime_env/schemas/pip_schema.json'].\n\n\nINFO:ray.tune.tune:Total run time: 44.70 seconds (43.68 seconds for the tuning loop).\n\n\n\n\nHere are the hyperparamters found to minimize the mean loss of the defined objective.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial name        status    loc            activation     height   width     loss  iter  total time (s)  iterations  neg_mean_loss\n\n\nobjective_085274beTERMINATED127.0.0.1:46516tanh          0      10       1.1        100         10.7324          99      -1.1     \nobjective_09dee4f2TERMINATED127.0.0.1:46524tanh        -44.4216 12.9653 -3.36485    100         11.3476          99       3.36485 \nobjective_09e0846aTERMINATED127.0.0.1:46525relu        -38.0638 11.1574  6.28334    100         11.3103          99      -6.28334 \nobjective_09e21122TERMINATED127.0.0.1:46526relu         41.2509  9.7558514.2276     100         11.3512          99     -14.2276  \nobjective_1045958eTERMINATED127.0.0.1:46544relu        -73.2818  5.78832 2.84334    100         10.7372          99      -2.84334 \nobjective_12309db2TERMINATED127.0.0.1:46549relu        -94.9666 16.9764  0.562486   100         10.7329          99      -0.562486\nobjective_12342770TERMINATED127.0.0.1:46550tanh        -98.0775 17.2252 -8.74945    100         10.7455          99       8.74945 \nobjective_12374d7eTERMINATED127.0.0.1:46551relu         -1.6075918.0841  9.89479    100         10.7348          99      -9.89479 \nobjective_18344524TERMINATED127.0.0.1:46569tanh        -41.1284 12.2952 -3.03135    100         12.622           99       3.03135 \nobjective_1a1e29b8TERMINATED127.0.0.1:46576tanh         64.0289 10.0482  7.50242    100         10.8237          99      -7.50242 \n\n\nINFO:ray.tune.tune:Total run time: 43.33 seconds (43.21 seconds for the tuning loop).\n\n\n\n\nHere are the hyperparamters found to minimize the mean loss of the defined objective. Note that we have to pass the metric and mode here because we don\u2019t set it in the TuneConfig.\n\n\nprint(\"Best hyperparameters found were: \", results.get_best_result(\"mean_loss\", \"min\").config)\n\n\n\n\nBest hyperparameters found were:  {'steps': 100, 'width': 17.225166732233465, 'height': -98.07750812064515, 'activation': 'tanh'}': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners#\n\n\nAlgorithmConfig.env_runners(*, env_runner_cls: type | None = <ray.rllib.utils.from_config._NotProvided object>, num_env_runners: int | None = <ray.rllib.utils.from_config._NotProvided object>, create_local_env_runner: bool | None = <ray.rllib.utils.from_config._NotProvided object>, create_env_on_local_worker: bool | None = <ray.rllib.utils.from_config._NotProvided object>, num_envs_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, gym_env_vectorize_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, num_cpus_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, num_gpus_per_env_runner: float | int | None = <ray.rllib.utils.from_config._NotProvided object>, custom_resources_per_env_runner: dict | None = <ray.rllib.utils.from_config._NotProvided object>, validate_env_runners_after_construction: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sample_timeout_s: float | None = <ray.rllib.utils.from_config._NotProvided object>, max_requests_in_flight_per_env_runner: int | None = <ray.rllib.utils.from_config._NotProvided object>, env_to_module_connector: ~typing.Callable[[~typing.Any | gymnasium.Env], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, module_to_env_connector: ~typing.Callable[[~typing.Any | gymnasium.Env, RLModule], ConnectorV2 | ~typing.List[ConnectorV2]] | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_env_to_module_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, add_default_connectors_to_module_to_env_pipeline: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episode_lookback_horizon: int | None = <ray.rllib.utils.from_config._NotProvided object>, merge_env_runner_states: str | bool | None = <ray.rllib.utils.from_config._NotProvided object>, broadcast_env_runner_states: bool | None = <ray.rllib.utils.from_config._NotProvided object>, compress_observations: bool | None = <ray.rllib.utils.from_config._NotProvided object>, rollout_fragment_length: int | str | None = <ray.rllib.utils.from_config._NotProvided object>, batch_mode: str | None = <ray.rllib.utils.from_config._NotProvided object>, explore: bool | None = <ray.rllib.utils.from_config._NotProvided object>, episodes_to_numpy: bool | None = <ray.rllib.utils.from_config._NotProvided object>, use_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, update_worker_filter_stats: bool | None = <ray.rllib.utils.from_config._NotProvided object>, exploration_config: dict | None = <ray.rllib.utils.from_config._NotProvided object>, sample_collector: ~typing.Type[~ray.rllib.evaluation.collectors.sample_collector.SampleCollector] | None = <ray.rllib.utils.from_config._NotProvided object>, remote_worker_envs: bool | None = <ray.rllib.utils.from_config._NotProvided object>, remote_env_batch_wait_ms: float | None = <ray.rllib.utils.from_config._NotProvided object>, preprocessor_pref: str | None = <ray.rllib.utils.from_config._NotProvided object>, observation_filter: str | None = <ray.rllib.utils.from_config._NotProvided object>, enable_tf1_exec_eagerly: bool | None = <ray.rllib.utils.from_config._NotProvided object>, sampler_perf_stats_ema_coef: float | None = <ray.rllib.utils.from_config._NotProvided object>, num_rollout_workers=-1, num_envs_per_worker=-1, validate_workers_after_construction=-1, ignore_worker_failures=-1, recreate_failed_workers=-1, restart_failed_sub_environments=-1, num_consecutive_worker_failures_tolerance=-1, worker_health_probe_timeout_s=-1, worker_restore_timeout_s=-1, synchronize_filter=-1, enable_connectors=-1) \u2192 AlgorithmConfig[source]#\nSets the rollout worker configuration.\n\nParameters:\n\n\nReturns:\nThis updated AlgorithmConfig object.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Example Response\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n\n\n\nGET \"/api/serve/applications/\"#\nGets cluster-level info and comprehensive details on all Serve applications deployed on the Ray cluster. See metadata schema for the response\u2019s JSON schema.\nGET /api/serve/applications/ HTTP/1.1\nHost: http://localhost:8265/\nAccept: application/json\n\n\nExample Response (abridged JSON):\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n\n\n\nDELETE \"/api/serve/applications/\"#\nShuts down Serve and all applications running on the Ray cluster. Has no effect if Serve is not running on the Ray cluster.\nExample Request:\nDELETE /api/serve/applications/ HTTP/1.1\nHost: http://localhost:8265/\nAccept: application/json\n\n\nExample Response\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n\n\n\n\nConfig Schemas#\n\n\nschema.ServeDeploySchema\nMulti-application config for deploying a list of Serve applications to the Ray cluster.\n\nschema.gRPCOptionsSchema\nOptions to start the gRPC Proxy with.\n\nschema.HTTPOptionsSchema\nOptions to start the HTTP Proxy with.\n\nschema.ServeApplicationSchema\nDescribes one Serve application, and currently can also be used as a standalone config to deploy a single application to a Ray cluster.\n\nschema.DeploymentSchema\nSpecifies options for one deployment within a Serve application.\n\nschema.RayActorOptionsSchema\nOptions with which to start a replica actor.\n\n\n\n\n\nResponse Schemas#\n\n\nschema.ServeInstanceDetails\nServe metadata with system-level info and details on all applications deployed to the Ray cluster.\n\nschema.APIType\nTracks the type of API that an application originates from.\n\nschema.ApplicationStatus\nThe current status of the application.\n\nschema.ApplicationDetails\nDetailed info about a Serve application.\n\nschema.DeploymentDetails\nDetailed info about a deployment within a Serve application.\n\nschema.ReplicaDetails\nDetailed info about a single deployment replica.\n\nschema.ProxyStatus\nThe current status of the proxy.\n\nschema.TargetGroup\nPublicAPI (alpha): This API is in alpha and may change before becoming stable.\n\nschema.Target\nPublicAPI (alpha): This API is in alpha and may change before becoming stable.\n\n\n\n\n\nObservability#\n\n\nmetrics.Counter\nA serve cumulative metric that is monotonically increasing.\n\nmetrics.Histogram\nTracks the size and number of events in buckets.\n\nmetrics.Gauge\nGauges keep the last recorded value and drop everything before.\n\nschema.LoggingConfig\nLogging config schema for configuring serve components logs.\n\n\n\n\n\nLLM API#\n\nBuilders#\n\n\nserve.llm.build_llm_deployment\nHelper to build a single vllm deployment from the given llm config.\n\nserve.llm.build_openai_app\nHelper to build an OpenAI compatible app with the llm deployment setup from the given llm serving args.\n\n\n\n\n\nConfigs#\n\n\nserve.llm.LLMConfig\nThe configuration for starting an LLM deployment.\n\nserve.llm.LLMServingArgs\nThe configuration for starting an LLM deployment application.\n\nserve.llm.ModelLoadingConfig\nThe configuration for loading an LLM model.\n\nserve.llm.CloudMirrorConfig\nThe configuration for mirroring an LLM model from cloud storage.\n\nserve.llm.LoraConfig\nThe configuration for loading an LLM model with LoRA.\n\n\n\n\n\nDeployments#\n\n\nserve.llm.LLMServer\nThe implementation of the vLLM engine deployment.\n\nserve.llm.LLMRouter\nThe implementation of the OpenAI compatiple model router.\n\n\n\n\n\nOpenAI API Models#\n\n\nserve.llm.openai_api_models.ChatCompletionRequest\nChatCompletionRequest is the request body for the chat completion API.\n\nserve.llm.openai_api_models.CompletionRequest\nCompletionRequest is the request body for the completion API.\n\nserve.llm.openai_api_models.ChatCompletionStreamResponse\nChatCompletionStreamResponse is the response body for the chat completion API.\n\nserve.llm.openai_api_models.ChatCompletionResponse\nChatCompletionResponse is the response body for the chat completion API.\n\nserve.llm.openai_api_models.CompletionStreamResponse\nCompletionStreamResponse is the response body for the completion API.\n\nserve.llm.openai_api_models.CompletionResponse\nCompletionResponse is the response body for the completion API.\n\nserve.llm.openai_api_models.ErrorResponse\nThe returned response in case of an error.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'For a complete list of available ray libraries on Conda-forge, have a look\nat https://anaconda.org/conda-forge/ray-default\n\nNote\nRay conda packages are maintained by the community, not the Ray team. While\nusing a conda environment, it is recommended to install Ray from PyPi using\npip install ray in the newly created environment.\n\n\n\nBuilding Ray from Source#\nInstalling from pip should be sufficient for most Ray users.\nHowever, should you need to build from source, follow these instructions for building Ray.\n\n\nDocker Source Images#\nUsers can pull a Docker image from the rayproject/ray Docker Hub repository.\nThe images include Ray and all required dependencies. It comes with anaconda and various versions of Python.\nImages are tagged with the format {Ray version}[-{Python version}][-{Platform}]. Ray version tag can be one of the following:\n\n\n\n\n\n\nRay version tag\nDescription\n\n\n\nlatest\nThe most recent Ray release.\n\nx.y.z\nA specific Ray release, e.g. 2.31.0\n\nnightly\nThe most recent Ray development build (a recent commit from Github master)\n\n\n\nThe optional Python version tag specifies the Python version in the image. All Python versions supported by Ray are available, e.g. py39, py310 and py311. If unspecified, the tag points to an image of the lowest Python version that the Ray version supports.\nThe optional Platform tag specifies the platform where the image is intended for:\n\n\n\n\n\n\nPlatform tag\nDescription\n\n\n\n-cpu\nThese are based off of an Ubuntu image.\n\n-cuXX\nThese are based off of an NVIDIA CUDA image with the specified CUDA version. They require the Nvidia Docker Runtime.\n\n-gpu\nAliases to a specific -cuXX tagged image.\n\n<no tag>\nAliases to -cpu tagged images.\n\n\n\nExample: for the nightly image based on Python 3.9 and without GPU support, the tag is nightly-py39-cpu.\nIf you want to tweak some aspects of these images and build them locally, refer to the following script:\ncd ray\n./build-docker.sh\n\n\nReview images by listing them:\ndocker images\n\n\nOutput should look something like the following:\nREPOSITORY                          TAG                 IMAGE ID            CREATED             SIZE\nrayproject/ray                      dev                 7243a11ac068        2 days ago          1.11 GB\nrayproject/base-deps                latest              5606591eeab9        8 days ago          512  MB\nubuntu                              22.04               1e4467b07108        3 weeks ago         73.9 MB\n\n\n\nLaunch Ray in Docker#\nStart out by launching the deployment container.\ndocker run --shm-size=<shm-size> -t -i rayproject/ray\n\n\nReplace <shm-size> with a limit appropriate for your system, for example\n512M or 2G. A good estimate for this is to use roughly 30% of your available memory (this is\nwhat Ray uses internally for its Object Store). The -t and -i options here are required to support\ninteractive use of the container.\nIf you use a GPU version Docker image, remember to add --gpus all option. Replace <ray-version> with your target ray version in the following command:\ndocker run --shm-size=<shm-size> -t -i --gpus all rayproject/ray:<ray-version>-gpu\n\n\nNote: Ray requires a large amount of shared memory because each object\nstore keeps all of its objects in shared memory, so the amount of shared memory\nwill limit the size of the object store.\nYou should now see a prompt that looks something like:\nroot@ebc78f68d100:/ray#\n\n\n\n\nTest if the installation succeeded#\nTo test if the installation was successful, try running some tests. This assumes\nthat you\u2019ve cloned the git repository.\npython -m pytest -v python/ray/tests/test_mini.py\n\n\n\n\nInstalled Python dependencies#\nOur docker images are shipped with pre-installed Python dependencies\nrequired for Ray and its libraries.\nWe publish the dependencies that are installed in our ray Docker images for Python 3.9.\n\n\n\n\n\n\n\n\n\nInstall Ray Java with Maven#\n\nNote\nAll Ray Java APIs are experimental and only supported by the community.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Installed Python dependencies#\nOur docker images are shipped with pre-installed Python dependencies\nrequired for Ray and its libraries.\nWe publish the dependencies that are installed in our ray Docker images for Python 3.9.\n\n\n\n\n\n\n\n\n\nInstall Ray Java with Maven#\n\nNote\nAll Ray Java APIs are experimental and only supported by the community.\n\nBefore installing Ray Java with Maven, you should install Ray Python with pip install -U ray . Note that the versions of Ray Java and Ray Python must match.\nNote that nightly Ray python wheels are also required if you want to install Ray Java snapshot version.\nFind the latest Ray Java release in the central repository. To use the latest Ray Java release in your application, add the following entries in your pom.xml:\n<dependency>\n  <groupId>io.ray</groupId>\n  <artifactId>ray-api</artifactId>\n  <version>${ray.version}</version>\n</dependency>\n<dependency>\n  <groupId>io.ray</groupId>\n  <artifactId>ray-runtime</artifactId>\n  <version>${ray.version}</version>\n</dependency>\n\n\nThe latest Ray Java snapshot can be found in sonatype repository. To use the latest Ray Java snapshot in your application, add the following entries in your pom.xml:\n<!-- only needed for snapshot version of ray -->\n<repositories>\n  <repository>\n    <id>sonatype</id>\n    <url>https://oss.sonatype.org/content/repositories/snapshots/</url>\n    <releases>\n      <enabled>false</enabled>\n    </releases>\n    <snapshots>\n      <enabled>true</enabled>\n    </snapshots>\n  </repository>\n</repositories>\n\n<dependencies>\n  <dependency>\n    <groupId>io.ray</groupId>\n    <artifactId>ray-api</artifactId>\n    <version>${ray.version}</version>\n  </dependency>\n  <dependency>\n    <groupId>io.ray</groupId>\n    <artifactId>ray-runtime</artifactId>\n    <version>${ray.version}</version>\n  </dependency>\n</dependencies>\n\n\n\nNote\nWhen you run pip install to install Ray, Java jars are installed as well. The above dependencies are only used to build your Java code and to run your code in local mode.\nIf you want to run your Java code in a multi-node Ray cluster, it\u2019s better to exclude Ray jars when packaging your code to avoid jar conflicts if the versions (installed Ray with pip install and maven dependencies) don\u2019t match.\n\n\n\nInstall Ray C++#\n\nNote\nAll Ray C++ APIs are experimental and only supported by the community.\n\nYou can install and use Ray C++ API as follows.\npip install -U ray[cpp]\n\n# Create a Ray C++ project template to start with.\nray cpp --generate-bazel-project-template-to ray-template\n\n\n\nNote\nIf you build Ray from source, remove the build option build --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" from the file cpp/example/.bazelrc before running your application. The related issue is this.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '[INFO 07-22 15:04:27] ax.service.ax_client: Completed trial 3 with data: {'landscape': (-0.011984, None), 'l2norm': (1.530347, None)}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Generated new trial 5 with parameters {'x1': 0.126064, 'x2': 0.703408, 'x3': 0.344681, 'x4': 0.337363, 'x5': 0.401396, 'x6': 0.679202, 'iterations': 100}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Completed trial 1 with data: {'landscape': (-0.11286, None), 'l2norm': (1.163407, None)}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Generated new trial 6 with parameters {'x1': 0.091094, 'x2': 0.304138, 'x3': 0.869848, 'x4': 0.405435, 'x5': 0.567922, 'x6': 0.228608, 'iterations': 100}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Completed trial 2 with data: {'landscape': (-0.11348, None), 'l2norm': (1.359954, None)}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Generated new trial 7 with parameters {'x1': 0.603178, 'x2': 0.409057, 'x3': 0.729056, 'x4': 0.082598, 'x5': 0.572948, 'x6': 0.508304, 'iterations': 100}.\n\n\n[INFO 07-22 15:04:30] ax.service.ax_client: Completed trial 4 with data: {'landscape': (-0.00678, None), 'l2norm': (1.80573, None)}.\n[INFO 07-22 15:04:30] ax.service.ax_client: Generated new trial 8 with parameters {'x1': 0.454189, 'x2': 0.271772, 'x3': 0.530871, 'x4': 0.991841, 'x5': 0.691843, 'x6': 0.472366, 'iterations': 100}.\n[INFO 07-22 15:04:30] ax.service.ax_client: Completed trial 5 with data: {'landscape': (-0.904622, None), 'l2norm': (1.168644, None)}.\n[INFO 07-22 15:04:30] ax.service.ax_client: Generated new trial 9 with parameters {'x1': 0.265264, 'x2': 0.924884, 'x3': 0.151716, 'x4': 0.436026, 'x5': 0.85731, 'x6': 0.08981, 'iterations': 100}.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '[INFO 07-22 15:04:27] ax.service.ax_client: Completed trial 3 with data: {'landscape': (-0.011984, None), 'l2norm': (1.530347, None)}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Generated new trial 5 with parameters {'x1': 0.126064, 'x2': 0.703408, 'x3': 0.344681, 'x4': 0.337363, 'x5': 0.401396, 'x6': 0.679202, 'iterations': 100}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Completed trial 1 with data: {'landscape': (-0.11286, None), 'l2norm': (1.163407, None)}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Generated new trial 6 with parameters {'x1': 0.091094, 'x2': 0.304138, 'x3': 0.869848, 'x4': 0.405435, 'x5': 0.567922, 'x6': 0.228608, 'iterations': 100}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Completed trial 2 with data: {'landscape': (-0.11348, None), 'l2norm': (1.359954, None)}.\n[INFO 07-22 15:04:27] ax.service.ax_client: Generated new trial 7 with parameters {'x1': 0.603178, 'x2': 0.409057, 'x3': 0.729056, 'x4': 0.082598, 'x5': 0.572948, 'x6': 0.508304, 'iterations': 100}.\n\n\n[INFO 07-22 15:04:30] ax.service.ax_client: Completed trial 4 with data: {'landscape': (-0.00678, None), 'l2norm': (1.80573, None)}.\n[INFO 07-22 15:04:30] ax.service.ax_client: Generated new trial 8 with parameters {'x1': 0.454189, 'x2': 0.271772, 'x3': 0.530871, 'x4': 0.991841, 'x5': 0.691843, 'x6': 0.472366, 'iterations': 100}.\n[INFO 07-22 15:04:30] ax.service.ax_client: Completed trial 5 with data: {'landscape': (-0.904622, None), 'l2norm': (1.168644, None)}.\n[INFO 07-22 15:04:30] ax.service.ax_client: Generated new trial 9 with parameters {'x1': 0.265264, 'x2': 0.924884, 'x3': 0.151716, 'x4': 0.436026, 'x5': 0.85731, 'x6': 0.08981, 'iterations': 100}.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Result for objective_313d3d3a:\n  date: 2022-07-22_15-04-30\n  done: true\n  experiment_id: fa7afd557e154fbebe4f54d8eedb3573\n  experiment_tag: 5_iterations=100,x1=0.0419,x2=0.9928,x3=0.9060,x4=0.5944,x5=0.8254,x6=0.6464\n  hostname: Kais-MacBook-Pro.local\n  iterations_since_restore: 100\n  l2norm: 1.805729990121368\n  landscape: -0.006779757704679272\n  node_ip: 127.0.0.1\n  pid: 44747\n  time_since_restore: 3.1623308658599854\n  time_this_iter_s: 0.02911996841430664\n  time_total_s: 3.1623308658599854\n  timestamp: 1658498670\n  timesteps_since_restore: 0\n  timesteps_total: 99\n  training_iteration: 100\n  trial_id: 313d3d3a\n  warmup_time: 0.0029790401458740234\n  \nResult for objective_32c9acd8:\n  date: 2022-07-22_15-04-30\n  done: true\n  experiment_id: c555bfed13ac43e5b8c8e9f6d4b9b2f7\n  experiment_tag: 6_iterations=100,x1=0.1261,x2=0.7034,x3=0.3447,x4=0.3374,x5=0.4014,x6=0.6792\n  hostname: Kais-MacBook-Pro.local\n  iterations_since_restore: 100\n  l2norm: 1.1686440476629836\n  landscape: -0.9046216637367911\n  node_ip: 127.0.0.1\n  pid: 44726\n  time_since_restore: 3.1211891174316406\n  time_this_iter_s: 0.02954697608947754\n  time_total_s: 3.1211891174316406\n  timestamp: 1658498670\n  timesteps_since_restore: 0\n  timesteps_total: 99\n  training_iteration: 100\n  trial_id: 32c9acd8\n  warmup_time: 0.0026290416717529297\n  \n\n\n[INFO 07-22 15:04:32] ax.service.ax_client: Completed trial 7 with data: {'landscape': (-0.247223, None), 'l2norm': (1.286911, None)}.\n[INFO 07-22 15:04:32] ax.service.ax_client: Completed trial 6 with data: {'landscape': (-0.146532, None), 'l2norm': (1.181781, None)}.\n\n\n[INFO 07-22 15:04:35] ax.service.ax_client: Completed trial 8 with data: {'landscape': (-0.013292, None), 'l2norm': (1.499166, None)}.\n[INFO 07-22 15:04:35] ax.service.ax_client: Completed trial 9 with data: {'landscape': (-1.662444, None), 'l2norm': (1.371845, None)}.': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpkvf1rrst/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88184) Extracting /tmp/tmppk4zrz1w/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmppk4zrz1w/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=88184)  [repeated 12x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpkvf1rrst/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88184) Extracting /tmp/tmppk4zrz1w/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmppk4zrz1w/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=88184)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=101545) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95492) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=95492) Extracting /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=95492)  [repeated 12x across cluster]\n\n\n  0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpkvf1rrst/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88184) Extracting /tmp/tmppk4zrz1w/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmppk4zrz1w/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=88184)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=101545) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95492) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=95492) Extracting /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=95492)  [repeated 12x across cluster]\n\n\n  0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]\n\n\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n\n\n(RayTrainWorker pid=108863) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Extracting /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw [repeated 8x across cluster]\n(RayTrainWorker pid=101546)  [repeated 12x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpkvf1rrst/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88184) Extracting /tmp/tmppk4zrz1w/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmppk4zrz1w/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=88184)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=101545) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95492) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=95492) Extracting /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=95492)  [repeated 12x across cluster]\n\n\n  0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]\n\n\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n\n\n(RayTrainWorker pid=108863) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Extracting /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw [repeated 8x across cluster]\n(RayTrainWorker pid=101546)  [repeated 12x across cluster]\n\n\n(autoscaler +11m23s) [workspace snapshot] New snapshot created successfully (Size: 327.01 KB)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpkvf1rrst/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88184) Extracting /tmp/tmppk4zrz1w/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmppk4zrz1w/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=88184)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=101545) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95492) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=95492) Extracting /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=95492)  [repeated 12x across cluster]\n\n\n  0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]\n\n\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n\n\n(RayTrainWorker pid=108863) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Extracting /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw [repeated 8x across cluster]\n(RayTrainWorker pid=101546)  [repeated 12x across cluster]\n\n\n(autoscaler +11m23s) [workspace snapshot] New snapshot created successfully (Size: 327.01 KB)\n\n\n(RayTrainWorker pid=111131) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=111131) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpddnnc0iv/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=108863) Extracting /tmp/tmpxcg0v86z/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxcg0v86z/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=108863)  [repeated 12x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpkvf1rrst/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88184) Extracting /tmp/tmppk4zrz1w/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmppk4zrz1w/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=88184)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=101545) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95492) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=95492) Extracting /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=95492)  [repeated 12x across cluster]\n\n\n  0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]\n\n\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n\n\n(RayTrainWorker pid=108863) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Extracting /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw [repeated 8x across cluster]\n(RayTrainWorker pid=101546)  [repeated 12x across cluster]\n\n\n(autoscaler +11m23s) [workspace snapshot] New snapshot created successfully (Size: 327.01 KB)\n\n\n(RayTrainWorker pid=111131) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=111131) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpddnnc0iv/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=108863) Extracting /tmp/tmpxcg0v86z/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxcg0v86z/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=108863)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=118364) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=118364) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmp0sbwiedt/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=111130) Extracting /tmp/tmpfmuq9_qh/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpfmuq9_qh/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=111130)  [repeated 12x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding 'Trial Status\n\n\nTrial name              status    loc                train_loop_config/ba\ntch_size    train_loop_config/la\nyer_1_size    train_loop_config/la\nyer_2_size  train_loop_config/lr  iter  total time (s)  ptl/train_loss  ptl/train_accuracy  ptl/val_loss\n\n\nTorchTrainer_5144b_00000TERMINATED10.0.0.84:63990 32 64256           0.0316233       5         29.3336      0.973613              0.766667     0.580943 \nTorchTrainer_5144b_00001TERMINATED10.0.0.84:71294 64128 64           0.0839278       1         12.2275      2.19514               0.266667     1.56644  \nTorchTrainer_5144b_00002TERMINATED10.0.0.84:73540 32 64256           0.000233034     5         29.1314      0.146903              0.933333     0.114229 \nTorchTrainer_5144b_00003TERMINATED10.0.0.84:80840 64128 64           0.00109259      5         21.6534      0.0474913             0.966667     0.0714878\nTorchTrainer_5144b_00004TERMINATED10.0.0.84:88077 32 32128           0.00114083      5         29.6367      0.0990443             0.966667     0.0891999\nTorchTrainer_5144b_00005TERMINATED10.0.0.84:95388 32 64 64           0.00924264      4         25.7089      0.0349707             1            0.153937 \nTorchTrainer_5144b_00006TERMINATED10.0.0.84:10143432128256           0.00325671      5         29.5763      0.0708755             0.966667     0.0820903\nTorchTrainer_5144b_00007TERMINATED10.0.0.84:10875032 32 64           0.000123766     1         13.9326      0.27464               0.966667     0.401102 \nTorchTrainer_5144b_00008TERMINATED10.0.0.84:11101964128256           0.00371762      5         21.8337      0.00108961            1            0.0579874\nTorchTrainer_5144b_00009TERMINATED10.0.0.84:11825532128128           0.00397956      5         29.8334      0.00940019            1            0.0685028\n\n\n\n\n\n\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n(RayTrainWorker pid=64102) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 120812916.07it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 101305832.98it/s]\n\n\n(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102)': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=64102) Extracting /tmp/tmpydcy4598/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpydcy4598/MNIST/raw\n(RayTrainWorker pid=64102) \n\n\n(RayTrainWorker pid=64102) LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n(RayTrainWorker pid=64101) \n(RayTrainWorker pid=64101)   | Name     | Type               | Params\n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 0 | accuracy | MulticlassAccuracy | 0     \n(RayTrainWorker pid=64101) 1 | layer_1  | Linear             | 50.2 K\n(RayTrainWorker pid=64101) 2 | layer_2  | Linear             | 16.6 K\n(RayTrainWorker pid=64101) 3 | layer_3  | Linear             | 2.6 K \n(RayTrainWorker pid=64101) ------------------------------------------------\n(RayTrainWorker pid=64101) 69.5 K    Trainable params\n(RayTrainWorker pid=64101) 0         Non-trainable params\n(RayTrainWorker pid=64101) 69.5 K    Total params\n(RayTrainWorker pid=64101) 0.278     Total estimated model params size (MB)\n(RayTrainWorker pid=64102) [W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n\n\n(autoscaler +7m33s) [autoscaler] Current infeasible resource requests: {\"resourcesBundle\":{\"bundle_group_289661bddaad4820732f117e33d702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_d14ed93ffcb267f77984fc5e097c02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_9d0f0584af89d9185ad87362359402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_b8fdebe2246b003d6e5d0451465b02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_35d0a11b5707ef020363a907e5fc02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_ba2b3c448809cad351fc7dc545a402000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_05283c0cbfbb775ad68aacf47bc702000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_2cd0e3d931d1e356a1ab0f3afb6a02000000\":0.001}}, {\"resourcesBundle\":{\"bundle_group_14f2bd9329dfcde35c77e8474b0f02000000\":0.001}}\n\n\n(RayTrainWorker pid=71408) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=64101) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=64101) Extracting /tmp/tmpt8k8jglf/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt8k8jglf/MNIST/raw [repeated 11x across cluster]\n(RayTrainWorker pid=64101)  [repeated 11x across cluster]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73648) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpcy67mfe_/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=71409) Extracting /tmp/tmpmxchio03/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpmxchio03/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=71409)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80950) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpdj6sv23q/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=73647) Extracting /tmp/tmpjm0jv6rr/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpjm0jv6rr/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=73647)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88186) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpd1qkzrfz/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=80951) Extracting /tmp/tmpyrcbok27/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyrcbok27/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=80951)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95494) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpkvf1rrst/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=88184) Extracting /tmp/tmppk4zrz1w/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmppk4zrz1w/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=88184)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=101545) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=95492) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 11x across cluster]\n(RayTrainWorker pid=95492) Extracting /tmp/tmpyy7a6r11/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpyy7a6r11/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=95492)  [repeated 12x across cluster]\n\n\n  0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '0%|          | 0/9912422 [00:00<?, ?it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9912422/9912422 [00:00<00:00, 104607984.65it/s]\n\n\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n(RayTrainWorker pid=101545) Extracting /tmp/tmpxobpdr_p/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxobpdr_p/MNIST/raw\n\n\n(RayTrainWorker pid=108863) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=101546) Extracting /tmp/tmpt_if2tuu/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpt_if2tuu/MNIST/raw [repeated 8x across cluster]\n(RayTrainWorker pid=101546)  [repeated 12x across cluster]\n\n\n(autoscaler +11m23s) [workspace snapshot] New snapshot created successfully (Size: 327.01 KB)\n\n\n(RayTrainWorker pid=111131) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=111131) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmpddnnc0iv/MNIST/raw/train-images-idx3-ubyte.gz [repeated 13x across cluster]\n(RayTrainWorker pid=108863) Extracting /tmp/tmpxcg0v86z/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpxcg0v86z/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=108863)  [repeated 12x across cluster]\n\n\n(RayTrainWorker pid=118364) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=118364) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/tmp0sbwiedt/MNIST/raw/train-images-idx3-ubyte.gz [repeated 12x across cluster]\n(RayTrainWorker pid=111130) Extracting /tmp/tmpfmuq9_qh/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/tmpfmuq9_qh/MNIST/raw [repeated 12x across cluster]\n(RayTrainWorker pid=111130)  [repeated 12x across cluster]\n\n\n\n\n\n\n\nresults.get_best_result(metric=\"ptl/val_accuracy\", mode=\"max\")': cannot unpack non-iterable NoneType object\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "Error in finding '# Check, how the data is transformed. Note, the\n# example dataset has only 3 such images.\nbatch = offline_data.data.take_batch(3)\n\n# Construct your `OfflinePreLearner`.\noffline_prelearner = ImageOfflinePreLearner(\n    config=config,\n    learner=None,\n    spaces=(\n        config.observation_space,\n        config.action_space,\n    ),\n    module_spec=module_spec,\n)\n\n# Transform the raw data to `MultiAgentBatch` data.\nbatch = offline_prelearner(batch)\n\n# Show the transformed batch.\nprint(f\"Batch: {batch}\")\n\n\n\nTip\nConsider this approach carefully: in many cases, fully transforming your data into a suitable format before engaging RLlib\u2019s offline RL API can be more efficient. For instance, in the example above, you could preprocess the entire image dataset into numpy arrays beforehand and utilize RLlib\u2019s default OfflineData class for subsequent steps.\n\n\n\n\n\nMonitoring#\nTo effectively monitor your offline data pipeline, leverage Ray Data\u2019s built-in monitoring capacities. Focus on ensuring that all stages of your offline data streaming pipeline are actively processing data. Additionally, keep an eye on the Learner instance, particularly the learner_update_timer, which should maintain low values - around 0.02 for small models - to indicate efficient data processing and model updates.\n\nNote\nRLlib doesn\u2019t include Ray Data  metrics in its results or display them in Tensorboard through Ray Tune\u2019s TBXLoggerCallback. It\u2019s strongly recommended to enable the Ray Dashboard, accessible at 127.0.0.1:8265, for comprehensive monitoring and insights.\n\n\n\n\n\n\nOutput API#\nYou can configure experience output for an agent using the following options:\ndef offline_data(\n    # Specify where experiences should be saved:\n    # - None: don't save any experiences\n    # - a path/URI to save to a custom output directory (for example, \"s3://bckt/\")\n    output: Optional[str],\n    # What sample batch columns to LZ4 compress in the output data.\n    # Note that providing `rllib.core.columns.Columns.OBS` also\n    # compresses `rllib.core.columns.Columns.NEXT_OBS`.\n    output_compress_columns: Optional[List[str]],\n    # Max output file size (in bytes) before rolling over to a new\n    # file.\n    output_max_file_size: Optional[float],\n    # Max output row numbers before rolling over to a new file.\n    output_max_rows_per_file: Optional[int],\n    # Write method for the `ray.data.Dataset` to write the\n    # offline data to `output`. The default is `read_parquet` for Parquet\n    # files. See https://docs.ray.io/en/latest/data/api/input_output.html for\n    # more info about available read methods in `ray.data`.\n    output_write_method: Optional[str],\n    # Keyword arguments for the `output_write_method`. These are\n    # passed into the write method without checking.\n    output_write_method_kwargs: Optional[Dict],\n    # A cloud filesystem to handle access to cloud storage when\n    # writing experiences. Can be \"gcs\" for Google Cloud Storage, \"s3\" for AWS\n    # S3 buckets, \"abs\" for Azure Blob Storage, or any filesystem supported\n    # by PyArrow. In general the file path is sufficient for accessing data\n    # from public or local storage systems. See\n    # https://arrow.apache.org/docs/python/filesystems.html for details.\n    output_filesystem: Optional[str],\n    # A dictionary holding the keyword arguments for the filesystem\n    # given by `output_filesystem`. See `gcsfs.GCSFilesystem` for GCS,\n    # `pyarrow.fs.S3FileSystem`, for S3, and `ablfs.AzureBlobFilesystem` for\n    # ABS filesystem arguments.\n    output_filesystem_kwargs: Optional[Dict],\n    # If data should be recorded in RLlib's `EpisodeType`\n    # format (i.e. `SingleAgentEpisode` objects). Use this format, if you\n    # need data to be ordered in time and directly grouped by episodes for\n    # example to train stateful modules or if you plan to use recordings\n    # exclusively in RLlib. Otherwise data is recorded in tabular (columnar)\n    # format. Default is `True`.\n    output_write_episodes: Optional[bool],': cannot unpack non-iterable NoneType object\n"
        }
      ]
    },
    {
      "id": "SFPL",
      "code_hash": "5f1f24ff6a55e97a0a23496df828325e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "application/json": "[{\"start_index\": 2, \"end_index\": 1193, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_index.txt\"}, {\"start_index\": 2, \"end_index\": 4051, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_ray-collective.txt\"}, {\"start_index\": 3562, \"end_index\": 7782, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_ray-collective.txt\"}, {\"start_index\": 7632, \"end_index\": 11632, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_ray-collective.txt\"}, {\"start_index\": 11289, \"end_index\": 15179, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_ray-collective.txt\"}, {\"start_index\": 14893, \"end_index\": 18383, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_ray-collective.txt\"}, {\"start_index\": 2, \"end_index\": 4514, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_getting-involved.txt\"}, {\"start_index\": 4189, \"end_index\": 8607, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_getting-involved.txt\"}, {\"start_index\": 8311, \"end_index\": 12245, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_getting-involved.txt\"}, {\"start_index\": 2, \"end_index\": 665, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_end.txt\"}, {\"start_index\": 2, \"end_index\": 1780, \"corpus_id\": \"datasets/raydocs_full/ray-core_api_utility.txt\"}, {\"start_index\": 2, \"end_index\": 3887, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.txt\"}, {\"start_index\": 2, \"end_index\": 4504, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_rl_modules.txt\"}, {\"start_index\": 4058, \"end_index\": 8447, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_rl_modules.txt\"}, {\"start_index\": 8081, \"end_index\": 12181, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_rl_modules.txt\"}, {\"start_index\": 11810, \"end_index\": 14104, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_rl_modules.txt\"}, {\"start_index\": 2, \"end_index\": 434, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learner_class.txt\"}, {\"start_index\": 2, \"end_index\": 3990, \"corpus_id\": \"datasets/raydocs_full/ray-core_runtime_env_auth.txt\"}, {\"start_index\": 1, \"end_index\": 543, \"corpus_id\": \"datasets/raydocs_full/data_examples.txt\"}, {\"start_index\": 2, \"end_index\": 430, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.build.txt\"}, {\"start_index\": 2, \"end_index\": 4450, \"corpus_id\": \"datasets/raydocs_full/cluster_usage-stats.txt\"}, {\"start_index\": 2, \"end_index\": 4988, \"corpus_id\": \"datasets/raydocs_full/data_comparisons.txt\"}, {\"start_index\": 4620, \"end_index\": 5460, \"corpus_id\": \"datasets/raydocs_full/data_comparisons.txt\"}, {\"start_index\": 2, \"end_index\": 4314, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 4106, \"end_index\": 7989, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 7993, \"end_index\": 11747, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 11679, \"end_index\": 13300, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 13044, \"end_index\": 14990, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 14994, \"end_index\": 17693, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 17694, \"end_index\": 17993, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 2, \"end_index\": 4314, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 4106, \"end_index\": 7989, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 7993, \"end_index\": 11747, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 11679, \"end_index\": 13300, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 19043, \"end_index\": 21661, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 21520, \"end_index\": 25429, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 25057, \"end_index\": 27815, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 27588, \"end_index\": 30671, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 30443, \"end_index\": 33137, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-xgboost.txt\"}, {\"start_index\": 2, \"end_index\": 1951, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_fork-new-processes.txt\"}, {\"start_index\": 2, \"end_index\": 4581, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_general-debugging.txt\"}, {\"start_index\": 4191, \"end_index\": 6850, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_general-debugging.txt\"}, {\"start_index\": 2, \"end_index\": 457, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.remove_module.txt\"}, {\"start_index\": 2, \"end_index\": 4594, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_persist-kuberay-custom-resource-logs.txt\"}, {\"start_index\": 4535, \"end_index\": 8512, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_persist-kuberay-custom-resource-logs.txt\"}, {\"start_index\": 8518, \"end_index\": 11856, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_persist-kuberay-custom-resource-logs.txt\"}, {\"start_index\": 2, \"end_index\": 817, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.convert_to_torch_tensor.txt\"}, {\"start_index\": 2, \"end_index\": 1475, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_index.txt\"}, {\"start_index\": 2, \"end_index\": 2993, \"corpus_id\": \"datasets/raydocs_full/data_working-with-tensors.txt\"}, {\"start_index\": 2, \"end_index\": 4368, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 4185, \"end_index\": 8338, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 8343, \"end_index\": 12275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 12068, \"end_index\": 14485, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 14319, \"end_index\": 16477, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 16479, \"end_index\": 18697, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 18486, \"end_index\": 20886, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 20844, \"end_index\": 23249, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 23207, \"end_index\": 25589, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 25591, \"end_index\": 26370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 26374, \"end_index\": 29073, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 28818, \"end_index\": 30542, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 2, \"end_index\": 4368, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 4185, \"end_index\": 8338, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 8343, \"end_index\": 12275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 12068, \"end_index\": 14485, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 14319, \"end_index\": 16477, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 16479, \"end_index\": 18697, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 18486, \"end_index\": 20886, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 20844, \"end_index\": 23249, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 23207, \"end_index\": 25589, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 32931, \"end_index\": 34411, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 34423, \"end_index\": 37114, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 36881, \"end_index\": 39454, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 39221, \"end_index\": 39982, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 2, \"end_index\": 4368, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 4185, \"end_index\": 8338, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 8343, \"end_index\": 12275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 12068, \"end_index\": 14485, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 14319, \"end_index\": 16477, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 16479, \"end_index\": 18697, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 18486, \"end_index\": 20886, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 20844, \"end_index\": 23249, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 23207, \"end_index\": 25589, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 41163, \"end_index\": 43440, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 43446, \"end_index\": 45238, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 45040, \"end_index\": 47232, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 47234, \"end_index\": 49271, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 49273, \"end_index\": 51664, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 51667, \"end_index\": 54092, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 54095, \"end_index\": 56496, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 56499, \"end_index\": 58891, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 58894, \"end_index\": 61291, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 61249, \"end_index\": 63681, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 63639, \"end_index\": 66041, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 65792, \"end_index\": 68185, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 67974, \"end_index\": 70351, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 70105, \"end_index\": 72550, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 72339, \"end_index\": 74739, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 74493, \"end_index\": 76913, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 76711, \"end_index\": 77271, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_visualization_pbt_visualization.txt\"}, {\"start_index\": 2, \"end_index\": 427, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.models.distributions.Distribution.logp.txt\"}, {\"start_index\": 2, \"end_index\": 4678, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_data_juicer_distributed_data_processing.txt\"}, {\"start_index\": 4682, \"end_index\": 7693, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_data_juicer_distributed_data_processing.txt\"}, {\"start_index\": 2, \"end_index\": 4099, \"corpus_id\": \"datasets/raydocs_full/serve_resource-allocation.txt\"}, {\"start_index\": 2, \"end_index\": 2706, \"corpus_id\": \"datasets/raydocs_full/tune_examples_index.txt\"}, {\"start_index\": 2, \"end_index\": 1659, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_created.txt\"}, {\"start_index\": 2, \"end_index\": 228, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_index.txt\"}, {\"start_index\": 2, \"end_index\": 4092, \"corpus_id\": \"datasets/raydocs_full/data_working-with-llms.txt\"}, {\"start_index\": 3694, \"end_index\": 7802, \"corpus_id\": \"datasets/raydocs_full/data_working-with-llms.txt\"}, {\"start_index\": 2, \"end_index\": 3605, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_mnist-training-example.txt\"}, {\"start_index\": 3608, \"end_index\": 5977, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_mnist-training-example.txt\"}, {\"start_index\": 2, \"end_index\": 123, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_data.OfflineData.default_map_batches_kwargs.txt\"}, {\"start_index\": 2, \"end_index\": 4470, \"corpus_id\": \"datasets/raydocs_full/rllib_key-concepts.txt\"}, {\"start_index\": 4052, \"end_index\": 8380, \"corpus_id\": \"datasets/raydocs_full/rllib_key-concepts.txt\"}, {\"start_index\": 7962, \"end_index\": 11825, \"corpus_id\": \"datasets/raydocs_full/rllib_key-concepts.txt\"}, {\"start_index\": 11524, \"end_index\": 14285, \"corpus_id\": \"datasets/raydocs_full/rllib_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 4249, \"corpus_id\": \"datasets/raydocs_full/data_working-with-pytorch.txt\"}, {\"start_index\": 3859, \"end_index\": 8062, \"corpus_id\": \"datasets/raydocs_full/data_working-with-pytorch.txt\"}, {\"start_index\": 7636, \"end_index\": 11592, \"corpus_id\": \"datasets/raydocs_full/data_working-with-pytorch.txt\"}, {\"start_index\": 11227, \"end_index\": 13453, \"corpus_id\": \"datasets/raydocs_full/data_working-with-pytorch.txt\"}, {\"start_index\": 2, \"end_index\": 459, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.get_module.txt\"}, {\"start_index\": 2, \"end_index\": 4142, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-ft.txt\"}, {\"start_index\": 3716, \"end_index\": 5603, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-ft.txt\"}, {\"start_index\": 5444, \"end_index\": 7905, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-ft.txt\"}, {\"start_index\": 7912, \"end_index\": 10346, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-ft.txt\"}, {\"start_index\": 10268, \"end_index\": 13585, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-ft.txt\"}, {\"start_index\": 13408, \"end_index\": 17122, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-ft.txt\"}, {\"start_index\": 17127, \"end_index\": 19371, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-ft.txt\"}, {\"start_index\": 2, \"end_index\": 1266, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.checkpoints.Checkpointable.txt\"}, {\"start_index\": 2, \"end_index\": 634, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.set_state.txt\"}, {\"start_index\": 2, \"end_index\": 110, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.inference_only.txt\"}, {\"start_index\": 2, \"end_index\": 170, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.eval_env_runner.txt\"}, {\"start_index\": 2, \"end_index\": 3211, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_multi_agent_env.txt\"}, {\"start_index\": 3200, \"end_index\": 5936, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_multi_agent_env.txt\"}, {\"start_index\": 2, \"end_index\": 3987, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_accelerators.txt\"}, {\"start_index\": 3934, \"end_index\": 7507, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_accelerators.txt\"}, {\"start_index\": 7229, \"end_index\": 10022, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_accelerators.txt\"}, {\"start_index\": 9855, \"end_index\": 13803, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_accelerators.txt\"}, {\"start_index\": 13675, \"end_index\": 15521, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_accelerators.txt\"}, {\"start_index\": 2, \"end_index\": 189, \"corpus_id\": \"datasets/raydocs_full/data_api_execution_options.txt\"}, {\"start_index\": 2, \"end_index\": 3515, \"corpus_id\": \"datasets/raydocs_full/data_iterating-over-data.txt\"}, {\"start_index\": 3065, \"end_index\": 6391, \"corpus_id\": \"datasets/raydocs_full/data_iterating-over-data.txt\"}, {\"start_index\": 2, \"end_index\": 1713, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_unnecessary-ray-get.txt\"}, {\"start_index\": 2, \"end_index\": 793, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule._forward.txt\"}, {\"start_index\": 2, \"end_index\": 4259, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_docker.txt\"}, {\"start_index\": 3913, \"end_index\": 6163, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_docker.txt\"}, {\"start_index\": 2, \"end_index\": 3817, \"corpus_id\": \"datasets/raydocs_full/ray-core_starting-ray.txt\"}, {\"start_index\": 3509, \"end_index\": 4981, \"corpus_id\": \"datasets/raydocs_full/ray-core_starting-ray.txt\"}, {\"start_index\": 2, \"end_index\": 4373, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.txt\"}, {\"start_index\": 3941, \"end_index\": 5290, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.txt\"}, {\"start_index\": 2, \"end_index\": 501, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule._forward_exploration.txt\"}, {\"start_index\": 2, \"end_index\": 4844, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_resources.txt\"}, {\"start_index\": 4847, \"end_index\": 8911, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_resources.txt\"}, {\"start_index\": 8492, \"end_index\": 9760, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_resources.txt\"}, {\"start_index\": 2, \"end_index\": 3714, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_user-guides_configuring-autoscaling.txt\"}, {\"start_index\": 2, \"end_index\": 281, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_multi_agent.txt\"}, {\"start_index\": 2, \"end_index\": 3931, \"corpus_id\": \"datasets/raydocs_full/tune_examples_hyperopt_example.txt\"}, {\"start_index\": 3581, \"end_index\": 5670, \"corpus_id\": \"datasets/raydocs_full/tune_examples_hyperopt_example.txt\"}, {\"start_index\": 5429, \"end_index\": 8532, \"corpus_id\": \"datasets/raydocs_full/tune_examples_hyperopt_example.txt\"}, {\"start_index\": 8329, \"end_index\": 11102, \"corpus_id\": \"datasets/raydocs_full/tune_examples_hyperopt_example.txt\"}, {\"start_index\": 2, \"end_index\": 1548, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.restore_from_path.txt\"}, {\"start_index\": 2, \"end_index\": 1487, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_actor-utils.txt\"}, {\"start_index\": 2, \"end_index\": 719, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.convert_to_numpy.txt\"}, {\"start_index\": 2, \"end_index\": 3762, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_rayjob-quick-start.txt\"}, {\"start_index\": 3504, \"end_index\": 7569, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_rayjob-quick-start.txt\"}, {\"start_index\": 7576, \"end_index\": 11096, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_rayjob-quick-start.txt\"}, {\"start_index\": 2, \"end_index\": 338, \"corpus_id\": \"datasets/raydocs_full/ray-core_api_index.txt\"}, {\"start_index\": 2, \"end_index\": 829, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer.txt\"}, {\"start_index\": 2, \"end_index\": 3928, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_results.txt\"}, {\"start_index\": 2, \"end_index\": 4624, \"corpus_id\": \"datasets/raydocs_full/ray-air_getting-started.txt\"}, {\"start_index\": 4121, \"end_index\": 5398, \"corpus_id\": \"datasets/raydocs_full/ray-air_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 1826, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_mobilenet-rayservice.txt\"}, {\"start_index\": 2, \"end_index\": 3930, \"corpus_id\": \"datasets/raydocs_full/data_transforming-data.txt\"}, {\"start_index\": 3689, \"end_index\": 7945, \"corpus_id\": \"datasets/raydocs_full/data_transforming-data.txt\"}, {\"start_index\": 7539, \"end_index\": 9656, \"corpus_id\": \"datasets/raydocs_full/data_transforming-data.txt\"}, {\"start_index\": 2, \"end_index\": 88, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.inference_only.txt\"}, {\"start_index\": 2, \"end_index\": 3412, \"corpus_id\": \"datasets/raydocs_full/cluster_configure-manage-dashboard.txt\"}, {\"start_index\": 3173, \"end_index\": 7728, \"corpus_id\": \"datasets/raydocs_full/cluster_configure-manage-dashboard.txt\"}, {\"start_index\": 7580, \"end_index\": 11542, \"corpus_id\": \"datasets/raydocs_full/cluster_configure-manage-dashboard.txt\"}, {\"start_index\": 11370, \"end_index\": 12319, \"corpus_id\": \"datasets/raydocs_full/cluster_configure-manage-dashboard.txt\"}, {\"start_index\": 2, \"end_index\": 4697, \"corpus_id\": \"datasets/raydocs_full/ray-overview_use-cases.txt\"}, {\"start_index\": 4295, \"end_index\": 5849, \"corpus_id\": \"datasets/raydocs_full/ray-overview_use-cases.txt\"}, {\"start_index\": 2, \"end_index\": 4194, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-resources.txt\"}, {\"start_index\": 3855, \"end_index\": 5372, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-resources.txt\"}, {\"start_index\": 2, \"end_index\": 592, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_train_result.txt\"}, {\"start_index\": 2, \"end_index\": 4533, \"corpus_id\": \"datasets/raydocs_full/rllib_checkpoints.txt\"}, {\"start_index\": 4171, \"end_index\": 8867, \"corpus_id\": \"datasets/raydocs_full/rllib_checkpoints.txt\"}, {\"start_index\": 8603, \"end_index\": 12986, \"corpus_id\": \"datasets/raydocs_full/rllib_checkpoints.txt\"}, {\"start_index\": 12725, \"end_index\": 14722, \"corpus_id\": \"datasets/raydocs_full/rllib_checkpoints.txt\"}, {\"start_index\": 1, \"end_index\": 679, \"corpus_id\": \"datasets/raydocs_full/serve_examples.txt\"}, {\"start_index\": 2, \"end_index\": 797, \"corpus_id\": \"datasets/raydocs_full/ray-core_api_scheduling.txt\"}, {\"start_index\": 2, \"end_index\": 3338, \"corpus_id\": \"datasets/raydocs_full/tune_key-concepts.txt\"}, {\"start_index\": 2944, \"end_index\": 5513, \"corpus_id\": \"datasets/raydocs_full/tune_key-concepts.txt\"}, {\"start_index\": 5516, \"end_index\": 9645, \"corpus_id\": \"datasets/raydocs_full/tune_key-concepts.txt\"}, {\"start_index\": 9278, \"end_index\": 13463, \"corpus_id\": \"datasets/raydocs_full/tune_key-concepts.txt\"}, {\"start_index\": 13102, \"end_index\": 15617, \"corpus_id\": \"datasets/raydocs_full/tune_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 344, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.set_state.txt\"}, {\"start_index\": 2, \"end_index\": 4081, \"corpus_id\": \"datasets/raydocs_full/ray-core_walkthrough.txt\"}, {\"start_index\": 2, \"end_index\": 1321, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.remove_policy.txt\"}, {\"start_index\": 2, \"end_index\": 1892, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_global-variables.txt\"}, {\"start_index\": 2, \"end_index\": 1621, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_mars-on-ray.txt\"}, {\"start_index\": 2, \"end_index\": 2769, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-comet.txt\"}, {\"start_index\": 2772, \"end_index\": 4235, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-comet.txt\"}, {\"start_index\": 4238, \"end_index\": 6641, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-comet.txt\"}, {\"start_index\": 6427, \"end_index\": 7462, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-comet.txt\"}, {\"start_index\": 2, \"end_index\": 2769, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-comet.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-comet.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 6718, \"end_index\": 9137, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 8927, \"end_index\": 11379, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 11169, \"end_index\": 12326, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 12332, \"end_index\": 14888, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 14889, \"end_index\": 16926, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 16929, \"end_index\": 19370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 19147, \"end_index\": 21625, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 21397, \"end_index\": 21815, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 21821, \"end_index\": 23652, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 23655, \"end_index\": 26061, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 26067, \"end_index\": 28632, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 28333, \"end_index\": 32045, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 31705, \"end_index\": 34191, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 34194, \"end_index\": 36643, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 36403, \"end_index\": 38760, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 38552, \"end_index\": 40410, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 21821, \"end_index\": 23652, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 23655, \"end_index\": 26061, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 26067, \"end_index\": 28632, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 28333, \"end_index\": 32045, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 31705, \"end_index\": 34191, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 40416, \"end_index\": 41478, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 41484, \"end_index\": 44054, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 44055, \"end_index\": 44717, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 21821, \"end_index\": 23652, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 23655, \"end_index\": 26061, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 26067, \"end_index\": 28632, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 28333, \"end_index\": 32045, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 31705, \"end_index\": 34191, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 40416, \"end_index\": 41478, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 44720, \"end_index\": 47152, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 46930, \"end_index\": 47718, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 21821, \"end_index\": 23652, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 23655, \"end_index\": 26061, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 26067, \"end_index\": 28632, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 28333, \"end_index\": 32045, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 31705, \"end_index\": 34191, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 48792, \"end_index\": 50320, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 50323, \"end_index\": 51517, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 51523, \"end_index\": 52907, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 52910, \"end_index\": 55370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 55155, \"end_index\": 55909, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 3964, \"end_index\": 5374, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 5241, \"end_index\": 6716, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 21821, \"end_index\": 23652, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 23655, \"end_index\": 26061, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 26067, \"end_index\": 28632, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 28333, \"end_index\": 32045, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 31705, \"end_index\": 34191, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 48792, \"end_index\": 50320, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 50323, \"end_index\": 51517, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bohb_example.txt\"}, {\"start_index\": 2, \"end_index\": 868, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_references.txt\"}, {\"start_index\": 2, \"end_index\": 4003, \"corpus_id\": \"datasets/raydocs_full/data_working-with-images.txt\"}, {\"start_index\": 3653, \"end_index\": 4977, \"corpus_id\": \"datasets/raydocs_full/data_working-with-images.txt\"}, {\"start_index\": 2, \"end_index\": 778, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.SCHEMA.txt\"}, {\"start_index\": 2, \"end_index\": 3633, \"corpus_id\": \"datasets/raydocs_full/serve_llm_serving-llms.txt\"}, {\"start_index\": 3329, \"end_index\": 6888, \"corpus_id\": \"datasets/raydocs_full/serve_llm_serving-llms.txt\"}, {\"start_index\": 6672, \"end_index\": 10329, \"corpus_id\": \"datasets/raydocs_full/serve_llm_serving-llms.txt\"}, {\"start_index\": 10009, \"end_index\": 13559, \"corpus_id\": \"datasets/raydocs_full/serve_llm_serving-llms.txt\"}, {\"start_index\": 13315, \"end_index\": 16889, \"corpus_id\": \"datasets/raydocs_full/serve_llm_serving-llms.txt\"}, {\"start_index\": 16618, \"end_index\": 18816, \"corpus_id\": \"datasets/raydocs_full/serve_llm_serving-llms.txt\"}, {\"start_index\": 2, \"end_index\": 4461, \"corpus_id\": \"datasets/raydocs_full/ray-core_ray-generator.txt\"}, {\"start_index\": 4465, \"end_index\": 8656, \"corpus_id\": \"datasets/raydocs_full/ray-core_ray-generator.txt\"}, {\"start_index\": 8395, \"end_index\": 10440, \"corpus_id\": \"datasets/raydocs_full/ray-core_ray-generator.txt\"}, {\"start_index\": 2, \"end_index\": 537, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_overview.txt\"}, {\"start_index\": 2, \"end_index\": 4511, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-stopping.txt\"}, {\"start_index\": 4184, \"end_index\": 8607, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-stopping.txt\"}, {\"start_index\": 2, \"end_index\": 381, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.framework.try_import_torch.txt\"}, {\"start_index\": 2, \"end_index\": 84, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.model_config.txt\"}, {\"start_index\": 2, \"end_index\": 96, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.concat_aligned.txt\"}, {\"start_index\": 2, \"end_index\": 4166, \"corpus_id\": \"datasets/raydocs_full/tune_api_suggestion.txt\"}, {\"start_index\": 3877, \"end_index\": 6407, \"corpus_id\": \"datasets/raydocs_full/tune_api_suggestion.txt\"}, {\"start_index\": 2, \"end_index\": 4719, \"corpus_id\": \"datasets/raydocs_full/serve_model_composition.txt\"}, {\"start_index\": 4408, \"end_index\": 8919, \"corpus_id\": \"datasets/raydocs_full/serve_model_composition.txt\"}, {\"start_index\": 8670, \"end_index\": 11577, \"corpus_id\": \"datasets/raydocs_full/serve_model_composition.txt\"}, {\"start_index\": 2, \"end_index\": 3059, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-run.txt\"}, {\"start_index\": 2977, \"end_index\": 6108, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-run.txt\"}, {\"start_index\": 5696, \"end_index\": 6487, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-run.txt\"}, {\"start_index\": 2, \"end_index\": 223, \"corpus_id\": \"datasets/raydocs_full/ray-core_api_runtime-env.txt\"}, {\"start_index\": 2, \"end_index\": 4859, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_fault-tolerance.txt\"}, {\"start_index\": 4458, \"end_index\": 9182, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_fault-tolerance.txt\"}, {\"start_index\": 8907, \"end_index\": 11682, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_fault-tolerance.txt\"}, {\"start_index\": 2, \"end_index\": 4113, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 3838, \"end_index\": 6800, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 6449, \"end_index\": 8817, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 8561, \"end_index\": 11350, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 11355, \"end_index\": 13170, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 12837, \"end_index\": 15378, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 15106, \"end_index\": 19088, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 19077, \"end_index\": 19811, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-wandb.txt\"}, {\"start_index\": 2, \"end_index\": 4091, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_grpc-guide.txt\"}, {\"start_index\": 3882, \"end_index\": 8134, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_grpc-guide.txt\"}, {\"start_index\": 7719, \"end_index\": 12088, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_grpc-guide.txt\"}, {\"start_index\": 12090, \"end_index\": 16500, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_grpc-guide.txt\"}, {\"start_index\": 16349, \"end_index\": 20639, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_grpc-guide.txt\"}, {\"start_index\": 2, \"end_index\": 4074, \"corpus_id\": \"datasets/raydocs_full/serve_index.txt\"}, {\"start_index\": 3837, \"end_index\": 8668, \"corpus_id\": \"datasets/raydocs_full/serve_index.txt\"}, {\"start_index\": 8327, \"end_index\": 13209, \"corpus_id\": \"datasets/raydocs_full/serve_index.txt\"}, {\"start_index\": 12860, \"end_index\": 14022, \"corpus_id\": \"datasets/raydocs_full/serve_index.txt\"}, {\"start_index\": 2, \"end_index\": 459, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_learner_class.txt\"}, {\"start_index\": 2, \"end_index\": 69, \"corpus_id\": \"datasets/raydocs_full/workflows_api_api.txt\"}, {\"start_index\": 2, \"end_index\": 141, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.setup.txt\"}, {\"start_index\": 2, \"end_index\": 4107, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_testing-tips.txt\"}, {\"start_index\": 2, \"end_index\": 3887, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_pong_example.txt\"}, {\"start_index\": 3897, \"end_index\": 7494, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_pong_example.txt\"}, {\"start_index\": 7367, \"end_index\": 10058, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_pong_example.txt\"}, {\"start_index\": 2, \"end_index\": 3736, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_stability.txt\"}, {\"start_index\": 2, \"end_index\": 557, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_utils.txt\"}, {\"start_index\": 2, \"end_index\": 635, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_index.txt\"}, {\"start_index\": 2, \"end_index\": 1328, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer.txt\"}, {\"start_index\": 2, \"end_index\": 2891, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm.txt\"}, {\"start_index\": 2, \"end_index\": 1845, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_offline.txt\"}, {\"start_index\": 2, \"end_index\": 1078, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.train.txt\"}, {\"start_index\": 2, \"end_index\": 4324, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.txt\"}, {\"start_index\": 2, \"end_index\": 259, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_whitepaper.txt\"}, {\"start_index\": 2, \"end_index\": 3252, \"corpus_id\": \"datasets/raydocs_full/data_quickstart.txt\"}, {\"start_index\": 2, \"end_index\": 1935, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_single_agent_episode.txt\"}, {\"start_index\": 2, \"end_index\": 2976, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2965, \"end_index\": 5611, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 5530, \"end_index\": 7295, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 7297, \"end_index\": 11345, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 10919, \"end_index\": 12241, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2, \"end_index\": 2976, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2965, \"end_index\": 5611, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 16129, \"end_index\": 20414, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 20029, \"end_index\": 24427, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 23983, \"end_index\": 26342, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2, \"end_index\": 2976, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2965, \"end_index\": 5611, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 29722, \"end_index\": 32084, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 32073, \"end_index\": 35326, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 35233, \"end_index\": 38955, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 38863, \"end_index\": 42545, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 42547, \"end_index\": 46808, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 46412, \"end_index\": 50933, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 50495, \"end_index\": 54798, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 54387, \"end_index\": 56139, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2, \"end_index\": 2976, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2965, \"end_index\": 5611, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 29722, \"end_index\": 32084, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 32073, \"end_index\": 35326, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 35233, \"end_index\": 38955, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 59514, \"end_index\": 64074, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 63755, \"end_index\": 68264, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 67848, \"end_index\": 70420, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2, \"end_index\": 2976, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2965, \"end_index\": 5611, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 29722, \"end_index\": 32084, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 32073, \"end_index\": 35326, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 35233, \"end_index\": 38955, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 71959, \"end_index\": 75959, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 75948, \"end_index\": 79943, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 79932, \"end_index\": 84177, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_algorithm-config.txt\"}, {\"start_index\": 2, \"end_index\": 1823, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.save_to_path.txt\"}, {\"start_index\": 2, \"end_index\": 921, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_kuberay-operator-installation.txt\"}, {\"start_index\": 2, \"end_index\": 1915, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_multiprocessing.txt\"}, {\"start_index\": 2, \"end_index\": 4484, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_map_reduce.txt\"}, {\"start_index\": 4169, \"end_index\": 6497, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_map_reduce.txt\"}, {\"start_index\": 6263, \"end_index\": 8270, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_map_reduce.txt\"}, {\"start_index\": 2, \"end_index\": 4597, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-auth.txt\"}, {\"start_index\": 4385, \"end_index\": 6601, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-auth.txt\"}, {\"start_index\": 2, \"end_index\": 394, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_evaluation_config_object.txt\"}, {\"start_index\": 2, \"end_index\": 4014, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.txt\"}, {\"start_index\": 4020, \"end_index\": 6155, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.txt\"}, {\"start_index\": 2, \"end_index\": 3680, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_objects.txt\"}, {\"start_index\": 3338, \"end_index\": 4883, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_objects.txt\"}, {\"start_index\": 2, \"end_index\": 4502, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault-tolerance.txt\"}, {\"start_index\": 2, \"end_index\": 4498, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_best-practices.txt\"}, {\"start_index\": 4500, \"end_index\": 6187, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_best-practices.txt\"}, {\"start_index\": 6191, \"end_index\": 8589, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_best-practices.txt\"}, {\"start_index\": 8404, \"end_index\": 9116, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_best-practices.txt\"}, {\"start_index\": 2, \"end_index\": 4498, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_best-practices.txt\"}, {\"start_index\": 4500, \"end_index\": 6187, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_best-practices.txt\"}, {\"start_index\": 2, \"end_index\": 1055, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_environment_created.txt\"}, {\"start_index\": 2, \"end_index\": 279, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.freeze.txt\"}, {\"start_index\": 2, \"end_index\": 3897, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_index.txt\"}, {\"start_index\": 3473, \"end_index\": 8065, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_index.txt\"}, {\"start_index\": 7624, \"end_index\": 8157, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_index.txt\"}, {\"start_index\": 2, \"end_index\": 3844, \"corpus_id\": \"datasets/raydocs_full/serve_model-multiplexing.txt\"}, {\"start_index\": 3461, \"end_index\": 5846, \"corpus_id\": \"datasets/raydocs_full/serve_model-multiplexing.txt\"}, {\"start_index\": 2, \"end_index\": 2366, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_joblib.txt\"}, {\"start_index\": 2, \"end_index\": 1600, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_start.txt\"}, {\"start_index\": 2, \"end_index\": 3583, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_handling-dependencies.txt\"}, {\"start_index\": 2, \"end_index\": 4403, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_gke-gcs-bucket.txt\"}, {\"start_index\": 4344, \"end_index\": 4868, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_gke-gcs-bucket.txt\"}, {\"start_index\": 2, \"end_index\": 182, \"corpus_id\": \"datasets/raydocs_full/tune_api_env.txt\"}, {\"start_index\": 184, \"end_index\": 4572, \"corpus_id\": \"datasets/raydocs_full/tune_api_env.txt\"}, {\"start_index\": 4219, \"end_index\": 6104, \"corpus_id\": \"datasets/raydocs_full/tune_api_env.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_api_env.txt\"}, {\"start_index\": 2, \"end_index\": 3132, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_value.txt\"}, {\"start_index\": 3121, \"end_index\": 4839, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_value.txt\"}, {\"start_index\": 2, \"end_index\": 563, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.checkpoints.try_import_msgpack.txt\"}, {\"start_index\": 2, \"end_index\": 4548, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_development.txt\"}, {\"start_index\": 4198, \"end_index\": 8364, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_development.txt\"}, {\"start_index\": 7946, \"end_index\": 10682, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_development.txt\"}, {\"start_index\": 10283, \"end_index\": 14360, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_development.txt\"}, {\"start_index\": 14016, \"end_index\": 16142, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_development.txt\"}, {\"start_index\": 2, \"end_index\": 4332, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_actors.txt\"}, {\"start_index\": 4007, \"end_index\": 8555, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_actors.txt\"}, {\"start_index\": 8557, \"end_index\": 12027, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_actors.txt\"}, {\"start_index\": 12031, \"end_index\": 14182, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_actors.txt\"}, {\"start_index\": 2, \"end_index\": 143, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.model_config.txt\"}, {\"start_index\": 2, \"end_index\": 635, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.evaluate.txt\"}, {\"start_index\": 2, \"end_index\": 3084, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_dict.txt\"}, {\"start_index\": 2, \"end_index\": 2877, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-search-spaces.txt\"}, {\"start_index\": 2541, \"end_index\": 6197, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-search-spaces.txt\"}, {\"start_index\": 2, \"end_index\": 2202, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.txt\"}, {\"start_index\": 2, \"end_index\": 2486, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_stable-diffusion-rayservice.txt\"}, {\"start_index\": 2, \"end_index\": 3810, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 3439, \"end_index\": 6968, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 6643, \"end_index\": 10485, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 10125, \"end_index\": 13848, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 13398, \"end_index\": 17513, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 17113, \"end_index\": 21539, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 21306, \"end_index\": 25515, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 25398, \"end_index\": 28755, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 28407, \"end_index\": 32147, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 31817, \"end_index\": 34982, \"corpus_id\": \"datasets/raydocs_full/workflows_comparison.txt\"}, {\"start_index\": 2, \"end_index\": 3728, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_tls.txt\"}, {\"start_index\": 3522, \"end_index\": 7568, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_tls.txt\"}, {\"start_index\": 2, \"end_index\": 618, \"corpus_id\": \"datasets/raydocs_full/data_api_aggregate.txt\"}, {\"start_index\": 2, \"end_index\": 133, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.observation_space.txt\"}, {\"start_index\": 2, \"end_index\": 137, \"corpus_id\": \"datasets/raydocs_full/train_more-frameworks.txt\"}, {\"start_index\": 2, \"end_index\": 512, \"corpus_id\": \"datasets/raydocs_full/workflows_api_management.txt\"}, {\"start_index\": 2, \"end_index\": 4064, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_getting-started.txt\"}, {\"start_index\": 3721, \"end_index\": 7954, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_getting-started.txt\"}, {\"start_index\": 7588, \"end_index\": 11802, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 4275, \"corpus_id\": \"datasets/raydocs_full/ray-observability_reference_system-metrics.txt\"}, {\"start_index\": 4068, \"end_index\": 5739, \"corpus_id\": \"datasets/raydocs_full/ray-observability_reference_system-metrics.txt\"}, {\"start_index\": 2, \"end_index\": 295, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_index.txt\"}, {\"start_index\": 2, \"end_index\": 2958, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-metrics.txt\"}, {\"start_index\": 2, \"end_index\": 1809, \"corpus_id\": \"datasets/raydocs_full/ray-core_advanced-topics.txt\"}, {\"start_index\": 2, \"end_index\": 3660, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.txt\"}, {\"start_index\": 3662, \"end_index\": 7923, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.txt\"}, {\"start_index\": 7527, \"end_index\": 12048, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.txt\"}, {\"start_index\": 11610, \"end_index\": 15913, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.txt\"}, {\"start_index\": 15502, \"end_index\": 17254, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.txt\"}, {\"start_index\": 2, \"end_index\": 3947, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_deploy-vm.txt\"}, {\"start_index\": 2, \"end_index\": 504, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule._forward_inference.txt\"}, {\"start_index\": 2, \"end_index\": 4180, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_quickstart.txt\"}, {\"start_index\": 4030, \"end_index\": 7565, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_quickstart.txt\"}, {\"start_index\": 7222, \"end_index\": 11271, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_quickstart.txt\"}, {\"start_index\": 2, \"end_index\": 4426, \"corpus_id\": \"datasets/raydocs_full/ray-observability_reference_cli.txt\"}, {\"start_index\": 4096, \"end_index\": 7964, \"corpus_id\": \"datasets/raydocs_full/ray-observability_reference_cli.txt\"}, {\"start_index\": 2, \"end_index\": 3713, \"corpus_id\": \"datasets/raydocs_full/tune_api_search_space.txt\"}, {\"start_index\": 3330, \"end_index\": 4055, \"corpus_id\": \"datasets/raydocs_full/tune_api_search_space.txt\"}, {\"start_index\": 2, \"end_index\": 2931, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_dask-on-ray.txt\"}, {\"start_index\": 2714, \"end_index\": 6520, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_dask-on-ray.txt\"}, {\"start_index\": 6383, \"end_index\": 10198, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_dask-on-ray.txt\"}, {\"start_index\": 10100, \"end_index\": 14280, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_dask-on-ray.txt\"}, {\"start_index\": 13916, \"end_index\": 16207, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_dask-on-ray.txt\"}, {\"start_index\": 2, \"end_index\": 2934, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune_mnist_keras.txt\"}, {\"start_index\": 2632, \"end_index\": 5174, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune_mnist_keras.txt\"}, {\"start_index\": 2, \"end_index\": 519, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.fc.txt\"}, {\"start_index\": 2, \"end_index\": 196, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_class.txt\"}, {\"start_index\": 2, \"end_index\": 2247, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_limit-pending-tasks.txt\"}, {\"start_index\": 2, \"end_index\": 3425, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_debugging.txt\"}, {\"start_index\": 3430, \"end_index\": 4218, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_debugging.txt\"}, {\"start_index\": 2, \"end_index\": 474, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.model_config.txt\"}, {\"start_index\": 2, \"end_index\": 1636, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.restore_from_path.txt\"}, {\"start_index\": 2, \"end_index\": 111, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_data.OfflineData.__init__.txt\"}, {\"start_index\": 2, \"end_index\": 260, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.get_state.txt\"}, {\"start_index\": 2, \"end_index\": 134, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.get_default_config.txt\"}, {\"start_index\": 2, \"end_index\": 319, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_index.txt\"}, {\"start_index\": 2, \"end_index\": 4239, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_return-ray-put.txt\"}, {\"start_index\": 4013, \"end_index\": 5863, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_return-ray-put.txt\"}, {\"start_index\": 2, \"end_index\": 518, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.global_norm.txt\"}, {\"start_index\": 2, \"end_index\": 4294, \"corpus_id\": \"datasets/raydocs_full/tune_api_internals.txt\"}, {\"start_index\": 3875, \"end_index\": 8135, \"corpus_id\": \"datasets/raydocs_full/tune_api_internals.txt\"}, {\"start_index\": 7783, \"end_index\": 8653, \"corpus_id\": \"datasets/raydocs_full/tune_api_internals.txt\"}, {\"start_index\": 2, \"end_index\": 473, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.add.txt\"}, {\"start_index\": 2, \"end_index\": 185, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.huber_loss.txt\"}, {\"start_index\": 2, \"end_index\": 78, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.RayDaskCallback.ray_active.txt\"}, {\"start_index\": 2, \"end_index\": 3819, \"corpus_id\": \"datasets/raydocs_full/data_working-with-text.txt\"}, {\"start_index\": 3433, \"end_index\": 3985, \"corpus_id\": \"datasets/raydocs_full/data_working-with-text.txt\"}, {\"start_index\": 2, \"end_index\": 4430, \"corpus_id\": \"datasets/raydocs_full/workflows_metadata.txt\"}, {\"start_index\": 4041, \"end_index\": 4927, \"corpus_id\": \"datasets/raydocs_full/workflows_metadata.txt\"}, {\"start_index\": 2, \"end_index\": 2404, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.txt\"}, {\"start_index\": 2, \"end_index\": 563, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.txt\"}, {\"start_index\": 2, \"end_index\": 392, \"corpus_id\": \"datasets/raydocs_full/tune_api_integration.txt\"}, {\"start_index\": 2, \"end_index\": 4785, \"corpus_id\": \"datasets/raydocs_full/serve_architecture.txt\"}, {\"start_index\": 4789, \"end_index\": 6614, \"corpus_id\": \"datasets/raydocs_full/serve_architecture.txt\"}, {\"start_index\": 2, \"end_index\": 1668, \"corpus_id\": \"datasets/raydocs_full/data_api_from_other_data_libs.txt\"}, {\"start_index\": 2, \"end_index\": 2299, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_too-fine-grained-tasks.txt\"}, {\"start_index\": 2, \"end_index\": 859, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.lstm.txt\"}, {\"start_index\": 2, \"end_index\": 4348, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-dev.txt\"}, {\"start_index\": 3982, \"end_index\": 6971, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-dev.txt\"}, {\"start_index\": 2, \"end_index\": 4582, \"corpus_id\": \"datasets/raydocs_full/data_key-concepts.txt\"}, {\"start_index\": 4303, \"end_index\": 5725, \"corpus_id\": \"datasets/raydocs_full/data_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 2397, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_text-summarizer-rayservice.txt\"}, {\"start_index\": 2, \"end_index\": 4672, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_dyn-req-batch.txt\"}, {\"start_index\": 4436, \"end_index\": 7716, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_dyn-req-batch.txt\"}, {\"start_index\": 2, \"end_index\": 4439, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_monte_carlo_pi.txt\"}, {\"start_index\": 3970, \"end_index\": 5719, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_monte_carlo_pi.txt\"}, {\"start_index\": 2, \"end_index\": 4407, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_advanced-autoscaling.txt\"}, {\"start_index\": 4412, \"end_index\": 8806, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_advanced-autoscaling.txt\"}, {\"start_index\": 8479, \"end_index\": 12136, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_advanced-autoscaling.txt\"}, {\"start_index\": 12142, \"end_index\": 16365, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_advanced-autoscaling.txt\"}, {\"start_index\": 16370, \"end_index\": 16417, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_advanced-autoscaling.txt\"}, {\"start_index\": 2, \"end_index\": 574, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.txt\"}, {\"start_index\": 2, \"end_index\": 4075, \"corpus_id\": \"datasets/raydocs_full/data_monitoring-your-workload.txt\"}, {\"start_index\": 3758, \"end_index\": 7303, \"corpus_id\": \"datasets/raydocs_full/data_monitoring-your-workload.txt\"}, {\"start_index\": 6848, \"end_index\": 10844, \"corpus_id\": \"datasets/raydocs_full/data_monitoring-your-workload.txt\"}, {\"start_index\": 10849, \"end_index\": 13216, \"corpus_id\": \"datasets/raydocs_full/data_monitoring-your-workload.txt\"}, {\"start_index\": 13074, \"end_index\": 15179, \"corpus_id\": \"datasets/raydocs_full/data_monitoring-your-workload.txt\"}, {\"start_index\": 15181, \"end_index\": 17807, \"corpus_id\": \"datasets/raydocs_full/data_monitoring-your-workload.txt\"}, {\"start_index\": 2, \"end_index\": 3114, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_task-orders.txt\"}, {\"start_index\": 2, \"end_index\": 4389, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-replay-buffers.txt\"}, {\"start_index\": 4286, \"end_index\": 8600, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-replay-buffers.txt\"}, {\"start_index\": 8606, \"end_index\": 12863, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-replay-buffers.txt\"}, {\"start_index\": 12865, \"end_index\": 13046, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-replay-buffers.txt\"}, {\"start_index\": 2, \"end_index\": 3985, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch-lightning.txt\"}, {\"start_index\": 3656, \"end_index\": 8010, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch-lightning.txt\"}, {\"start_index\": 7541, \"end_index\": 12221, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch-lightning.txt\"}, {\"start_index\": 11716, \"end_index\": 15946, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch-lightning.txt\"}, {\"start_index\": 15714, \"end_index\": 16751, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 3128, \"corpus_id\": \"datasets/raydocs_full/data_inspecting-data.txt\"}, {\"start_index\": 2892, \"end_index\": 4840, \"corpus_id\": \"datasets/raydocs_full/data_inspecting-data.txt\"}, {\"start_index\": 2, \"end_index\": 4245, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-env.txt\"}, {\"start_index\": 3803, \"end_index\": 8149, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-env.txt\"}, {\"start_index\": 2, \"end_index\": 4023, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-batch-inference-example.txt\"}, {\"start_index\": 3790, \"end_index\": 5653, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-batch-inference-example.txt\"}, {\"start_index\": 2, \"end_index\": 2345, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_time.txt\"}, {\"start_index\": 2, \"end_index\": 367, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.models.distributions.Distribution.kl.txt\"}, {\"start_index\": 2, \"end_index\": 326, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.relu.txt\"}, {\"start_index\": 2, \"end_index\": 2934, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.add_policy.txt\"}, {\"start_index\": 2, \"end_index\": 531, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.softmax_cross_entropy_with_logits.txt\"}, {\"start_index\": 2, \"end_index\": 4783, \"corpus_id\": \"datasets/raydocs_full/data_shuffling-data.txt\"}, {\"start_index\": 4787, \"end_index\": 7388, \"corpus_id\": \"datasets/raydocs_full/data_shuffling-data.txt\"}, {\"start_index\": 2, \"end_index\": 2005, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_ray-get-loop.txt\"}, {\"start_index\": 2, \"end_index\": 78, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting.txt\"}, {\"start_index\": 2, \"end_index\": 413, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.set_state.txt\"}, {\"start_index\": 2, \"end_index\": 3774, \"corpus_id\": \"datasets/raydocs_full/ray-core_configure.txt\"}, {\"start_index\": 3481, \"end_index\": 6993, \"corpus_id\": \"datasets/raydocs_full/ray-core_configure.txt\"}, {\"start_index\": 6998, \"end_index\": 11338, \"corpus_id\": \"datasets/raydocs_full/ray-core_configure.txt\"}, {\"start_index\": 10939, \"end_index\": 15002, \"corpus_id\": \"datasets/raydocs_full/ray-core_configure.txt\"}, {\"start_index\": 2, \"end_index\": 544, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_start.txt\"}, {\"start_index\": 2, \"end_index\": 4324, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_checkpoints.txt\"}, {\"start_index\": 3955, \"end_index\": 8673, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_checkpoints.txt\"}, {\"start_index\": 8173, \"end_index\": 12992, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_checkpoints.txt\"}, {\"start_index\": 12755, \"end_index\": 17657, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_checkpoints.txt\"}, {\"start_index\": 17167, \"end_index\": 21680, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_checkpoints.txt\"}, {\"start_index\": 21352, \"end_index\": 22662, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_checkpoints.txt\"}, {\"start_index\": 2, \"end_index\": 94, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.aligned_array.txt\"}, {\"start_index\": 2, \"end_index\": 4660, \"corpus_id\": \"datasets/raydocs_full/serve_autoscaling-guide.txt\"}, {\"start_index\": 4435, \"end_index\": 6838, \"corpus_id\": \"datasets/raydocs_full/serve_autoscaling-guide.txt\"}, {\"start_index\": 2, \"end_index\": 4007, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_prometheus-grafana.txt\"}, {\"start_index\": 4011, \"end_index\": 8051, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_prometheus-grafana.txt\"}, {\"start_index\": 7980, \"end_index\": 11800, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_prometheus-grafana.txt\"}, {\"start_index\": 11805, \"end_index\": 15961, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_prometheus-grafana.txt\"}, {\"start_index\": 15582, \"end_index\": 17059, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_prometheus-grafana.txt\"}, {\"start_index\": 2, \"end_index\": 3672, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_profiling.txt\"}, {\"start_index\": 3674, \"end_index\": 5451, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_profiling.txt\"}, {\"start_index\": 2, \"end_index\": 3709, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_async_api.txt\"}, {\"start_index\": 3420, \"end_index\": 6646, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_async_api.txt\"}, {\"start_index\": 2, \"end_index\": 2359, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.flatten_inputs_to_1d_tensor.txt\"}, {\"start_index\": 2, \"end_index\": 853, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_overview.txt\"}, {\"start_index\": 2, \"end_index\": 1091, \"corpus_id\": \"datasets/raydocs_full/workflows_index.txt\"}, {\"start_index\": 2, \"end_index\": 3935, \"corpus_id\": \"datasets/raydocs_full/workflows_management.txt\"}, {\"start_index\": 3552, \"end_index\": 5183, \"corpus_id\": \"datasets/raydocs_full/workflows_management.txt\"}, {\"start_index\": 2, \"end_index\": 4005, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_terminating-actors.txt\"}, {\"start_index\": 3707, \"end_index\": 5407, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_terminating-actors.txt\"}, {\"start_index\": 2, \"end_index\": 3445, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_vllm-rayservice.txt\"}, {\"start_index\": 3265, \"end_index\": 4758, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_vllm-rayservice.txt\"}, {\"start_index\": 2, \"end_index\": 4512, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_parameter_server.txt\"}, {\"start_index\": 4196, \"end_index\": 8429, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_parameter_server.txt\"}, {\"start_index\": 8133, \"end_index\": 8966, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_parameter_server.txt\"}, {\"start_index\": 2, \"end_index\": 4129, \"corpus_id\": \"datasets/raydocs_full/workflows_key-concepts.txt\"}, {\"start_index\": 3700, \"end_index\": 4303, \"corpus_id\": \"datasets/raydocs_full/workflows_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 3875, \"corpus_id\": \"datasets/raydocs_full/ray-core_user-spawn-processes.txt\"}, {\"start_index\": 3880, \"end_index\": 5584, \"corpus_id\": \"datasets/raydocs_full/ray-core_user-spawn-processes.txt\"}, {\"start_index\": 2, \"end_index\": 4459, \"corpus_id\": \"datasets/raydocs_full/tune_examples_optuna_example.txt\"}, {\"start_index\": 4159, \"end_index\": 7217, \"corpus_id\": \"datasets/raydocs_full/tune_examples_optuna_example.txt\"}, {\"start_index\": 6851, \"end_index\": 9857, \"corpus_id\": \"datasets/raydocs_full/tune_examples_optuna_example.txt\"}, {\"start_index\": 9533, \"end_index\": 12598, \"corpus_id\": \"datasets/raydocs_full/tune_examples_optuna_example.txt\"}, {\"start_index\": 12547, \"end_index\": 14382, \"corpus_id\": \"datasets/raydocs_full/tune_examples_optuna_example.txt\"}, {\"start_index\": 14135, \"end_index\": 16573, \"corpus_id\": \"datasets/raydocs_full/tune_examples_optuna_example.txt\"}, {\"start_index\": 2, \"end_index\": 991, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_user-guides_launching-clusters_index.txt\"}, {\"start_index\": 2, \"end_index\": 2576, \"corpus_id\": \"datasets/raydocs_full/train_overview.txt\"}, {\"start_index\": 2, \"end_index\": 717, \"corpus_id\": \"datasets/raydocs_full/rllib_user-guides.txt\"}, {\"start_index\": 2, \"end_index\": 4271, \"corpus_id\": \"datasets/raydocs_full/workflows_basics.txt\"}, {\"start_index\": 3877, \"end_index\": 8203, \"corpus_id\": \"datasets/raydocs_full/workflows_basics.txt\"}, {\"start_index\": 7823, \"end_index\": 11869, \"corpus_id\": \"datasets/raydocs_full/workflows_basics.txt\"}, {\"start_index\": 11874, \"end_index\": 13482, \"corpus_id\": \"datasets/raydocs_full/workflows_basics.txt\"}, {\"start_index\": 2, \"end_index\": 4013, \"corpus_id\": \"datasets/raydocs_full/data_saving-data.txt\"}, {\"start_index\": 3708, \"end_index\": 5423, \"corpus_id\": \"datasets/raydocs_full/data_saving-data.txt\"}, {\"start_index\": 5426, \"end_index\": 6493, \"corpus_id\": \"datasets/raydocs_full/data_saving-data.txt\"}, {\"start_index\": 6405, \"end_index\": 7294, \"corpus_id\": \"datasets/raydocs_full/data_saving-data.txt\"}, {\"start_index\": 2, \"end_index\": 4013, \"corpus_id\": \"datasets/raydocs_full/data_saving-data.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/data_saving-data.txt\"}, {\"start_index\": 2, \"end_index\": 4488, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-callback.txt\"}, {\"start_index\": 4056, \"end_index\": 8420, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-callback.txt\"}, {\"start_index\": 8018, \"end_index\": 12103, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-callback.txt\"}, {\"start_index\": 2, \"end_index\": 4397, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_data-loading-preprocessing.txt\"}, {\"start_index\": 4115, \"end_index\": 8572, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_data-loading-preprocessing.txt\"}, {\"start_index\": 8183, \"end_index\": 12342, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_data-loading-preprocessing.txt\"}, {\"start_index\": 11987, \"end_index\": 16410, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_data-loading-preprocessing.txt\"}, {\"start_index\": 16050, \"end_index\": 20625, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_data-loading-preprocessing.txt\"}, {\"start_index\": 20253, \"end_index\": 22178, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_data-loading-preprocessing.txt\"}, {\"start_index\": 2, \"end_index\": 4180, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 4182, \"end_index\": 8543, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 8030, \"end_index\": 10851, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 10853, \"end_index\": 14811, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 14196, \"end_index\": 15657, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 2, \"end_index\": 4180, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 4182, \"end_index\": 8543, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 16385, \"end_index\": 19919, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 19772, \"end_index\": 23383, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 23019, \"end_index\": 26526, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 26426, \"end_index\": 29791, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_fault-tolerance.txt\"}, {\"start_index\": 2, \"end_index\": 4528, \"corpus_id\": \"datasets/raydocs_full/workflows_events.txt\"}, {\"start_index\": 4067, \"end_index\": 6332, \"corpus_id\": \"datasets/raydocs_full/workflows_events.txt\"}, {\"start_index\": 2, \"end_index\": 2627, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_limit-running-tasks.txt\"}, {\"start_index\": 2, \"end_index\": 819, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.from_checkpoint.txt\"}, {\"start_index\": 2, \"end_index\": 654, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.one_hot.txt\"}, {\"start_index\": 2, \"end_index\": 4254, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 3825, \"end_index\": 5980, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 5985, \"end_index\": 8269, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 8275, \"end_index\": 10356, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 10359, \"end_index\": 12863, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 12689, \"end_index\": 13551, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 2, \"end_index\": 4254, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 3825, \"end_index\": 5980, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 5985, \"end_index\": 8269, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 14630, \"end_index\": 17769, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_distributed-checkpointing-with-gcsfuse.txt\"}, {\"start_index\": 2, \"end_index\": 500, \"corpus_id\": \"datasets/raydocs_full/data_api_llm.txt\"}, {\"start_index\": 2, \"end_index\": 4095, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_yunikorn.txt\"}, {\"start_index\": 3746, \"end_index\": 7118, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_yunikorn.txt\"}, {\"start_index\": 2, \"end_index\": 1386, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.models.distributions.Distribution.txt\"}, {\"start_index\": 2, \"end_index\": 3220, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-aim.txt\"}, {\"start_index\": 3206, \"end_index\": 3558, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-aim.txt\"}, {\"start_index\": 3561, \"end_index\": 6000, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-aim.txt\"}, {\"start_index\": 6001, \"end_index\": 6305, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-aim.txt\"}, {\"start_index\": 2, \"end_index\": 3220, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-aim.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-aim.txt\"}, {\"start_index\": 2, \"end_index\": 2156, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_ci.txt\"}, {\"start_index\": 2, \"end_index\": 543, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.explained_variance.txt\"}, {\"start_index\": 2, \"end_index\": 1652, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.restore_from_path.txt\"}, {\"start_index\": 2, \"end_index\": 4046, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-fault-tolerance.txt\"}, {\"start_index\": 2, \"end_index\": 3839, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.txt\"}, {\"start_index\": 3483, \"end_index\": 4751, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.txt\"}, {\"start_index\": 2, \"end_index\": 3782, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_ingress.txt\"}, {\"start_index\": 3787, \"end_index\": 7465, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_ingress.txt\"}, {\"start_index\": 7220, \"end_index\": 7702, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_ingress.txt\"}, {\"start_index\": 2, \"end_index\": 1433, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env.txt\"}, {\"start_index\": 2, \"end_index\": 1787, \"corpus_id\": \"datasets/raydocs_full/tune_api_cli.txt\"}, {\"start_index\": 2, \"end_index\": 4616, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_managing-java-deployments.txt\"}, {\"start_index\": 4200, \"end_index\": 4986, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_managing-java-deployments.txt\"}, {\"start_index\": 2, \"end_index\": 1098, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.sample.txt\"}, {\"start_index\": 2, \"end_index\": 134, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.build.txt\"}, {\"start_index\": 2, \"end_index\": 3177, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_overlap.txt\"}, {\"start_index\": 2, \"end_index\": 4623, \"corpus_id\": \"datasets/raydocs_full/ray-core_objects_serialization.txt\"}, {\"start_index\": 4383, \"end_index\": 8503, \"corpus_id\": \"datasets/raydocs_full/ray-core_objects_serialization.txt\"}, {\"start_index\": 8212, \"end_index\": 10994, \"corpus_id\": \"datasets/raydocs_full/ray-core_objects_serialization.txt\"}, {\"start_index\": 2, \"end_index\": 3219, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_multi_agent_env_runner.txt\"}, {\"start_index\": 2, \"end_index\": 1816, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner.txt\"}, {\"start_index\": 2, \"end_index\": 3822, \"corpus_id\": \"datasets/raydocs_full/ray-core_ray-dag.txt\"}, {\"start_index\": 3635, \"end_index\": 6145, \"corpus_id\": \"datasets/raydocs_full/ray-core_ray-dag.txt\"}, {\"start_index\": 2, \"end_index\": 192, \"corpus_id\": \"datasets/raydocs_full/tune_api_syncing.txt\"}, {\"start_index\": 2, \"end_index\": 4217, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_profiling.txt\"}, {\"start_index\": 3905, \"end_index\": 6035, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_profiling.txt\"}, {\"start_index\": 2, \"end_index\": 3481, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_raydp.txt\"}, {\"start_index\": 2, \"end_index\": 4088, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-kueue-priority-scheduling.txt\"}, {\"start_index\": 3802, \"end_index\": 6752, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-kueue-priority-scheduling.txt\"}, {\"start_index\": 6755, \"end_index\": 9176, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-kueue-priority-scheduling.txt\"}, {\"start_index\": 2, \"end_index\": 855, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.make_action_immutable.txt\"}, {\"start_index\": 2, \"end_index\": 407, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_rl_module_spec.txt\"}, {\"start_index\": 2, \"end_index\": 736, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_sample_end.txt\"}, {\"start_index\": 2, \"end_index\": 1453, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_debug-hangs.txt\"}, {\"start_index\": 2, \"end_index\": 4807, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-examples.txt\"}, {\"start_index\": 4475, \"end_index\": 9669, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-examples.txt\"}, {\"start_index\": 9090, \"end_index\": 14204, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-examples.txt\"}, {\"start_index\": 13734, \"end_index\": 18209, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-examples.txt\"}, {\"start_index\": 17853, \"end_index\": 20231, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-examples.txt\"}, {\"start_index\": 2, \"end_index\": 4202, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch.txt\"}, {\"start_index\": 3873, \"end_index\": 8185, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch.txt\"}, {\"start_index\": 7848, \"end_index\": 12391, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-pytorch.txt\"}, {\"start_index\": 2, \"end_index\": 4143, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_monitoring-logging.txt\"}, {\"start_index\": 3790, \"end_index\": 6326, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_monitoring-logging.txt\"}, {\"start_index\": 2, \"end_index\": 4476, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_optimize-performance.txt\"}, {\"start_index\": 4296, \"end_index\": 7913, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_optimize-performance.txt\"}, {\"start_index\": 7919, \"end_index\": 10897, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_optimize-performance.txt\"}, {\"start_index\": 10572, \"end_index\": 12724, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_optimize-performance.txt\"}, {\"start_index\": 2, \"end_index\": 819, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.sequence_mask.txt\"}, {\"start_index\": 2, \"end_index\": 3778, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-scalability.txt\"}, {\"start_index\": 3597, \"end_index\": 6101, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-scalability.txt\"}, {\"start_index\": 2, \"end_index\": 2718, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 2392, \"end_index\": 6438, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 6441, \"end_index\": 10204, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 3920, \"end_index\": 3931, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 10220, \"end_index\": 14182, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 13910, \"end_index\": 15263, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 2, \"end_index\": 2718, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 2392, \"end_index\": 6438, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 6441, \"end_index\": 10204, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 18756, \"end_index\": 22525, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 22107, \"end_index\": 26132, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 25711, \"end_index\": 26634, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 2, \"end_index\": 2718, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 2392, \"end_index\": 6438, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 6441, \"end_index\": 10204, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 30137, \"end_index\": 34214, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 33952, \"end_index\": 37292, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 37281, \"end_index\": 41694, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 41596, \"end_index\": 45074, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 45063, \"end_index\": 49239, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 48980, \"end_index\": 52378, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 52367, \"end_index\": 54351, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-algorithms.txt\"}, {\"start_index\": 2, \"end_index\": 3371, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_volcano.txt\"}, {\"start_index\": 3374, \"end_index\": 6664, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_volcano.txt\"}, {\"start_index\": 6510, \"end_index\": 9510, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_volcano.txt\"}, {\"start_index\": 9216, \"end_index\": 11260, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_volcano.txt\"}, {\"start_index\": 2, \"end_index\": 1769, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_rest.txt\"}, {\"start_index\": 2, \"end_index\": 1964, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_autoscaling_reference.txt\"}, {\"start_index\": 2, \"end_index\": 1159, \"corpus_id\": \"datasets/raydocs_full/data_api_api.txt\"}, {\"start_index\": 2, \"end_index\": 4055, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_cli.txt\"}, {\"start_index\": 3625, \"end_index\": 7465, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_cli.txt\"}, {\"start_index\": 7080, \"end_index\": 8757, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_cli.txt\"}, {\"start_index\": 2, \"end_index\": 3916, \"corpus_id\": \"datasets/raydocs_full/ray-core_cross-language.txt\"}, {\"start_index\": 3666, \"end_index\": 6685, \"corpus_id\": \"datasets/raydocs_full/ray-core_cross-language.txt\"}, {\"start_index\": 6298, \"end_index\": 7826, \"corpus_id\": \"datasets/raydocs_full/ray-core_cross-language.txt\"}, {\"start_index\": 2, \"end_index\": 1075, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.prioritized_replay_buffer.PrioritizedReplayBuffer.txt\"}, {\"start_index\": 2, \"end_index\": 4786, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_docs.txt\"}, {\"start_index\": 4659, \"end_index\": 9202, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_docs.txt\"}, {\"start_index\": 8898, \"end_index\": 13144, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_docs.txt\"}, {\"start_index\": 12949, \"end_index\": 16818, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_docs.txt\"}, {\"start_index\": 16465, \"end_index\": 20403, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_docs.txt\"}, {\"start_index\": 2, \"end_index\": 1173, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_user-guides_logging.txt\"}, {\"start_index\": 2, \"end_index\": 291, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_data.OfflineData.txt\"}, {\"start_index\": 2, \"end_index\": 623, \"corpus_id\": \"datasets/raydocs_full/data_api_grouped_data.txt\"}, {\"start_index\": 2, \"end_index\": 3175, \"corpus_id\": \"datasets/raydocs_full/tune_examples_horovod_simple.txt\"}, {\"start_index\": 2807, \"end_index\": 4124, \"corpus_id\": \"datasets/raydocs_full/tune_examples_horovod_simple.txt\"}, {\"start_index\": 2, \"end_index\": 4047, \"corpus_id\": \"datasets/raydocs_full/cluster_faq.txt\"}, {\"start_index\": 2, \"end_index\": 803, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.from_checkpoint.txt\"}, {\"start_index\": 2, \"end_index\": 733, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_sample_batch_to_episode.txt\"}, {\"start_index\": 2, \"end_index\": 2867, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_callback.txt\"}, {\"start_index\": 2, \"end_index\": 3834, \"corpus_id\": \"datasets/raydocs_full/ray-security_index.txt\"}, {\"start_index\": 2, \"end_index\": 4335, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_using-gpus.txt\"}, {\"start_index\": 4214, \"end_index\": 5952, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_using-gpus.txt\"}, {\"start_index\": 2, \"end_index\": 4514, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune_get_data_in_and_out.txt\"}, {\"start_index\": 4450, \"end_index\": 8526, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune_get_data_in_and_out.txt\"}, {\"start_index\": 8094, \"end_index\": 12173, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune_get_data_in_and_out.txt\"}, {\"start_index\": 12176, \"end_index\": 16467, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune_get_data_in_and_out.txt\"}, {\"start_index\": 16173, \"end_index\": 18557, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune_get_data_in_and_out.txt\"}, {\"start_index\": 2, \"end_index\": 3813, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_concurrency_group_api.txt\"}, {\"start_index\": 3505, \"end_index\": 5143, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_concurrency_group_api.txt\"}, {\"start_index\": 2, \"end_index\": 114, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module_spec.txt\"}, {\"start_index\": 2, \"end_index\": 1389, \"corpus_id\": \"datasets/raydocs_full/ray-core_objects_object-spilling.txt\"}, {\"start_index\": 2, \"end_index\": 685, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_k8s-cluster-setup.txt\"}, {\"start_index\": 2, \"end_index\": 3997, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_multi-app-container.txt\"}, {\"start_index\": 3678, \"end_index\": 7959, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_multi-app-container.txt\"}, {\"start_index\": 7529, \"end_index\": 8309, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_multi-app-container.txt\"}, {\"start_index\": 2, \"end_index\": 2553, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_agent_setup.txt\"}, {\"start_index\": 2, \"end_index\": 3491, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_dev-workflow.txt\"}, {\"start_index\": 3495, \"end_index\": 7275, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_dev-workflow.txt\"}, {\"start_index\": 2, \"end_index\": 1082, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner.txt\"}, {\"start_index\": 2, \"end_index\": 2820, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_end.txt\"}, {\"start_index\": 2, \"end_index\": 3184, \"corpus_id\": \"datasets/raydocs_full/ray-core_api_exceptions.txt\"}, {\"start_index\": 2, \"end_index\": 4633, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 4287, \"end_index\": 8713, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 8362, \"end_index\": 12632, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 12473, \"end_index\": 16239, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 16241, \"end_index\": 20329, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 20332, \"end_index\": 23505, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 23508, \"end_index\": 27503, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 27506, \"end_index\": 31980, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 31870, \"end_index\": 35242, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 35104, \"end_index\": 39577, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 39477, \"end_index\": 43817, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 43447, \"end_index\": 48145, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 47934, \"end_index\": 48867, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 48870, \"end_index\": 51605, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 51606, \"end_index\": 53592, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 2, \"end_index\": 4633, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 4287, \"end_index\": 8713, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 8362, \"end_index\": 12632, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 12473, \"end_index\": 16239, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 16241, \"end_index\": 20329, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 20332, \"end_index\": 23505, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 23508, \"end_index\": 27503, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 27506, \"end_index\": 31980, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 31870, \"end_index\": 35242, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 35104, \"end_index\": 39577, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 39477, \"end_index\": 43817, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 43447, \"end_index\": 48145, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/ray-core_handling-dependencies.txt\"}, {\"start_index\": 2, \"end_index\": 4831, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 4443, \"end_index\": 9083, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 8702, \"end_index\": 12731, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 12369, \"end_index\": 15912, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 15493, \"end_index\": 18494, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 18497, \"end_index\": 22624, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 22265, \"end_index\": 26590, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 26172, \"end_index\": 30461, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 30096, \"end_index\": 31775, \"corpus_id\": \"datasets/raydocs_full/serve_monitoring.txt\"}, {\"start_index\": 2, \"end_index\": 3857, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-xgboost.txt\"}, {\"start_index\": 3720, \"end_index\": 7725, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-xgboost.txt\"}, {\"start_index\": 7728, \"end_index\": 12138, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-xgboost.txt\"}, {\"start_index\": 11995, \"end_index\": 12364, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-xgboost.txt\"}, {\"start_index\": 2, \"end_index\": 3744, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_ray-debugging.txt\"}, {\"start_index\": 3411, \"end_index\": 6663, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_ray-debugging.txt\"}, {\"start_index\": 6378, \"end_index\": 9238, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_ray-debugging.txt\"}, {\"start_index\": 2, \"end_index\": 3776, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_cli-sdk.txt\"}, {\"start_index\": 3421, \"end_index\": 6865, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_cli-sdk.txt\"}, {\"start_index\": 6561, \"end_index\": 10279, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_cli-sdk.txt\"}, {\"start_index\": 9940, \"end_index\": 13767, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_cli-sdk.txt\"}, {\"start_index\": 13342, \"end_index\": 16362, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_cli-sdk.txt\"}, {\"start_index\": 2, \"end_index\": 358, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.setup.txt\"}, {\"start_index\": 2, \"end_index\": 1312, \"corpus_id\": \"datasets/raydocs_full/tune_api_callbacks.txt\"}, {\"start_index\": 2, \"end_index\": 3995, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_kubernetes.txt\"}, {\"start_index\": 3973, \"end_index\": 8151, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_kubernetes.txt\"}, {\"start_index\": 8155, \"end_index\": 12300, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_kubernetes.txt\"}, {\"start_index\": 2, \"end_index\": 2723, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_debug-memory.txt\"}, {\"start_index\": 2304, \"end_index\": 5767, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_debug-memory.txt\"}, {\"start_index\": 5770, \"end_index\": 10113, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_debug-memory.txt\"}, {\"start_index\": 9997, \"end_index\": 10779, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_debug-memory.txt\"}, {\"start_index\": 2, \"end_index\": 477, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_reproducibility.txt\"}, {\"start_index\": 2, \"end_index\": 125, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_data.OfflineData.default_iter_batches_kwargs.txt\"}, {\"start_index\": 2, \"end_index\": 3448, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-output.txt\"}, {\"start_index\": 3453, \"end_index\": 7997, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-output.txt\"}, {\"start_index\": 7568, \"end_index\": 10783, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-output.txt\"}, {\"start_index\": 2, \"end_index\": 1451, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_env_runner.txt\"}, {\"start_index\": 2, \"end_index\": 1609, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer.txt\"}, {\"start_index\": 2, \"end_index\": 4123, \"corpus_id\": \"datasets/raydocs_full/train_huggingface-accelerate.txt\"}, {\"start_index\": 3743, \"end_index\": 8166, \"corpus_id\": \"datasets/raydocs_full/train_huggingface-accelerate.txt\"}, {\"start_index\": 7826, \"end_index\": 12251, \"corpus_id\": \"datasets/raydocs_full/train_huggingface-accelerate.txt\"}, {\"start_index\": 12032, \"end_index\": 15821, \"corpus_id\": \"datasets/raydocs_full/train_huggingface-accelerate.txt\"}, {\"start_index\": 2, \"end_index\": 4217, \"corpus_id\": \"datasets/raydocs_full/rllib_scaling-guide.txt\"}, {\"start_index\": 3995, \"end_index\": 6681, \"corpus_id\": \"datasets/raydocs_full/rllib_scaling-guide.txt\"}, {\"start_index\": 2, \"end_index\": 4086, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-learner.txt\"}, {\"start_index\": 3810, \"end_index\": 8079, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-learner.txt\"}, {\"start_index\": 7722, \"end_index\": 9285, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-learner.txt\"}, {\"start_index\": 2, \"end_index\": 388, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.schedules.scheduler.Scheduler.get_current_value.txt\"}, {\"start_index\": 2, \"end_index\": 4468, \"corpus_id\": \"datasets/raydocs_full/cluster_metrics.txt\"}, {\"start_index\": 4214, \"end_index\": 8589, \"corpus_id\": \"datasets/raydocs_full/cluster_metrics.txt\"}, {\"start_index\": 8374, \"end_index\": 12051, \"corpus_id\": \"datasets/raydocs_full/cluster_metrics.txt\"}, {\"start_index\": 11774, \"end_index\": 15241, \"corpus_id\": \"datasets/raydocs_full/cluster_metrics.txt\"}, {\"start_index\": 2, \"end_index\": 654, \"corpus_id\": \"datasets/raydocs_full/tune_api_result_grid.txt\"}, {\"start_index\": 2, \"end_index\": 3969, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_transformers.txt\"}, {\"start_index\": 3641, \"end_index\": 6631, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_transformers.txt\"}, {\"start_index\": 2, \"end_index\": 3989, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 3832, \"end_index\": 7767, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 7404, \"end_index\": 11481, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 11084, \"end_index\": 15079, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 14733, \"end_index\": 18620, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 18623, \"end_index\": 22492, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 22120, \"end_index\": 25734, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 25655, \"end_index\": 29866, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 29450, \"end_index\": 33599, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 33233, \"end_index\": 37133, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 36822, \"end_index\": 37968, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 37664, \"end_index\": 42017, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 41658, \"end_index\": 44971, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 44592, \"end_index\": 48664, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 48670, \"end_index\": 52570, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 52474, \"end_index\": 56271, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 56125, \"end_index\": 60041, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 59853, \"end_index\": 62955, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 62583, \"end_index\": 66804, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 66461, \"end_index\": 68749, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-configuration.txt\"}, {\"start_index\": 2, \"end_index\": 619, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_algorithm_init.txt\"}, {\"start_index\": 2, \"end_index\": 3673, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 3439, \"end_index\": 5451, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 5453, \"end_index\": 7898, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 7693, \"end_index\": 10143, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 9938, \"end_index\": 12358, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 12124, \"end_index\": 14624, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 14383, \"end_index\": 15212, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 2, \"end_index\": 3673, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 3439, \"end_index\": 5451, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 15218, \"end_index\": 17674, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 17432, \"end_index\": 19924, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 19709, \"end_index\": 22190, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 21958, \"end_index\": 24434, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 2, \"end_index\": 3673, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 3439, \"end_index\": 5451, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 24440, \"end_index\": 26947, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 26715, \"end_index\": 28483, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 2, \"end_index\": 3673, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_bayesopt_example.txt\"}, {\"start_index\": 2, \"end_index\": 783, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.models.distributions.Distribution.rsample.txt\"}, {\"start_index\": 2, \"end_index\": 1781, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_step.txt\"}, {\"start_index\": 2, \"end_index\": 2767, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_istio.txt\"}, {\"start_index\": 2487, \"end_index\": 5036, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_istio.txt\"}, {\"start_index\": 4760, \"end_index\": 8030, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_istio.txt\"}, {\"start_index\": 7790, \"end_index\": 9285, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_istio.txt\"}, {\"start_index\": 2, \"end_index\": 3814, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_config.txt\"}, {\"start_index\": 3514, \"end_index\": 8188, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_config.txt\"}, {\"start_index\": 7972, \"end_index\": 9022, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_config.txt\"}, {\"start_index\": 2, \"end_index\": 189, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_data.OfflineData.sample.txt\"}, {\"start_index\": 2, \"end_index\": 3714, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice-high-availability.txt\"}, {\"start_index\": 3570, \"end_index\": 4546, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice-high-availability.txt\"}, {\"start_index\": 2, \"end_index\": 395, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.copy.txt\"}, {\"start_index\": 2, \"end_index\": 403, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_examples_index.txt\"}, {\"start_index\": 2, \"end_index\": 625, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.RayDaskCallback.txt\"}, {\"start_index\": 2, \"end_index\": 1206, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.get_state.txt\"}, {\"start_index\": 2, \"end_index\": 4466, \"corpus_id\": \"datasets/raydocs_full/data_performance-tips.txt\"}, {\"start_index\": 4468, \"end_index\": 8847, \"corpus_id\": \"datasets/raydocs_full/data_performance-tips.txt\"}, {\"start_index\": 8602, \"end_index\": 12302, \"corpus_id\": \"datasets/raydocs_full/data_performance-tips.txt\"}, {\"start_index\": 12305, \"end_index\": 15870, \"corpus_id\": \"datasets/raydocs_full/data_performance-tips.txt\"}, {\"start_index\": 2, \"end_index\": 4055, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_rayservice-quick-start.txt\"}, {\"start_index\": 3796, \"end_index\": 5458, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_rayservice-quick-start.txt\"}, {\"start_index\": 2, \"end_index\": 3072, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_out-of-band-object-ref-serialization.txt\"}, {\"start_index\": 2, \"end_index\": 4774, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-lifecycle.txt\"}, {\"start_index\": 4754, \"end_index\": 7405, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-lifecycle.txt\"}, {\"start_index\": 2, \"end_index\": 1361, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_jobs-package-ref.txt\"}, {\"start_index\": 2, \"end_index\": 474, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule._forward_train.txt\"}, {\"start_index\": 2, \"end_index\": 1353, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.from_checkpoint.txt\"}, {\"start_index\": 2, \"end_index\": 4296, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice.txt\"}, {\"start_index\": 3959, \"end_index\": 7651, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice.txt\"}, {\"start_index\": 7503, \"end_index\": 11445, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice.txt\"}, {\"start_index\": 11320, \"end_index\": 13178, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice.txt\"}, {\"start_index\": 2, \"end_index\": 1821, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.save_to_path.txt\"}, {\"start_index\": 2, \"end_index\": 2451, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.txt\"}, {\"start_index\": 2, \"end_index\": 4173, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-mlflow.txt\"}, {\"start_index\": 3837, \"end_index\": 6990, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-mlflow.txt\"}, {\"start_index\": 6579, \"end_index\": 9330, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-mlflow.txt\"}, {\"start_index\": 9049, \"end_index\": 10397, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-mlflow.txt\"}, {\"start_index\": 9979, \"end_index\": 12682, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-mlflow.txt\"}, {\"start_index\": 12372, \"end_index\": 16389, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-mlflow.txt\"}, {\"start_index\": 16378, \"end_index\": 19321, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-mlflow.txt\"}, {\"start_index\": 2, \"end_index\": 3323, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_upgrade-guide.txt\"}, {\"start_index\": 2, \"end_index\": 4286, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-torch2x.txt\"}, {\"start_index\": 4289, \"end_index\": 4805, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-torch2x.txt\"}, {\"start_index\": 2, \"end_index\": 3903, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_rayservice-troubleshooting.txt\"}, {\"start_index\": 3600, \"end_index\": 7733, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_rayservice-troubleshooting.txt\"}, {\"start_index\": 7414, \"end_index\": 10627, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_rayservice-troubleshooting.txt\"}, {\"start_index\": 10341, \"end_index\": 13631, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_rayservice-troubleshooting.txt\"}, {\"start_index\": 13220, \"end_index\": 17248, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_rayservice-troubleshooting.txt\"}, {\"start_index\": 17252, \"end_index\": 19583, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_rayservice-troubleshooting.txt\"}, {\"start_index\": 2, \"end_index\": 965, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_compiled-graph-api.txt\"}, {\"start_index\": 2, \"end_index\": 2080, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_env_runners_recreated.txt\"}, {\"start_index\": 2, \"end_index\": 4601, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 4148, \"end_index\": 8413, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 8106, \"end_index\": 12374, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 11989, \"end_index\": 16206, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 16089, \"end_index\": 20081, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 19992, \"end_index\": 23877, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 23491, \"end_index\": 27822, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 27536, \"end_index\": 31969, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 31863, \"end_index\": 32331, \"corpus_id\": \"datasets/raydocs_full/ray-overview_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 3677, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_writing-code-snippets.txt\"}, {\"start_index\": 3506, \"end_index\": 7214, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_writing-code-snippets.txt\"}, {\"start_index\": 2, \"end_index\": 612, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit.txt\"}, {\"start_index\": 2, \"end_index\": 3736, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_raycluster-quick-start.txt\"}, {\"start_index\": 3289, \"end_index\": 6127, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started_raycluster-quick-start.txt\"}, {\"start_index\": 2, \"end_index\": 844, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_to_episodes.txt\"}, {\"start_index\": 2, \"end_index\": 4268, \"corpus_id\": \"datasets/raydocs_full/ray-observability_ray-distributed-debugger.txt\"}, {\"start_index\": 4065, \"end_index\": 4867, \"corpus_id\": \"datasets/raydocs_full/ray-observability_ray-distributed-debugger.txt\"}, {\"start_index\": 2, \"end_index\": 4666, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-storage.txt\"}, {\"start_index\": 4189, \"end_index\": 7131, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-storage.txt\"}, {\"start_index\": 2, \"end_index\": 2073, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_configure-logging.txt\"}, {\"start_index\": 1738, \"end_index\": 6216, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_configure-logging.txt\"}, {\"start_index\": 6083, \"end_index\": 9655, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_configure-logging.txt\"}, {\"start_index\": 9439, \"end_index\": 13747, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_configure-logging.txt\"}, {\"start_index\": 13250, \"end_index\": 17642, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_configure-logging.txt\"}, {\"start_index\": 17218, \"end_index\": 20538, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_configure-logging.txt\"}, {\"start_index\": 20089, \"end_index\": 23655, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_configure-logging.txt\"}, {\"start_index\": 2, \"end_index\": 1874, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_replay-buffers.txt\"}, {\"start_index\": 2, \"end_index\": 333, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.callbacks.RayDaskCallback._ray_finish.txt\"}, {\"start_index\": 2, \"end_index\": 4467, \"corpus_id\": \"datasets/raydocs_full/train_distributed-tensorflow-keras.txt\"}, {\"start_index\": 4470, \"end_index\": 9147, \"corpus_id\": \"datasets/raydocs_full/train_distributed-tensorflow-keras.txt\"}, {\"start_index\": 8731, \"end_index\": 12124, \"corpus_id\": \"datasets/raydocs_full/train_distributed-tensorflow-keras.txt\"}, {\"start_index\": 2, \"end_index\": 4073, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_pod-command.txt\"}, {\"start_index\": 3930, \"end_index\": 5099, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_pod-command.txt\"}, {\"start_index\": 2, \"end_index\": 291, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.as_multi_rl_module.txt\"}, {\"start_index\": 2, \"end_index\": 4432, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_index.txt\"}, {\"start_index\": 4266, \"end_index\": 5963, \"corpus_id\": \"datasets/raydocs_full/serve_production-guide_index.txt\"}, {\"start_index\": 2, \"end_index\": 1069, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.one_hot.txt\"}, {\"start_index\": 2, \"end_index\": 4098, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_hyperparameter.txt\"}, {\"start_index\": 3771, \"end_index\": 6935, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_plot_hyperparameter.txt\"}, {\"start_index\": 2, \"end_index\": 467, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.reduce_mean_ignore_inf.txt\"}, {\"start_index\": 2, \"end_index\": 2325, \"corpus_id\": \"datasets/raydocs_full/rllib_hierarchical-envs.txt\"}, {\"start_index\": 2, \"end_index\": 2984, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_app-builder-guide.txt\"}, {\"start_index\": 2671, \"end_index\": 5886, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_app-builder-guide.txt\"}, {\"start_index\": 5870, \"end_index\": 7217, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_app-builder-guide.txt\"}, {\"start_index\": 2, \"end_index\": 4760, \"corpus_id\": \"datasets/raydocs_full/ray-overview_index.txt\"}, {\"start_index\": 2, \"end_index\": 4333, \"corpus_id\": \"datasets/raydocs_full/tune_getting-started.txt\"}, {\"start_index\": 4128, \"end_index\": 8542, \"corpus_id\": \"datasets/raydocs_full/tune_getting-started.txt\"}, {\"start_index\": 8364, \"end_index\": 9735, \"corpus_id\": \"datasets/raydocs_full/tune_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 311, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner.__init__.txt\"}, {\"start_index\": 2, \"end_index\": 4286, \"corpus_id\": \"datasets/raydocs_full/tune_api_trainable.txt\"}, {\"start_index\": 3929, \"end_index\": 8237, \"corpus_id\": \"datasets/raydocs_full/tune_api_trainable.txt\"}, {\"start_index\": 7805, \"end_index\": 9713, \"corpus_id\": \"datasets/raydocs_full/tune_api_trainable.txt\"}, {\"start_index\": 2, \"end_index\": 902, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.utils.update_priorities_in_replay_buffer.txt\"}, {\"start_index\": 2, \"end_index\": 4337, \"corpus_id\": \"datasets/raydocs_full/tune_api_schedulers.txt\"}, {\"start_index\": 3911, \"end_index\": 8171, \"corpus_id\": \"datasets/raydocs_full/tune_api_schedulers.txt\"}, {\"start_index\": 8109, \"end_index\": 10607, \"corpus_id\": \"datasets/raydocs_full/tune_api_schedulers.txt\"}, {\"start_index\": 2, \"end_index\": 405, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.schedules.scheduler.Scheduler.update.txt\"}, {\"start_index\": 2, \"end_index\": 4166, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_user-guides_large-cluster-best-practices.txt\"}, {\"start_index\": 4149, \"end_index\": 5220, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_user-guides_large-cluster-best-practices.txt\"}, {\"start_index\": 2, \"end_index\": 4242, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_tpu.txt\"}, {\"start_index\": 4209, \"end_index\": 4332, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_tpu.txt\"}, {\"start_index\": 2, \"end_index\": 3872, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_batch_prediction.txt\"}, {\"start_index\": 3745, \"end_index\": 8065, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_batch_prediction.txt\"}, {\"start_index\": 7712, \"end_index\": 9970, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_batch_prediction.txt\"}, {\"start_index\": 2, \"end_index\": 4511, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_debug-failures.txt\"}, {\"start_index\": 4148, \"end_index\": 4941, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_debug-apps_debug-failures.txt\"}, {\"start_index\": 2, \"end_index\": 3379, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_add-app-metrics.txt\"}, {\"start_index\": 2, \"end_index\": 4042, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-cifar.txt\"}, {\"start_index\": 4048, \"end_index\": 8424, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-cifar.txt\"}, {\"start_index\": 8083, \"end_index\": 12037, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-cifar.txt\"}, {\"start_index\": 11824, \"end_index\": 14789, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-cifar.txt\"}, {\"start_index\": 14489, \"end_index\": 15219, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-cifar.txt\"}, {\"start_index\": 2, \"end_index\": 447, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner.__call__.txt\"}, {\"start_index\": 2, \"end_index\": 3305, \"corpus_id\": \"datasets/raydocs_full/data_api_data_context.txt\"}, {\"start_index\": 3307, \"end_index\": 7880, \"corpus_id\": \"datasets/raydocs_full/data_api_data_context.txt\"}, {\"start_index\": 7434, \"end_index\": 8527, \"corpus_id\": \"datasets/raydocs_full/data_api_data_context.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/data_api_data_context.txt\"}, {\"start_index\": 2, \"end_index\": 4306, \"corpus_id\": \"datasets/raydocs_full/data_execution-configurations.txt\"}, {\"start_index\": 2, \"end_index\": 3910, \"corpus_id\": \"datasets/raydocs_full/ray-core_namespaces.txt\"}, {\"start_index\": 3595, \"end_index\": 7729, \"corpus_id\": \"datasets/raydocs_full/ray-core_namespaces.txt\"}, {\"start_index\": 7429, \"end_index\": 9250, \"corpus_id\": \"datasets/raydocs_full/ray-core_namespaces.txt\"}, {\"start_index\": 2, \"end_index\": 4354, \"corpus_id\": \"datasets/raydocs_full/data_batch_inference.txt\"}, {\"start_index\": 4071, \"end_index\": 8023, \"corpus_id\": \"datasets/raydocs_full/data_batch_inference.txt\"}, {\"start_index\": 7753, \"end_index\": 11780, \"corpus_id\": \"datasets/raydocs_full/data_batch_inference.txt\"}, {\"start_index\": 11432, \"end_index\": 14054, \"corpus_id\": \"datasets/raydocs_full/data_batch_inference.txt\"}, {\"start_index\": 2, \"end_index\": 4465, \"corpus_id\": \"datasets/raydocs_full/serve_key-concepts.txt\"}, {\"start_index\": 4139, \"end_index\": 5592, \"corpus_id\": \"datasets/raydocs_full/serve_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 4720, \"corpus_id\": \"datasets/raydocs_full/data_data-internals.txt\"}, {\"start_index\": 4710, \"end_index\": 9677, \"corpus_id\": \"datasets/raydocs_full/data_data-internals.txt\"}, {\"start_index\": 9474, \"end_index\": 10317, \"corpus_id\": \"datasets/raydocs_full/data_data-internals.txt\"}, {\"start_index\": 2, \"end_index\": 1413, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_pass-large-arg-by-value.txt\"}, {\"start_index\": 2, \"end_index\": 1007, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.schedules.scheduler.Scheduler.validate.txt\"}, {\"start_index\": 2, \"end_index\": 3867, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_ppo_example.txt\"}, {\"start_index\": 3535, \"end_index\": 4646, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_ppo_example.txt\"}, {\"start_index\": 2, \"end_index\": 3753, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_learner.txt\"}, {\"start_index\": 2, \"end_index\": 488, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.callbacks.RayDaskCallback._ray_posttask.txt\"}, {\"start_index\": 2, \"end_index\": 1342, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group.txt\"}, {\"start_index\": 2, \"end_index\": 3849, \"corpus_id\": \"datasets/raydocs_full/ray-core_tasks.txt\"}, {\"start_index\": 3513, \"end_index\": 7221, \"corpus_id\": \"datasets/raydocs_full/ray-core_tasks.txt\"}, {\"start_index\": 6916, \"end_index\": 9388, \"corpus_id\": \"datasets/raydocs_full/ray-core_tasks.txt\"}, {\"start_index\": 2, \"end_index\": 1104, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_env_runner.OfflineSingleAgentEnvRunner.txt\"}, {\"start_index\": 2, \"end_index\": 4134, \"corpus_id\": \"datasets/raydocs_full/rllib_index.txt\"}, {\"start_index\": 3828, \"end_index\": 8036, \"corpus_id\": \"datasets/raydocs_full/rllib_index.txt\"}, {\"start_index\": 7649, \"end_index\": 10258, \"corpus_id\": \"datasets/raydocs_full/rllib_index.txt\"}, {\"start_index\": 2, \"end_index\": 4707, \"corpus_id\": \"datasets/raydocs_full/ray-observability_key-concepts.txt\"}, {\"start_index\": 4536, \"end_index\": 5943, \"corpus_id\": \"datasets/raydocs_full/ray-observability_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 1681, \"corpus_id\": \"datasets/raydocs_full/ray-core_tasks_nested-tasks.txt\"}, {\"start_index\": 2, \"end_index\": 2041, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_tree-of-actors.txt\"}, {\"start_index\": 2, \"end_index\": 430, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.sigmoid.txt\"}, {\"start_index\": 2, \"end_index\": 1531, \"corpus_id\": \"datasets/raydocs_full/data_api_preprocessor.txt\"}, {\"start_index\": 2, \"end_index\": 4018, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 3732, \"end_index\": 6274, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 6278, \"end_index\": 8695, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 8453, \"end_index\": 10892, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 10677, \"end_index\": 13096, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 12854, \"end_index\": 15372, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 15146, \"end_index\": 15430, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 2, \"end_index\": 4018, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 3732, \"end_index\": 6274, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 15436, \"end_index\": 17909, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 17669, \"end_index\": 20164, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 19931, \"end_index\": 22384, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 22140, \"end_index\": 24072, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 2, \"end_index\": 4018, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 3732, \"end_index\": 6274, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 24078, \"end_index\": 26549, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 26307, \"end_index\": 28798, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 28549, \"end_index\": 29442, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 2, \"end_index\": 4018, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 29448, \"end_index\": 31183, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 31053, \"end_index\": 32494, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 32497, \"end_index\": 34990, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 34749, \"end_index\": 37230, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 36989, \"end_index\": 39489, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 39252, \"end_index\": 41724, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 41481, \"end_index\": 42279, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 2, \"end_index\": 4018, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 29448, \"end_index\": 31183, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 31053, \"end_index\": 32494, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 42285, \"end_index\": 44738, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 44496, \"end_index\": 46973, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 46740, \"end_index\": 49228, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 48991, \"end_index\": 51520, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 51294, \"end_index\": 51577, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 2, \"end_index\": 4018, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 29448, \"end_index\": 31183, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 31053, \"end_index\": 32494, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 51583, \"end_index\": 54063, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 53831, \"end_index\": 55668, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 2, \"end_index\": 4018, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 29448, \"end_index\": 31183, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_nevergrad_example.txt\"}, {\"start_index\": 2, \"end_index\": 2754, \"corpus_id\": \"datasets/raydocs_full/tune_api_api.txt\"}, {\"start_index\": 2, \"end_index\": 2679, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_modin_index.txt\"}, {\"start_index\": 2, \"end_index\": 2807, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_gcs.txt\"}, {\"start_index\": 2, \"end_index\": 401, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.on_checkpoint_loaded.txt\"}, {\"start_index\": 2, \"end_index\": 4009, \"corpus_id\": \"datasets/raydocs_full/data_loading-data.txt\"}, {\"start_index\": 3653, \"end_index\": 7396, \"corpus_id\": \"datasets/raydocs_full/data_loading-data.txt\"}, {\"start_index\": 7195, \"end_index\": 10525, \"corpus_id\": \"datasets/raydocs_full/data_loading-data.txt\"}, {\"start_index\": 10332, \"end_index\": 13834, \"corpus_id\": \"datasets/raydocs_full/data_loading-data.txt\"}, {\"start_index\": 13379, \"end_index\": 17445, \"corpus_id\": \"datasets/raydocs_full/data_loading-data.txt\"}, {\"start_index\": 17061, \"end_index\": 20441, \"corpus_id\": \"datasets/raydocs_full/data_loading-data.txt\"}, {\"start_index\": 2, \"end_index\": 411, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.set_state.txt\"}, {\"start_index\": 2, \"end_index\": 238, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner._should_module_be_updated.txt\"}, {\"start_index\": 2, \"end_index\": 1831, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_index.txt\"}, {\"start_index\": 2, \"end_index\": 3632, \"corpus_id\": \"datasets/raydocs_full/ray-observability_user-guides_ray-tracing.txt\"}, {\"start_index\": 2, \"end_index\": 4172, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_inplace-updates.txt\"}, {\"start_index\": 2, \"end_index\": 3731, \"corpus_id\": \"datasets/raydocs_full/tune_api_reporters.txt\"}, {\"start_index\": 3326, \"end_index\": 4104, \"corpus_id\": \"datasets/raydocs_full/tune_api_reporters.txt\"}, {\"start_index\": 2, \"end_index\": 4336, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_ray-client.txt\"}, {\"start_index\": 4063, \"end_index\": 8343, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_ray-client.txt\"}, {\"start_index\": 8053, \"end_index\": 11136, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_ray-client.txt\"}, {\"start_index\": 2, \"end_index\": 3554, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_highly_parallel.txt\"}, {\"start_index\": 2, \"end_index\": 399, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_index.txt\"}, {\"start_index\": 2, \"end_index\": 177, \"corpus_id\": \"datasets/raydocs_full/ray-observability_reference_index.txt\"}, {\"start_index\": 2, \"end_index\": 4140, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_named-actors.txt\"}, {\"start_index\": 3783, \"end_index\": 6043, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_named-actors.txt\"}, {\"start_index\": 2, \"end_index\": 983, \"corpus_id\": \"datasets/raydocs_full/workflows_advanced.txt\"}, {\"start_index\": 2, \"end_index\": 4289, \"corpus_id\": \"datasets/raydocs_full/serve_getting_started.txt\"}, {\"start_index\": 4010, \"end_index\": 8790, \"corpus_id\": \"datasets/raydocs_full/serve_getting_started.txt\"}, {\"start_index\": 8273, \"end_index\": 12822, \"corpus_id\": \"datasets/raydocs_full/serve_getting_started.txt\"}, {\"start_index\": 12714, \"end_index\": 14033, \"corpus_id\": \"datasets/raydocs_full/serve_getting_started.txt\"}, {\"start_index\": 2, \"end_index\": 3950, \"corpus_id\": \"datasets/raydocs_full/cluster_cli.txt\"}, {\"start_index\": 3610, \"end_index\": 7794, \"corpus_id\": \"datasets/raydocs_full/cluster_cli.txt\"}, {\"start_index\": 7460, \"end_index\": 11453, \"corpus_id\": \"datasets/raydocs_full/cluster_cli.txt\"}, {\"start_index\": 11088, \"end_index\": 13474, \"corpus_id\": \"datasets/raydocs_full/cluster_cli.txt\"}, {\"start_index\": 2, \"end_index\": 4368, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_hyperparameter-optimization.txt\"}, {\"start_index\": 4085, \"end_index\": 8005, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_hyperparameter-optimization.txt\"}, {\"start_index\": 8010, \"end_index\": 12599, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_hyperparameter-optimization.txt\"}, {\"start_index\": 12602, \"end_index\": 14821, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_hyperparameter-optimization.txt\"}, {\"start_index\": 2, \"end_index\": 94, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.observation_space.txt\"}, {\"start_index\": 2, \"end_index\": 4306, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_automl_for_time_series.txt\"}, {\"start_index\": 4311, \"end_index\": 8717, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_automl_for_time_series.txt\"}, {\"start_index\": 8387, \"end_index\": 11600, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_automl_for_time_series.txt\"}, {\"start_index\": 11458, \"end_index\": 12362, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_automl_for_time_series.txt\"}, {\"start_index\": 2, \"end_index\": 4305, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-distributed.txt\"}, {\"start_index\": 4027, \"end_index\": 7603, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-distributed.txt\"}, {\"start_index\": 7150, \"end_index\": 10609, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-distributed.txt\"}, {\"start_index\": 2, \"end_index\": 4531, \"corpus_id\": \"datasets/raydocs_full/rllib_getting-started.txt\"}, {\"start_index\": 4171, \"end_index\": 8029, \"corpus_id\": \"datasets/raydocs_full/rllib_getting-started.txt\"}, {\"start_index\": 8031, \"end_index\": 11651, \"corpus_id\": \"datasets/raydocs_full/rllib_getting-started.txt\"}, {\"start_index\": 11294, \"end_index\": 14266, \"corpus_id\": \"datasets/raydocs_full/rllib_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 3682, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_benchmarks_memory-scalability-benchmark.txt\"}, {\"start_index\": 2, \"end_index\": 3244, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_nested-tasks.txt\"}, {\"start_index\": 2, \"end_index\": 4731, \"corpus_id\": \"datasets/raydocs_full/train_deepspeed.txt\"}, {\"start_index\": 4474, \"end_index\": 9046, \"corpus_id\": \"datasets/raydocs_full/train_deepspeed.txt\"}, {\"start_index\": 8633, \"end_index\": 12693, \"corpus_id\": \"datasets/raydocs_full/train_deepspeed.txt\"}, {\"start_index\": 12051, \"end_index\": 15101, \"corpus_id\": \"datasets/raydocs_full/train_deepspeed.txt\"}, {\"start_index\": 2, \"end_index\": 3211, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kubectl-plugin.txt\"}, {\"start_index\": 3213, \"end_index\": 6604, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kubectl-plugin.txt\"}, {\"start_index\": 6279, \"end_index\": 8330, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kubectl-plugin.txt\"}, {\"start_index\": 2, \"end_index\": 3166, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_concurrent-operations-async-actor.txt\"}, {\"start_index\": 2, \"end_index\": 4762, \"corpus_id\": \"datasets/raydocs_full/serve_multi-app.txt\"}, {\"start_index\": 4476, \"end_index\": 8329, \"corpus_id\": \"datasets/raydocs_full/serve_multi-app.txt\"}, {\"start_index\": 8279, \"end_index\": 10424, \"corpus_id\": \"datasets/raydocs_full/serve_multi-app.txt\"}, {\"start_index\": 2, \"end_index\": 3025, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_single_agent_env_runner.txt\"}, {\"start_index\": 2, \"end_index\": 237, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.set_torch_seed.txt\"}, {\"start_index\": 2, \"end_index\": 1535, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.learner.learner_group.LearnerGroup.txt\"}, {\"start_index\": 2, \"end_index\": 542, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.update_target_network.txt\"}, {\"start_index\": 2, \"end_index\": 4014, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.default_model_config.DefaultModelConfig.txt\"}, {\"start_index\": 3565, \"end_index\": 6360, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.default_model_config.DefaultModelConfig.txt\"}, {\"start_index\": 2, \"end_index\": 2555, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_pyspy.txt\"}, {\"start_index\": 2, \"end_index\": 2424, \"corpus_id\": \"datasets/raydocs_full/ray-observability_reference_api.txt\"}, {\"start_index\": 2, \"end_index\": 3696, \"corpus_id\": \"datasets/raydocs_full/ray-core_objects.txt\"}, {\"start_index\": 3703, \"end_index\": 7619, \"corpus_id\": \"datasets/raydocs_full/ray-core_objects.txt\"}, {\"start_index\": 7281, \"end_index\": 8194, \"corpus_id\": \"datasets/raydocs_full/ray-core_objects.txt\"}, {\"start_index\": 2, \"end_index\": 3917, \"corpus_id\": \"datasets/raydocs_full/train_api_api.txt\"}, {\"start_index\": 2, \"end_index\": 4312, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 4043, \"end_index\": 7613, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 7411, \"end_index\": 11469, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 11161, \"end_index\": 15194, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 14961, \"end_index\": 19228, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 18869, \"end_index\": 23297, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 23098, \"end_index\": 27276, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 26881, \"end_index\": 30724, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 30421, \"end_index\": 34628, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 34203, \"end_index\": 39168, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 38826, \"end_index\": 40176, \"corpus_id\": \"datasets/raydocs_full/rllib_rl-modules.txt\"}, {\"start_index\": 2, \"end_index\": 4444, \"corpus_id\": \"datasets/raydocs_full/data_custom-datasource-example.txt\"}, {\"start_index\": 2, \"end_index\": 4264, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_utils.txt\"}, {\"start_index\": 3872, \"end_index\": 4898, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_utils.txt\"}, {\"start_index\": 2, \"end_index\": 3838, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_web-crawler.txt\"}, {\"start_index\": 2, \"end_index\": 1948, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.callbacks.callbacks.RLlibCallback.txt\"}, {\"start_index\": 2, \"end_index\": 4075, \"corpus_id\": \"datasets/raydocs_full/ray-core_miscellaneous.txt\"}, {\"start_index\": 3909, \"end_index\": 8088, \"corpus_id\": \"datasets/raydocs_full/ray-core_miscellaneous.txt\"}, {\"start_index\": 8059, \"end_index\": 8601, \"corpus_id\": \"datasets/raydocs_full/ray-core_miscellaneous.txt\"}, {\"start_index\": 2, \"end_index\": 4577, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_static-ray-cluster-without-kuberay.txt\"}, {\"start_index\": 4435, \"end_index\": 8739, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_static-ray-cluster-without-kuberay.txt\"}, {\"start_index\": 2, \"end_index\": 3852, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners.txt\"}, {\"start_index\": 3854, \"end_index\": 8139, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners.txt\"}, {\"start_index\": 7754, \"end_index\": 12152, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners.txt\"}, {\"start_index\": 11708, \"end_index\": 14067, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners.txt\"}, {\"start_index\": 2, \"end_index\": 4161, \"corpus_id\": \"datasets/raydocs_full/rllib_algorithm-config.txt\"}, {\"start_index\": 3827, \"end_index\": 7561, \"corpus_id\": \"datasets/raydocs_full/rllib_algorithm-config.txt\"}, {\"start_index\": 2, \"end_index\": 1039, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides.txt\"}, {\"start_index\": 2, \"end_index\": 4716, \"corpus_id\": \"datasets/raydocs_full/rllib_metrics-logger.txt\"}, {\"start_index\": 4363, \"end_index\": 8258, \"corpus_id\": \"datasets/raydocs_full/rllib_metrics-logger.txt\"}, {\"start_index\": 8123, \"end_index\": 11934, \"corpus_id\": \"datasets/raydocs_full/rllib_metrics-logger.txt\"}, {\"start_index\": 11596, \"end_index\": 15825, \"corpus_id\": \"datasets/raydocs_full/rllib_metrics-logger.txt\"}, {\"start_index\": 15525, \"end_index\": 16725, \"corpus_id\": \"datasets/raydocs_full/rllib_metrics-logger.txt\"}, {\"start_index\": 2, \"end_index\": 990, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_algo.txt\"}, {\"start_index\": 2, \"end_index\": 2044, \"corpus_id\": \"datasets/raydocs_full/ray-core_api_cli.txt\"}, {\"start_index\": 2, \"end_index\": 1307, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_redefine-task-actor-loop.txt\"}, {\"start_index\": 2, \"end_index\": 1719, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_rl_module_spec.txt\"}, {\"start_index\": 2, \"end_index\": 778, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_index.txt\"}, {\"start_index\": 2, \"end_index\": 4586, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 4164, \"end_index\": 8478, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 8069, \"end_index\": 12382, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 12034, \"end_index\": 12465, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 12467, \"end_index\": 15854, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 15563, \"end_index\": 18181, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 2, \"end_index\": 4586, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 4164, \"end_index\": 8478, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 8069, \"end_index\": 12382, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/serve_api_index.txt\"}, {\"start_index\": 2, \"end_index\": 1033, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.training_step.txt\"}, {\"start_index\": 2, \"end_index\": 3561, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_profiling.txt\"}, {\"start_index\": 2, \"end_index\": 2915, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_api-policy.txt\"}, {\"start_index\": 2, \"end_index\": 4799, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_guide.txt\"}, {\"start_index\": 4802, \"end_index\": 8710, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_guide.txt\"}, {\"start_index\": 8459, \"end_index\": 11202, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_guide.txt\"}, {\"start_index\": 11207, \"end_index\": 14424, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_guide.txt\"}, {\"start_index\": 14367, \"end_index\": 17428, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_guide.txt\"}, {\"start_index\": 17378, \"end_index\": 21592, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_guide.txt\"}, {\"start_index\": 21317, \"end_index\": 24603, \"corpus_id\": \"datasets/raydocs_full/tune_examples_pbt_guide.txt\"}, {\"start_index\": 2, \"end_index\": 1727, \"corpus_id\": \"datasets/raydocs_full/ray-core_api_core.txt\"}, {\"start_index\": 2, \"end_index\": 279, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.l2_loss.txt\"}, {\"start_index\": 2, \"end_index\": 585, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit.txt\"}, {\"start_index\": 2, \"end_index\": 4339, \"corpus_id\": \"datasets/raydocs_full/ray-observability_getting-started.txt\"}, {\"start_index\": 4343, \"end_index\": 9167, \"corpus_id\": \"datasets/raydocs_full/ray-observability_getting-started.txt\"}, {\"start_index\": 8777, \"end_index\": 12802, \"corpus_id\": \"datasets/raydocs_full/ray-observability_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 65, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_benchmarks.txt\"}, {\"start_index\": 2, \"end_index\": 4044, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_fake-autoscaler.txt\"}, {\"start_index\": 3745, \"end_index\": 8045, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_fake-autoscaler.txt\"}, {\"start_index\": 7853, \"end_index\": 12326, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_fake-autoscaler.txt\"}, {\"start_index\": 12328, \"end_index\": 14305, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_fake-autoscaler.txt\"}, {\"start_index\": 2, \"end_index\": 106, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.learner_only.txt\"}, {\"start_index\": 2, \"end_index\": 4660, \"corpus_id\": \"datasets/raydocs_full/serve_http-guide.txt\"}, {\"start_index\": 4663, \"end_index\": 8996, \"corpus_id\": \"datasets/raydocs_full/serve_http-guide.txt\"}, {\"start_index\": 8669, \"end_index\": 12298, \"corpus_id\": \"datasets/raydocs_full/serve_http-guide.txt\"}, {\"start_index\": 11930, \"end_index\": 14145, \"corpus_id\": \"datasets/raydocs_full/serve_http-guide.txt\"}, {\"start_index\": 2, \"end_index\": 669, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_distributions.txt\"}, {\"start_index\": 2, \"end_index\": 757, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.clip_gradients.txt\"}, {\"start_index\": 2, \"end_index\": 1168, \"corpus_id\": \"datasets/raydocs_full/ray-observability_index.txt\"}, {\"start_index\": 2, \"end_index\": 2550, \"corpus_id\": \"datasets/raydocs_full/ray-core_using-ray-with-jupyter.txt\"}, {\"start_index\": 2, \"end_index\": 4031, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayserve-dev-doc.txt\"}, {\"start_index\": 3656, \"end_index\": 6226, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayserve-dev-doc.txt\"}, {\"start_index\": 2, \"end_index\": 4751, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-fault-tolerance.txt\"}, {\"start_index\": 4374, \"end_index\": 8597, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-fault-tolerance.txt\"}, {\"start_index\": 8186, \"end_index\": 9750, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-fault-tolerance.txt\"}, {\"start_index\": 2, \"end_index\": 4353, \"corpus_id\": \"datasets/raydocs_full/rllib_new-api-stack-migration-guide.txt\"}, {\"start_index\": 4356, \"end_index\": 8379, \"corpus_id\": \"datasets/raydocs_full/rllib_new-api-stack-migration-guide.txt\"}, {\"start_index\": 8384, \"end_index\": 12657, \"corpus_id\": \"datasets/raydocs_full/rllib_new-api-stack-migration-guide.txt\"}, {\"start_index\": 12270, \"end_index\": 16770, \"corpus_id\": \"datasets/raydocs_full/rllib_new-api-stack-migration-guide.txt\"}, {\"start_index\": 16441, \"end_index\": 18592, \"corpus_id\": \"datasets/raydocs_full/rllib_new-api-stack-migration-guide.txt\"}, {\"start_index\": 2, \"end_index\": 4264, \"corpus_id\": \"datasets/raydocs_full/ray-core_tasks_generators.txt\"}, {\"start_index\": 4080, \"end_index\": 7837, \"corpus_id\": \"datasets/raydocs_full/ray-core_tasks_generators.txt\"}, {\"start_index\": 12, \"end_index\": 515, \"corpus_id\": \"datasets/raydocs_full/ray-overview_examples.txt\"}, {\"start_index\": 531, \"end_index\": 5128, \"corpus_id\": \"datasets/raydocs_full/ray-overview_examples.txt\"}, {\"start_index\": 4757, \"end_index\": 5269, \"corpus_id\": \"datasets/raydocs_full/ray-overview_examples.txt\"}, {\"start_index\": 12, \"end_index\": 515, \"corpus_id\": \"datasets/raydocs_full/ray-overview_examples.txt\"}, {\"start_index\": 2, \"end_index\": 657, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.models.distributions.Distribution.sample.txt\"}, {\"start_index\": 2, \"end_index\": 3406, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_generators.txt\"}, {\"start_index\": 2, \"end_index\": 4016, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_quickstart.txt\"}, {\"start_index\": 3690, \"end_index\": 7841, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_quickstart.txt\"}, {\"start_index\": 7448, \"end_index\": 11993, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_quickstart.txt\"}, {\"start_index\": 11705, \"end_index\": 13179, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_quickstart.txt\"}, {\"start_index\": 2, \"end_index\": 1148, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_nodes.txt\"}, {\"start_index\": 2, \"end_index\": 4467, \"corpus_id\": \"datasets/raydocs_full/serve_configure-serve-deployment.txt\"}, {\"start_index\": 4133, \"end_index\": 7124, \"corpus_id\": \"datasets/raydocs_full/serve_configure-serve-deployment.txt\"}, {\"start_index\": 2, \"end_index\": 1940, \"corpus_id\": \"datasets/raydocs_full/cluster_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 4228, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_k8s-autoscaler.txt\"}, {\"start_index\": 2, \"end_index\": 1774, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_ray-get-submission-order.txt\"}, {\"start_index\": 2, \"end_index\": 584, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.callbacks.RayDaskCallback._ray_pretask.txt\"}, {\"start_index\": 1, \"end_index\": 1603, \"corpus_id\": \"datasets/raydocs_full/train_examples.txt\"}, {\"start_index\": 2, \"end_index\": 3804, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-kueue-gang-scheduling.txt\"}, {\"start_index\": 3356, \"end_index\": 7248, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-kueue-gang-scheduling.txt\"}, {\"start_index\": 7251, \"end_index\": 9286, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_rayjob-kueue-gang-scheduling.txt\"}, {\"start_index\": 2, \"end_index\": 668, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.add_module.txt\"}, {\"start_index\": 2, \"end_index\": 320, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_kwargs.txt\"}, {\"start_index\": 2, \"end_index\": 4128, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_config.txt\"}, {\"start_index\": 3841, \"end_index\": 8239, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_config.txt\"}, {\"start_index\": 8019, \"end_index\": 12101, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_config.txt\"}, {\"start_index\": 11723, \"end_index\": 12599, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_config.txt\"}, {\"start_index\": 2, \"end_index\": 2476, \"corpus_id\": \"datasets/raydocs_full/tune_api_logging.txt\"}, {\"start_index\": 2, \"end_index\": 3816, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_sdk.txt\"}, {\"start_index\": 3684, \"end_index\": 7422, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_sdk.txt\"}, {\"start_index\": 7425, \"end_index\": 9623, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_sdk.txt\"}, {\"start_index\": 2, \"end_index\": 352, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.total_train_batch_size.txt\"}, {\"start_index\": 2, \"end_index\": 4139, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_kueue.txt\"}, {\"start_index\": 4142, \"end_index\": 8208, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_kueue.txt\"}, {\"start_index\": 7835, \"end_index\": 8418, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem_kueue.txt\"}, {\"start_index\": 2, \"end_index\": 276, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.setup.txt\"}, {\"start_index\": 2, \"end_index\": 4123, \"corpus_id\": \"datasets/raydocs_full/tune_index.txt\"}, {\"start_index\": 3915, \"end_index\": 8289, \"corpus_id\": \"datasets/raydocs_full/tune_index.txt\"}, {\"start_index\": 8084, \"end_index\": 10175, \"corpus_id\": \"datasets/raydocs_full/tune_index.txt\"}, {\"start_index\": 2, \"end_index\": 3975, \"corpus_id\": \"datasets/raydocs_full/data_api_input_output.txt\"}, {\"start_index\": 3648, \"end_index\": 6480, \"corpus_id\": \"datasets/raydocs_full/data_api_input_output.txt\"}, {\"start_index\": 2, \"end_index\": 3555, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": 3190, \"end_index\": 7066, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": 6737, \"end_index\": 10541, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": 10546, \"end_index\": 13203, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": 12964, \"end_index\": 15169, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": 2, \"end_index\": 3555, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": 3190, \"end_index\": 7066, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/ray-overview_installation.txt\"}, {\"start_index\": 2, \"end_index\": 3948, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors.txt\"}, {\"start_index\": 3699, \"end_index\": 7167, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors.txt\"}, {\"start_index\": 6870, \"end_index\": 10547, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors.txt\"}, {\"start_index\": 10237, \"end_index\": 12621, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors.txt\"}, {\"start_index\": 2, \"end_index\": 552, \"corpus_id\": \"datasets/raydocs_full/cluster_package-overview.txt\"}, {\"start_index\": 2, \"end_index\": 123, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.action_space.txt\"}, {\"start_index\": 2, \"end_index\": 3596, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 3373, \"end_index\": 6874, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 6878, \"end_index\": 7594, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 7439, \"end_index\": 9156, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 9158, \"end_index\": 10860, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 10864, \"end_index\": 13222, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 13228, \"end_index\": 14226, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 14230, \"end_index\": 16553, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 16338, \"end_index\": 18484, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 2, \"end_index\": 3596, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 3373, \"end_index\": 6874, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 6878, \"end_index\": 7594, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 7439, \"end_index\": 9156, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 9158, \"end_index\": 10860, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 10864, \"end_index\": 13222, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 19156, \"end_index\": 20743, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 20747, \"end_index\": 23095, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 22854, \"end_index\": 23197, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 2, \"end_index\": 3596, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 3373, \"end_index\": 6874, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 6878, \"end_index\": 7594, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 7439, \"end_index\": 9156, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 9158, \"end_index\": 10860, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 10864, \"end_index\": 13222, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 23203, \"end_index\": 25163, \"corpus_id\": \"datasets/raydocs_full/tune_examples_ax_example.txt\"}, {\"start_index\": 2, \"end_index\": 4436, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune_analyze_results.txt\"}, {\"start_index\": 4261, \"end_index\": 7454, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune_analyze_results.txt\"}, {\"start_index\": 7129, \"end_index\": 10525, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune_analyze_results.txt\"}, {\"start_index\": 10124, \"end_index\": 11338, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune_analyze_results.txt\"}, {\"start_index\": 2, \"end_index\": 146, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate.txt\"}, {\"start_index\": 2, \"end_index\": 4345, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-cli.txt\"}, {\"start_index\": 4023, \"end_index\": 7876, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_references_ray-cluster-cli.txt\"}, {\"start_index\": 2, \"end_index\": 4619, \"corpus_id\": \"datasets/raydocs_full/rllib_external-envs.txt\"}, {\"start_index\": 4561, \"end_index\": 7823, \"corpus_id\": \"datasets/raydocs_full/rllib_external-envs.txt\"}, {\"start_index\": 2, \"end_index\": 4310, \"corpus_id\": \"datasets/raydocs_full/rllib_single-agent-episode.txt\"}, {\"start_index\": 4117, \"end_index\": 8196, \"corpus_id\": \"datasets/raydocs_full/rllib_single-agent-episode.txt\"}, {\"start_index\": 7916, \"end_index\": 11786, \"corpus_id\": \"datasets/raydocs_full/rllib_single-agent-episode.txt\"}, {\"start_index\": 11537, \"end_index\": 14351, \"corpus_id\": \"datasets/raydocs_full/rllib_single-agent-episode.txt\"}, {\"start_index\": 2, \"end_index\": 1759, \"corpus_id\": \"datasets/raydocs_full/train_train.txt\"}, {\"start_index\": 2, \"end_index\": 4536, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_configuring-autoscaling.txt\"}, {\"start_index\": 4172, \"end_index\": 7985, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_configuring-autoscaling.txt\"}, {\"start_index\": 7639, \"end_index\": 11564, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_configuring-autoscaling.txt\"}, {\"start_index\": 11080, \"end_index\": 15221, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_configuring-autoscaling.txt\"}, {\"start_index\": 15226, \"end_index\": 18946, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_configuring-autoscaling.txt\"}, {\"start_index\": 2, \"end_index\": 947, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.replay_buffers.utils.sample_min_n_steps_from_buffer.txt\"}, {\"start_index\": 2, \"end_index\": 2081, \"corpus_id\": \"datasets/raydocs_full/data_user-guide.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 9932, \"end_index\": 11725, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 11731, \"end_index\": 15135, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 14806, \"end_index\": 16541, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 16933, \"end_index\": 19283, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 19286, \"end_index\": 22357, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 22358, \"end_index\": 25718, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 25601, \"end_index\": 27776, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 28305, \"end_index\": 31584, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 31260, \"end_index\": 34595, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 34381, \"end_index\": 37592, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 37422, \"end_index\": 37656, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 37659, \"end_index\": 38182, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 38185, \"end_index\": 41546, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 41547, \"end_index\": 44702, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 44359, \"end_index\": 47815, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 47581, \"end_index\": 48102, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 48631, \"end_index\": 51869, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 51545, \"end_index\": 54601, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 54272, \"end_index\": 57578, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 57284, \"end_index\": 58345, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 58876, \"end_index\": 62155, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 61831, \"end_index\": 64953, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 64634, \"end_index\": 67966, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 67623, \"end_index\": 69027, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 69558, \"end_index\": 72836, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 72512, \"end_index\": 75598, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 75268, \"end_index\": 78590, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 78295, \"end_index\": 79365, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 79895, \"end_index\": 80493, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 80496, \"end_index\": 83967, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 83880, \"end_index\": 87049, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 86705, \"end_index\": 90181, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 89943, \"end_index\": 90469, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 91001, \"end_index\": 94298, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 93973, \"end_index\": 94639, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 94738, \"end_index\": 98139, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 98021, \"end_index\": 100627, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 101160, \"end_index\": 104481, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 104156, \"end_index\": 107319, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 106989, \"end_index\": 110311, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 110016, \"end_index\": 111086, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 111621, \"end_index\": 114920, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 114595, \"end_index\": 116736, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 4149, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 4025, \"end_index\": 8370, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 7908, \"end_index\": 10193, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 116745, \"end_index\": 118078, \"corpus_id\": \"datasets/raydocs_full/tune_examples_tune-pytorch-lightning.txt\"}, {\"start_index\": 2, \"end_index\": 2291, \"corpus_id\": \"datasets/raydocs_full/ray-core_actors_out-of-band-communication.txt\"}, {\"start_index\": 2, \"end_index\": 4460, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 4072, \"end_index\": 8326, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 7868, \"end_index\": 11855, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 11857, \"end_index\": 16242, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 16134, \"end_index\": 20067, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 19706, \"end_index\": 24157, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 23945, \"end_index\": 28822, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 28458, \"end_index\": 33106, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 33108, \"end_index\": 37996, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 37719, \"end_index\": 42597, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 42182, \"end_index\": 46479, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 46374, \"end_index\": 50777, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 50647, \"end_index\": 54752, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 54705, \"end_index\": 59466, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 59471, \"end_index\": 64130, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 63796, \"end_index\": 68282, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 68288, \"end_index\": 72627, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 72275, \"end_index\": 76350, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 75986, \"end_index\": 79995, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 79685, \"end_index\": 83528, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 83345, \"end_index\": 86720, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 86356, \"end_index\": 87906, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 87911, \"end_index\": 91848, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 91504, \"end_index\": 95556, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 95156, \"end_index\": 97590, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 2, \"end_index\": 4460, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 4072, \"end_index\": 8326, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 7868, \"end_index\": 11855, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 11857, \"end_index\": 16242, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 16134, \"end_index\": 20067, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 19706, \"end_index\": 24157, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 23945, \"end_index\": 28822, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 28458, \"end_index\": 33106, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 33108, \"end_index\": 37996, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 37719, \"end_index\": 42597, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 42182, \"end_index\": 46479, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 46374, \"end_index\": 50777, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 50647, \"end_index\": 54752, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 54705, \"end_index\": 59466, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 59471, \"end_index\": 64130, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 63796, \"end_index\": 68282, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 68288, \"end_index\": 72627, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 72275, \"end_index\": 76350, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 75986, \"end_index\": 79995, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 79685, \"end_index\": 83528, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 83345, \"end_index\": 86720, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": -1, \"end_index\": -1, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-offline.txt\"}, {\"start_index\": 2, \"end_index\": 84, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.action_space.txt\"}, {\"start_index\": 2, \"end_index\": 3682, \"corpus_id\": \"datasets/raydocs_full/train_benchmarks.txt\"}, {\"start_index\": 3464, \"end_index\": 4489, \"corpus_id\": \"datasets/raydocs_full/train_benchmarks.txt\"}, {\"start_index\": 2, \"end_index\": 4240, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_gpu.txt\"}, {\"start_index\": 3849, \"end_index\": 7249, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_gpu.txt\"}, {\"start_index\": 2, \"end_index\": 4260, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_experiment-tracking.txt\"}, {\"start_index\": 3968, \"end_index\": 7990, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_experiment-tracking.txt\"}, {\"start_index\": 7743, \"end_index\": 11842, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_experiment-tracking.txt\"}, {\"start_index\": 11552, \"end_index\": 15207, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_experiment-tracking.txt\"}, {\"start_index\": 14826, \"end_index\": 18739, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_experiment-tracking.txt\"}, {\"start_index\": 18401, \"end_index\": 21734, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_experiment-tracking.txt\"}, {\"start_index\": 2, \"end_index\": 394, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.schedules.scheduler.Scheduler._create_tensor_variable.txt\"}, {\"start_index\": 2, \"end_index\": 635, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.get_state.txt\"}, {\"start_index\": 2, \"end_index\": 5144, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_memory-management.txt\"}, {\"start_index\": 4661, \"end_index\": 9351, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_memory-management.txt\"}, {\"start_index\": 8967, \"end_index\": 14001, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_memory-management.txt\"}, {\"start_index\": 13440, \"end_index\": 16469, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_memory-management.txt\"}, {\"start_index\": 2, \"end_index\": 3783, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_tasks.txt\"}, {\"start_index\": 3495, \"end_index\": 7394, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_tasks.txt\"}, {\"start_index\": 6995, \"end_index\": 10484, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_tasks.txt\"}, {\"start_index\": 10124, \"end_index\": 12397, \"corpus_id\": \"datasets/raydocs_full/ray-core_fault_tolerance_tasks.txt\"}, {\"start_index\": 2, \"end_index\": 2344, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_index.txt\"}, {\"start_index\": 2, \"end_index\": 377, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.torch_utils.compute_global_norm.txt\"}, {\"start_index\": 2, \"end_index\": 4768, \"corpus_id\": \"datasets/raydocs_full/ray-core_user-guide.txt\"}, {\"start_index\": 4332, \"end_index\": 8646, \"corpus_id\": \"datasets/raydocs_full/ray-core_user-guide.txt\"}, {\"start_index\": 2, \"end_index\": 154, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_offline.txt\"}, {\"start_index\": 2, \"end_index\": 3668, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 3672, \"end_index\": 7857, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 7860, \"end_index\": 11663, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 11261, \"end_index\": 15055, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 14880, \"end_index\": 18638, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 18252, \"end_index\": 22724, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 22685, \"end_index\": 26650, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 26240, \"end_index\": 27869, \"corpus_id\": \"datasets/raydocs_full/rllib_multi-agent-envs.txt\"}, {\"start_index\": 2, \"end_index\": 3065, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_tpu-serve-stable-diffusion.txt\"}, {\"start_index\": 2, \"end_index\": 1800, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.peek.txt\"}, {\"start_index\": 2, \"end_index\": 2156, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_env_multi_agent_episode.txt\"}, {\"start_index\": 2, \"end_index\": 4865, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_reduce-image-pull-latency.txt\"}, {\"start_index\": 2, \"end_index\": 1307, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_actor-sync.txt\"}, {\"start_index\": 2, \"end_index\": 740, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_rollout_fragment_length.txt\"}, {\"start_index\": 2, \"end_index\": 707, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.schedules.scheduler.Scheduler.txt\"}, {\"start_index\": 2, \"end_index\": 967, \"corpus_id\": \"datasets/raydocs_full/data_api_data_iterator.txt\"}, {\"start_index\": 2, \"end_index\": 482, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.softmax.txt\"}, {\"start_index\": 2, \"end_index\": 2017, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_getting-started.txt\"}, {\"start_index\": 2, \"end_index\": 2255, \"corpus_id\": \"datasets/raydocs_full/cluster_running-applications_job-submission_index.txt\"}, {\"start_index\": 2, \"end_index\": 413, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_user-guides_index.txt\"}, {\"start_index\": 2, \"end_index\": 4212, \"corpus_id\": \"datasets/raydocs_full/ray-references_glossary.txt\"}, {\"start_index\": 3783, \"end_index\": 8305, \"corpus_id\": \"datasets/raydocs_full/ray-references_glossary.txt\"}, {\"start_index\": 7857, \"end_index\": 12295, \"corpus_id\": \"datasets/raydocs_full/ray-references_glossary.txt\"}, {\"start_index\": 11867, \"end_index\": 16396, \"corpus_id\": \"datasets/raydocs_full/ray-references_glossary.txt\"}, {\"start_index\": 16169, \"end_index\": 20778, \"corpus_id\": \"datasets/raydocs_full/ray-references_glossary.txt\"}, {\"start_index\": 20468, \"end_index\": 25098, \"corpus_id\": \"datasets/raydocs_full/ray-references_glossary.txt\"}, {\"start_index\": 24765, \"end_index\": 26441, \"corpus_id\": \"datasets/raydocs_full/ray-references_glossary.txt\"}, {\"start_index\": 2, \"end_index\": 4558, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_troubleshooting.txt\"}, {\"start_index\": 4311, \"end_index\": 5506, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_troubleshooting.txt\"}, {\"start_index\": 2, \"end_index\": 1336, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.models.distributions.Distribution.from_logits.txt\"}, {\"start_index\": 2, \"end_index\": 3002, \"corpus_id\": \"datasets/raydocs_full/data_data.txt\"}, {\"start_index\": 2, \"end_index\": 4469, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_ray-oom-prevention.txt\"}, {\"start_index\": 4164, \"end_index\": 8163, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_ray-oom-prevention.txt\"}, {\"start_index\": 7886, \"end_index\": 9249, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_ray-oom-prevention.txt\"}, {\"start_index\": 2, \"end_index\": 4657, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-trial-checkpoints.txt\"}, {\"start_index\": 4318, \"end_index\": 8598, \"corpus_id\": \"datasets/raydocs_full/tune_tutorials_tune-trial-checkpoints.txt\"}, {\"start_index\": 2, \"end_index\": 162, \"corpus_id\": \"datasets/raydocs_full/workflows_api_execution.txt\"}, {\"start_index\": 2, \"end_index\": 2580, \"corpus_id\": \"datasets/raydocs_full/ray-core_compiled-graph_ray-compiled-graph.txt\"}, {\"start_index\": 2, \"end_index\": 2672, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_pipelining.txt\"}, {\"start_index\": 2, \"end_index\": 149, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm.Algorithm.env_runner.txt\"}, {\"start_index\": 2, \"end_index\": 1387, \"corpus_id\": \"datasets/raydocs_full/train_user-guides.txt\"}, {\"start_index\": 2, \"end_index\": 1859, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_ray-get-too-many-objects.txt\"}, {\"start_index\": 2, \"end_index\": 2314, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor.txt\"}, {\"start_index\": 2, \"end_index\": 4499, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_troubleshooting.txt\"}, {\"start_index\": 4056, \"end_index\": 5338, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_troubleshooting_troubleshooting.txt\"}, {\"start_index\": 2, \"end_index\": 540, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.forward_train.txt\"}, {\"start_index\": 2, \"end_index\": 1208, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_user-guides_community_index.txt\"}, {\"start_index\": 2, \"end_index\": 4599, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-transformers.txt\"}, {\"start_index\": 4199, \"end_index\": 8984, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-transformers.txt\"}, {\"start_index\": 8658, \"end_index\": 13248, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-transformers.txt\"}, {\"start_index\": 12925, \"end_index\": 15049, \"corpus_id\": \"datasets/raydocs_full/train_getting-started-transformers.txt\"}, {\"start_index\": 2, \"end_index\": 954, \"corpus_id\": \"datasets/raydocs_full/tune_api_execution.txt\"}, {\"start_index\": 2, \"end_index\": 4029, \"corpus_id\": \"datasets/raydocs_full/serve_advanced-guides_performance.txt\"}, {\"start_index\": 2, \"end_index\": 2236, \"corpus_id\": \"datasets/raydocs_full/ray-core_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 122, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModuleSpec.module_class.txt\"}, {\"start_index\": 2, \"end_index\": 3392, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners.txt\"}, {\"start_index\": 2, \"end_index\": 4353, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_storage.txt\"}, {\"start_index\": 2, \"end_index\": 4476, \"corpus_id\": \"datasets/raydocs_full/serve_develop-and-deploy.txt\"}, {\"start_index\": 4481, \"end_index\": 6982, \"corpus_id\": \"datasets/raydocs_full/serve_develop-and-deploy.txt\"}, {\"start_index\": 2, \"end_index\": 171, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.as_multi_rl_module.txt\"}, {\"start_index\": 2, \"end_index\": 4319, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-advanced-api.txt\"}, {\"start_index\": 3971, \"end_index\": 8601, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-advanced-api.txt\"}, {\"start_index\": 8298, \"end_index\": 12176, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-advanced-api.txt\"}, {\"start_index\": 12179, \"end_index\": 15727, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-advanced-api.txt\"}, {\"start_index\": 15534, \"end_index\": 20284, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-advanced-api.txt\"}, {\"start_index\": 19855, \"end_index\": 21001, \"corpus_id\": \"datasets/raydocs_full/rllib_rllib-advanced-api.txt\"}, {\"start_index\": 2, \"end_index\": 4223, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_kuberay-gcs-persistent-ft.txt\"}, {\"start_index\": 2, \"end_index\": 4073, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_observability.txt\"}, {\"start_index\": 3682, \"end_index\": 6543, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_observability.txt\"}, {\"start_index\": 2, \"end_index\": 3579, \"corpus_id\": \"datasets/raydocs_full/tune_examples_lightgbm_example.txt\"}, {\"start_index\": 3587, \"end_index\": 4332, \"corpus_id\": \"datasets/raydocs_full/tune_examples_lightgbm_example.txt\"}, {\"start_index\": 2, \"end_index\": 1839, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.save_to_path.txt\"}, {\"start_index\": 2, \"end_index\": 2892, \"corpus_id\": \"datasets/raydocs_full/cluster_key-concepts.txt\"}, {\"start_index\": 2, \"end_index\": 4544, \"corpus_id\": \"datasets/raydocs_full/ray-overview_ray-libraries.txt\"}, {\"start_index\": 4284, \"end_index\": 7358, \"corpus_id\": \"datasets/raydocs_full/ray-overview_ray-libraries.txt\"}, {\"start_index\": 2, \"end_index\": 3967, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice-no-ray-serve-replica.txt\"}, {\"start_index\": 3871, \"end_index\": 7719, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice-no-ray-serve-replica.txt\"}, {\"start_index\": 7616, \"end_index\": 8909, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_rayservice-no-ray-serve-replica.txt\"}, {\"start_index\": 2, \"end_index\": 4437, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_placement-group.txt\"}, {\"start_index\": 4041, \"end_index\": 7858, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_placement-group.txt\"}, {\"start_index\": 7735, \"end_index\": 11652, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_placement-group.txt\"}, {\"start_index\": 11655, \"end_index\": 15369, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_placement-group.txt\"}, {\"start_index\": 15372, \"end_index\": 19983, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_placement-group.txt\"}, {\"start_index\": 19549, \"end_index\": 24087, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_placement-group.txt\"}, {\"start_index\": 23707, \"end_index\": 27427, \"corpus_id\": \"datasets/raydocs_full/ray-core_scheduling_placement-group.txt\"}, {\"start_index\": 2, \"end_index\": 3428, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.merge_and_log_n_dicts.txt\"}, {\"start_index\": 3055, \"end_index\": 5822, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.utils.metrics.metrics_logger.MetricsLogger.merge_and_log_n_dicts.txt\"}, {\"start_index\": 2, \"end_index\": 4040, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_helm-chart-rbac.txt\"}, {\"start_index\": 3732, \"end_index\": 7017, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_helm-chart-rbac.txt\"}, {\"start_index\": 2, \"end_index\": 3959, \"corpus_id\": \"datasets/raydocs_full/ray-core_tips-for-first-time.txt\"}, {\"start_index\": 3962, \"end_index\": 8067, \"corpus_id\": \"datasets/raydocs_full/ray-core_tips-for-first-time.txt\"}, {\"start_index\": 7878, \"end_index\": 11630, \"corpus_id\": \"datasets/raydocs_full/ray-core_tips-for-first-time.txt\"}, {\"start_index\": 11171, \"end_index\": 14825, \"corpus_id\": \"datasets/raydocs_full/ray-core_tips-for-first-time.txt\"}, {\"start_index\": 2, \"end_index\": 832, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.callbacks.RayDaskCallback._ray_presubmit.txt\"}, {\"start_index\": 2, \"end_index\": 3919, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_examples_ml-example.txt\"}, {\"start_index\": 3611, \"end_index\": 5235, \"corpus_id\": \"datasets/raydocs_full/cluster_vms_examples_ml-example.txt\"}, {\"start_index\": 2, \"end_index\": 1616, \"corpus_id\": \"datasets/raydocs_full/ray-core_patterns_closure-capture-large-objects.txt\"}, {\"start_index\": 2, \"end_index\": 724, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples.txt\"}, {\"start_index\": 2, \"end_index\": 3158, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_gpu-training-example.txt\"}, {\"start_index\": 2802, \"end_index\": 6497, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_gpu-training-example.txt\"}, {\"start_index\": 6127, \"end_index\": 8153, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_gpu-training-example.txt\"}, {\"start_index\": 2, \"end_index\": 3505, \"corpus_id\": \"datasets/raydocs_full/train_examples_xgboost_distributed-xgboost-lightgbm.txt\"}, {\"start_index\": 3513, \"end_index\": 6441, \"corpus_id\": \"datasets/raydocs_full/train_examples_xgboost_distributed-xgboost-lightgbm.txt\"}, {\"start_index\": 6444, \"end_index\": 9874, \"corpus_id\": \"datasets/raydocs_full/train_examples_xgboost_distributed-xgboost-lightgbm.txt\"}, {\"start_index\": 9485, \"end_index\": 12910, \"corpus_id\": \"datasets/raydocs_full/train_examples_xgboost_distributed-xgboost-lightgbm.txt\"}, {\"start_index\": 12915, \"end_index\": 17205, \"corpus_id\": \"datasets/raydocs_full/train_examples_xgboost_distributed-xgboost-lightgbm.txt\"}, {\"start_index\": 17197, \"end_index\": 18351, \"corpus_id\": \"datasets/raydocs_full/train_examples_xgboost_distributed-xgboost-lightgbm.txt\"}, {\"start_index\": 2, \"end_index\": 3889, \"corpus_id\": \"datasets/raydocs_full/train_horovod.txt\"}, {\"start_index\": 3553, \"end_index\": 4438, \"corpus_id\": \"datasets/raydocs_full/train_horovod.txt\"}, {\"start_index\": 2, \"end_index\": 4522, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_persistent-storage.txt\"}, {\"start_index\": 4525, \"end_index\": 8560, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_persistent-storage.txt\"}, {\"start_index\": 8123, \"end_index\": 12588, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_persistent-storage.txt\"}, {\"start_index\": 12593, \"end_index\": 15134, \"corpus_id\": \"datasets/raydocs_full/train_user-guides_persistent-storage.txt\"}, {\"start_index\": 2, \"end_index\": 1485, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_modin-example.txt\"}, {\"start_index\": 2, \"end_index\": 4365, \"corpus_id\": \"datasets/raydocs_full/data_api_dataset.txt\"}, {\"start_index\": 3969, \"end_index\": 8106, \"corpus_id\": \"datasets/raydocs_full/data_api_dataset.txt\"}, {\"start_index\": 2, \"end_index\": 255, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_k8s-ecosystem.txt\"}, {\"start_index\": 2, \"end_index\": 576, \"corpus_id\": \"datasets/raydocs_full/ray-contribute_index.txt\"}, {\"start_index\": 2, \"end_index\": 3127, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 2719, \"end_index\": 6922, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 6517, \"end_index\": 10121, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 10059, \"end_index\": 14489, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 14065, \"end_index\": 18552, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 18228, \"end_index\": 22820, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 22470, \"end_index\": 26711, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 26323, \"end_index\": 30531, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 30174, \"end_index\": 34547, \"corpus_id\": \"datasets/raydocs_full/tune_faq.txt\"}, {\"start_index\": 2, \"end_index\": 311, \"corpus_id\": \"datasets/raydocs_full/ray-more-libs_doc_ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit_all.txt\"}, {\"start_index\": 2, \"end_index\": 1345, \"corpus_id\": \"datasets/raydocs_full/tune_api_stoppers.txt\"}, {\"start_index\": 2, \"end_index\": 4194, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_gentle_walkthrough.txt\"}, {\"start_index\": 4197, \"end_index\": 8583, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_gentle_walkthrough.txt\"}, {\"start_index\": 8217, \"end_index\": 12560, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_gentle_walkthrough.txt\"}, {\"start_index\": 12429, \"end_index\": 15336, \"corpus_id\": \"datasets/raydocs_full/ray-core_examples_gentle_walkthrough.txt\"}, {\"start_index\": 2, \"end_index\": 4265, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_persist-kuberay-operator-logs.txt\"}, {\"start_index\": 3969, \"end_index\": 5218, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_user-guides_persist-kuberay-operator-logs.txt\"}, {\"start_index\": 2, \"end_index\": 4303, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_ml-example.txt\"}, {\"start_index\": 3995, \"end_index\": 7475, \"corpus_id\": \"datasets/raydocs_full/cluster_kubernetes_examples_ml-example.txt\"}, {\"start_index\": 2, \"end_index\": 619, \"corpus_id\": \"datasets/raydocs_full/rllib_package_ref_doc_ray.rllib.core.rl_module.rl_module.RLModule.get_state.txt\"}]"
          }
        }
      ],
      "console": []
    },
    {
      "id": "BYtC",
      "code_hash": "316e761712f7398a7f8caab948cd65a0",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"create-vector-embeddings-save-to-database\">Create vector embeddings, save to database</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "RGSE",
      "code_hash": "bfe6c52ad6cb33204c417302a4f9e6fa",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "Kclp",
      "code_hash": "46f9ceb9217b03122d58200bc258e314",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "emfo",
      "code_hash": "3953c7c6ae775a2ecffb3c58dd8f2a36",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<pre style='font-size: 12px'>Collection(name=inmem-document-index)</pre>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Hstk",
      "code_hash": "fbe11d8f650b933b51c09623348f3352",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"semantic-search-on-vector-embeddingg\">Semantic search on vector embeddingg.</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "nWHF",
      "code_hash": "d0edb9e4a79ee39a96911c65ef7a60de",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "iLit",
      "code_hash": "ab9560946fa85626461549f5de0a5a86",
      "outputs": [
        {
          "type": "data",
          "data": {
            "application/json": "[\"What is ray ?\", \"What is the difference between ray and spark?\", \"How to install ray?\"]"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ZHCJ",
      "code_hash": "8f3ceee7d3333a82a2a78324e1de01ab",
      "outputs": [
        {
          "type": "data",
          "data": {
            "application/json": "[[\"Security#\\nRay is an easy-to-use framework to run arbitrary code across one or more nodes in a Ray Cluster. Ray provides fault-tolerance, optimized scheduling, task orchestration, and auto-scaling to run a given workload.\\nTo achieve performant and distributed workloads, Ray components require intra-cluster communication. This communication includes central tenets like distributed memory and node-heartbeats, as well as auxiliary functions like metrics and logs. Ray leverages gRPC for a majority of this communication.\\nRay offers additional services to improve the developer experience. These services include Ray Dashboard (to allow for cluster introspection and debugging), Ray Jobs (hosted alongside the Dashboard, which services Ray Job submissions), and Ray Client (to allow for local, interactive development with a remote cluster). These services provide complete access to the Ray Cluster and the underlying compute resources.\\n\\nRay allows any clients to run arbitrary code. Be extremely careful about what is allowed to access your Ray Cluster\\nIf you expose these services (Ray Dashboard, Ray Jobs, Ray Client), anybody\\nwho can access the associated ports can execute arbitrary code on your Ray Cluster. This can happen:\\n\\nExplicitly: By submitting a Ray Job, or using the Ray Client\\nIndirectly: By calling the Dashboard REST APIs of these services\\nImplicitly: Ray extensively uses cloudpickle for serialization of arbitrary python objects. See the pickle documentation for more details on Pickle\\u2019s security model.\\n\\nThe Ray Dashboard, Ray Jobs and Ray Client are developer tools that you should\\nonly use with the necessary access controls in place to restrict access to trusted parties only.\\n\\n\\nPersonas#\\nWhen considering the security responsibilities of running Ray, think about the different personas interacting with Ray.\\n\\nRay Developers write code that relies on Ray. They either run a single-node Ray Cluster locally or multi-node Clusters remotely on provided compute infrastructure.\\nPlatform providers provide the compute environment on which Developers run Ray.\\nUsers interact with the output of Ray-powered applications.\\n\\n\\n\\nBest practices#\\nSecurity and isolation must be enforced outside of the Ray Cluster. Ray expects to run in a safe network environment and to act upon trusted code. Developers and platform providers must maintain the following invariants to ensure the safe operation of Ray Clusters.\\n\\nDeploy Ray Clusters in a controlled network environment#\\n\\nNetwork traffic between core Ray components and additional Ray components should always be in a controlled, isolated network. Access to additional services should be gated with strict network controls and/or external authentication/authorization proxies.\\ngRPC communication can be encrypted with TLS, but it\\u2019s not a replacement for network isolation.\\nPlatform providers are responsible for ensuring that Ray runs in sufficiently controlled network environments and that developers can access features like Ray Dashboard in a secure manner.\\n\\n\\n\\nOnly execute trusted code within Ray#\\n\\nRay faithfully executes code that is passed to it \\u2013 Ray doesn\\u2019t differentiate between a tuning experiment, a rootkit install, or an S3 bucket inspection.\\nRay developers are responsible for building their applications with this understanding in mind.\\n\\n\\n\\nEnforce isolation outside of Ray with multiple Ray Clusters#\\n\\nIf workloads require isolation from each other, use separate, isolated Ray Clusters. Ray can schedule multiple distinct Jobs in a single Cluster, but doesn\\u2019t attempt to enforce isolation between them. Similarly, Ray doesn\\u2019t implement access controls for developers interacting with a given cluster.\\nRay developers are responsible for determining which applications need to be separated and platform providers are responsible for providing this isolation.\", \"Ray Client#\\n\\nWarning\\nRay Client requires pip package ray[client]. If you installed the minimal Ray (e.g. pip install ray), please reinstall by executing pip install ray[client].\\n\\nWhat is the Ray Client?\\nThe Ray Client is an API that connects a Python script to a remote Ray cluster. Effectively, it allows you to leverage a remote Ray cluster just like you would with Ray running on your local machine.\\nBy changing ray.init() to ray.init(\\\"ray://<head_node_host>:<port>\\\"), you can connect from your laptop (or anywhere) directly to a remote cluster and scale-out your Ray code, while maintaining the ability to develop interactively in a Python shell. This will only work with Ray 1.5+.\\n# You can run this code outside of the Ray cluster!\\nimport ray\\n\\n# Starting the Ray client. This connects to a remote Ray cluster.\\nray.init(\\\"ray://<head_node_host>:10001\\\")\\n\\n# Normal Ray code follows\\n@ray.remote\\ndef do_work(x):\\n    return x ** x\\n\\ndo_work.remote(2)\\n#....\\n\\n\\n\\nWhen to use Ray Client#\\n\\nNote\\nRay Client has architectural limitations and may not work as expected when using Ray for ML workloads (like Ray Tune or Ray Train). Use Ray Jobs API for interactive development on ML projects.\\n\\nRay Client can be used when you want to connect an interactive Python shell to a remote cluster.\\n\\nUse ray.init(\\\"ray://<head_node_host>:10001\\\") (Ray Client) if you\\u2019ve set up a remote cluster at <head_node_host> and you want to do interactive work. This will connect your shell to the cluster. See the section on using Ray Client for more details on setting up your cluster.\\nUse ray.init() (non-client connection, no address specified) if you\\u2019re developing locally and want to connect to an existing cluster (i.e. ray start --head has already been run), or automatically create a local cluster and attach directly to it. This can also be used for Ray Job submission.\\n\\nRay Client is useful for developing interactively in a local Python shell. However, it requires a stable connection to the remote cluster and will terminate the workload if the connection is lost for more than 30 seconds. If you have a long running workload that you want to run on your cluster, we recommend using Ray Jobs instead.\\n\\n\\nClient arguments#\\nRay Client is used when the address passed into ray.init is prefixed with ray://. Besides the address, Client mode currently accepts two other arguments:\\n\\nnamespace (optional): Sets the namespace for the session.\\nruntime_env (optional): Sets the runtime environment for the session, allowing you to dynamically specify environment variables, packages, local files, and more.\\n\\n# Connects to an existing cluster at 1.2.3.4 listening on port 10001, using\\n# the namespace \\\"my_namespace\\\". The Ray workers will run inside a cluster-side\\n# copy of the local directory \\\"files/my_project\\\", in a Python environment with\\n# `toolz` and `requests` installed.\\nray.init(\\n    \\\"ray://1.2.3.4:10001\\\",\\n    namespace=\\\"my_namespace\\\",\\n    runtime_env={\\\"working_dir\\\": \\\"files/my_project\\\", \\\"pip\\\": [\\\"toolz\\\", \\\"requests\\\"]},\\n)\\n#....\\n\\n\\n\\n\\nHow do you use the Ray Client?#\\n\\nStep 1: Set up your Ray cluster#\\nIf you have a running Ray cluster (version >= 1.5), Ray Client server is likely already running on port 10001 of the head node by default. Otherwise, you\\u2019ll want to create a Ray cluster. To start a Ray cluster locally, you can run\\nray start --head\\n\\n\\nTo start a Ray cluster remotely, you can follow the directions in Getting Started.\\nIf necessary, you can modify the Ray Client server port to be other than 10001, by specifying --ray-client-server-port=... to the ray start command.\\n\\n\\nStep 2: Configure Access#\\nEnsure that your local machine can access the Ray Client port on the head node.\\nThe easiest way to accomplish this is to use SSH port forwarding or K8s port-forwarding.\\nThis allows you to connect to the Ray Client server on the head node via localhost.\\nFirst, open up an SSH connection with your Ray cluster and forward the\\nlistening port (10001). For Clusters launched with the Ray Cluster launcher this looks like:\\n$ ray up cluster.yaml\\n$ ray attach cluster.yaml -p 10001\\n\\n\\nThen connect to the Ray cluster from another terminal using  localhost as the\\nhead_node_host.\\nimport ray\\n\\n# This will connect to the cluster via the open SSH session.\\nray.init(\\\"ray://localhost:10001\\\")\\n\\n# Normal Ray code follows\\n@ray.remote\\ndef do_work(x):\\n    return x ** x\", \"What\\u2019s Ray Core?#\\n\\n\\nRay Core is a powerful distributed computing framework that provides a small set of essential primitives (tasks, actors, and objects) for building and scaling distributed applications.\\nThis walk-through introduces you to these core concepts with simple examples that demonstrate how to transform your Python functions and classes into distributed Ray tasks and actors, and how to work effectively with Ray objects.\\n\\nNote\\nRay has introduced an experimental API for high-performance workloads that\\u2019s\\nespecially well suited for applications using multiple GPUs.\\nSee Ray Compiled Graph for more details.\\n\\n\\nGetting Started#\\nTo get started, install Ray using pip install -U ray. For additional installation options, see Installing Ray.\\nThe first step is to import and initialize Ray:\\nimport ray\\n\\nray.init()\\n\\n\\n\\nNote\\nIn recent versions of Ray (>=1.5), ray.init() is automatically called on the first use of a Ray remote API.\\n\\n\\n\\nRunning a Task#\\nTasks are the simplest way to parallelize your Python functions across a Ray cluster. To create a task:\\n\\nDecorate your function with @ray.remote to indicate it should run remotely\\nCall the function with .remote() instead of a normal function call\\nUse ray.get() to retrieve the result from the returned future (Ray object reference)\\n\\nHere\\u2019s a simple example:\\n# Define the square task.\\n@ray.remote\\ndef square(x):\\n    return x * x\\n\\n# Launch four parallel square tasks.\\nfutures = [square.remote(i) for i in range(4)]\\n\\n# Retrieve results.\\nprint(ray.get(futures))\\n# -> [0, 1, 4, 9]\\n\\n\\n\\n\\nCalling an Actor#\\nWhile tasks are stateless, Ray actors allow you to create stateful workers that maintain their internal state between method calls.\\nWhen you instantiate a Ray actor:\\n\\nRay starts a dedicated worker process somewhere in your cluster\\nThe actor\\u2019s methods run on that specific worker and can access and modify its state\\nThe actor executes method calls serially in the order it receives them, preserving consistency\\n\\nHere\\u2019s a simple Counter example:\\n# Define the Counter actor.\\n@ray.remote\\nclass Counter:\\n    def __init__(self):\\n        self.i = 0\\n\\n    def get(self):\\n        return self.i\\n\\n    def incr(self, value):\\n        self.i += value\\n\\n# Create a Counter actor.\\nc = Counter.remote()\\n\\n# Submit calls to the actor. These calls run asynchronously but in\\n# submission order on the remote actor process.\\nfor _ in range(10):\\n    c.incr.remote(1)\\n\\n# Retrieve final actor state.\\nprint(ray.get(c.get.remote()))\\n# -> 10\\n\\n\\nThe preceding example demonstrates basic actor usage. For a more comprehensive example that combines both tasks and actors, see the Monte Carlo Pi estimation example.\\n\\n\\nPassing Objects#\\nRay\\u2019s distributed object store efficiently manages data across your cluster. There are three main ways to work with objects in Ray:\\n\\nImplicit creation: When tasks and actors return values, they are automatically stored in Ray\\u2019s distributed object store, returning object references that can be later retrieved.\\nExplicit creation: Use ray.put() to directly place objects in the store.\\nPassing references: You can pass object references to other tasks and actors, avoiding unnecessary data copying and enabling lazy execution.\\n\\nHere\\u2019s an example showing these techniques:\\nimport numpy as np\\n\\n# Define a task that sums the values in a matrix.\\n@ray.remote\\ndef sum_matrix(matrix):\\n    return np.sum(matrix)\\n\\n# Call the task with a literal argument value.\\nprint(ray.get(sum_matrix.remote(np.ones((100, 100)))))\\n# -> 10000.0\\n\\n# Put a large array into the object store.\\nmatrix_ref = ray.put(np.ones((1000, 1000)))\\n\\n# Call the task with the object reference as an argument.\\nprint(ray.get(sum_matrix.remote(matrix_ref)))\\n# -> 1000000.0\\n\\n\\n\\n\\nNext Steps#\\n\\nTip\\nTo monitor your application\\u2019s performance and resource usage, check out the Ray dashboard.\\n\\nYou can combine Ray\\u2019s simple primitives in powerful ways to express virtually any distributed computation pattern. To dive deeper into Ray\\u2019s key concepts,\\nexplore these user guides:\\n\\n\\n\\n\\n\\n\\nUsing remote functions (Tasks)\\n\\n\\n\\n\\n\\n\\n\\nUsing remote classes (Actors)\\n\\n\\n\\n\\n\\n\\n\\nWorking with Ray Objects\", \"Overview#\\nRay is an open-source unified framework for scaling AI and Python applications like machine learning. It provides the compute layer for parallel processing so that you don\\u2019t need to be a distributed systems expert. Ray minimizes the complexity of running your distributed individual and end-to-end machine learning workflows with these components:\\n\\nScalable libraries for common machine learning tasks such as data preprocessing, distributed training, hyperparameter tuning, reinforcement learning, and model serving.\\nPythonic distributed computing primitives for parallelizing and scaling Python applications.\\nIntegrations and utilities for integrating and deploying a Ray cluster with existing tools and infrastructure such as Kubernetes, AWS, GCP, and Azure.\\n\\nFor data scientists and machine learning practitioners, Ray lets you scale jobs without needing infrastructure expertise:\\n\\nEasily parallelize and distribute ML workloads across multiple nodes and GPUs.\\nLeverage the ML ecosystem with native and extensible integrations.\\n\\nFor ML platform builders and ML engineers, Ray:\\n\\nProvides compute abstractions for creating a scalable and robust ML platform.\\nProvides a unified ML API that simplifies onboarding and integration with the broader ML ecosystem.\\nReduces friction between development and production by enabling the same Python code to scale seamlessly from a laptop to a large cluster.\\n\\nFor distributed systems engineers, Ray automatically handles key processes:\\n\\nOrchestration\\u2013Managing the various components of a distributed system.\\nScheduling\\u2013Coordinating when and where tasks are executed.\\nFault tolerance\\u2013Ensuring tasks complete regardless of inevitable points of failure.\\nAuto-scaling\\u2013Adjusting the number of resources allocated to dynamic demand.\\n\\n\\nWhat you can do with Ray#\\nThese are some common ML workloads that individuals, organizations, and companies leverage Ray to build their AI applications:\\n\\nBatch inference on CPUs and GPUs\\nModel serving\\nDistributed training of large models\\nParallel hyperparameter tuning experiments\\nReinforcement learning\\nML platform\\n\\n\\n\\nRay framework#\\n\\n\\n\\n\\n\\n\\nStack of Ray libraries - unified toolkit for ML workloads.\\n\\n\\n\\nRay\\u2019s unified compute framework consists of three layers:\\n\\nRay AI Libraries\\u2013An open-source, Python, domain-specific set of libraries that equip ML engineers, data scientists, and researchers with a scalable and unified toolkit for ML applications.\\nRay Core\\u2013An open-source, Python, general purpose, distributed computing library that enables ML engineers and Python developers to scale Python applications and accelerate machine learning workloads.\\nRay Clusters\\u2013A set of worker nodes connected to a common Ray head node. Ray clusters can be fixed-size, or they can autoscale up and down according to the resources requested by applications running on the cluster.\\n\\n\\n\\n\\n\\n\\nScale machine learning workloads\\n\\n\\nBuild ML applications with a toolkit of libraries for distributed\\ndata processing,\\nmodel training,\\ntuning,\\nreinforcement learning,\\nmodel serving,\\nand more.\\n\\n\\nRay AI Libraries\\n\\n\\n\\n\\n\\n\\nBuild distributed applications\\n\\n\\nBuild and run distributed applications with a\\nsimple and flexible API.\\nParallelize single machine code with\\nlittle to zero code changes.\\n\\n\\nRay Core\\n\\n\\n\\n\\n\\n\\nDeploy large-scale workloads\\n\\n\\nDeploy workloads on AWS, GCP, Azure or\\non premise.\\nUse Ray cluster managers to run Ray on existing\\nKubernetes,\\nYARN,\\nor Slurm clusters.\\n\\n\\nRay Clusters\\n\\n\\n\\n\\n\\nEach of Ray\\u2019s five native libraries distributes a specific ML task:\\n\\nData: Scalable, framework-agnostic data loading and transformation across training, tuning, and prediction.\\nTrain: Distributed multi-node and multi-core model training with fault tolerance that integrates with popular training libraries.\\nTune: Scalable hyperparameter tuning to optimize model performance.\\nServe: Scalable and programmable serving to deploy models for online inference, with optional microbatching to improve performance.\\nRLlib: Scalable distributed reinforcement learning workloads.\\n\\nRay\\u2019s libraries are for both data scientists and ML engineers alike. For data scientists, these libraries can be used to scale individual workloads, and also end-to-end ML applications. For ML Engineers, these libraries provides scalable platform abstractions that can be used to easily onboard and integrate tooling from the broader ML ecosystem.\\nFor custom applications, the Ray Core library enables Python developers to easily build scalable, distributed systems that can run on a laptop, cluster, cloud, or Kubernetes. It\\u2019s the foundation that Ray AI libraries and third-party integrations (Ray ecosystem) are built on.\\nRay runs on any machine, cluster, cloud provider, and Kubernetes, and features a growing\\necosystem of community integrations.\", \"Getting Started#\\nRay is an open source unified framework for scaling AI and Python applications. It provides a simple, universal API for building distributed applications that can scale from a laptop to a cluster.\\n\\nWhat\\u2019s Ray?#\\nRay simplifies distributed computing by providing:\\n\\nScalable compute primitives: Tasks and actors for painless parallel programming\\nSpecialized AI libraries: Tools for common ML workloads like data processing, model training, hyperparameter tuning, and model serving\\nUnified resource management: Seamless scaling from laptop to cloud with automatic resource handling\\n\\n\\n\\nChoose Your Path#\\nSelect the guide that matches your needs:\\n\\nScale ML workloads: Ray Libraries Quickstart\\nScale general Python applications: Ray Core Quickstart\\nDeploy to the cloud: Ray Clusters Quickstart\\nDebug and monitor applications: Debugging and Monitoring Quickstart\\n\\n\\n\\nRay AI Libraries Quickstart#\\nUse individual libraries for ML workloads. Each library specializes in a specific part of the ML workflow, from data processing to model serving. Click on the dropdowns for your workload below.\\n\\n\\n Data: Scalable Datasets for ML\\n\\n\\n\\n\\nRay Data provides distributed data processing optimized for machine learning and AI workloads. It efficiently streams data through data pipelines.\\nHere\\u2019s an example on how to scale offline inference and training ingest with Ray Data.\\n\\nNote\\nTo run this example, install Ray Data:\\npip install -U \\\"ray[data]\\\"\\n\\n\\n\\nfrom typing import Dict\\nimport numpy as np\\nimport ray\\n\\n# Create datasets from on-disk files, Python objects, and cloud storage like S3.\\nds = ray.data.read_csv(\\\"s3://anonymous@ray-example-data/iris.csv\\\")\\n\\n# Apply functions to transform data. Ray Data executes transformations in parallel.\\ndef compute_area(batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\\n    length = batch[\\\"petal length (cm)\\\"]\\n    width = batch[\\\"petal width (cm)\\\"]\\n    batch[\\\"petal area (cm^2)\\\"] = length * width\\n    return batch\\n\\ntransformed_ds = ds.map_batches(compute_area)\\n\\n# Iterate over batches of data.\\nfor batch in transformed_ds.iter_batches(batch_size=4):\\n    print(batch)\\n\\n# Save dataset contents to on-disk files or cloud storage.\\ntransformed_ds.write_parquet(\\\"local:///tmp/iris/\\\")\\n\\n\\nLearn more about Ray Data\\n\\n\\n\\n Train: Distributed Model Training\\n\\n\\n\\n\\nRay Train makes distributed model training simple. It abstracts away the complexity of setting up distributed training across popular frameworks like PyTorch and TensorFlow.\\n\\n\\n\\nPyTorch\\nThis example shows how you can use Ray Train with PyTorch.\\nTo run this example install Ray Train and PyTorch packages:\\n\\nNote\\npip install -U \\\"ray[train]\\\" torch torchvision\\n\\n\\n\\nSet up your dataset and model.\\nimport torch\\nimport torch.nn as nn\\nfrom torch.utils.data import DataLoader\\nfrom torchvision import datasets\\nfrom torchvision.transforms import ToTensor\\n\\ndef get_dataset():\\n    return datasets.FashionMNIST(\\n        root=\\\"/tmp/data\\\",\\n        train=True,\\n        download=True,\\n        transform=ToTensor(),\\n    )\\n\\nclass NeuralNetwork(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.flatten = nn.Flatten()\\n        self.linear_relu_stack = nn.Sequential(\\n            nn.Linear(28 * 28, 512),\\n            nn.ReLU(),\\n            nn.Linear(512, 512),\\n            nn.ReLU(),\\n            nn.Linear(512, 10),\\n        )\\n\\n    def forward(self, inputs):\\n        inputs = self.flatten(inputs)\\n        logits = self.linear_relu_stack(inputs)\\n        return logits\\n\\n\\nNow define your single-worker PyTorch training function.\\ndef train_func():\\n    num_epochs = 3\\n    batch_size = 64\\n\\n    dataset = get_dataset()\\n    dataloader = DataLoader(dataset, batch_size=batch_size)\\n\\n    model = NeuralNetwork()\\n\\n    criterion = nn.CrossEntropyLoss()\\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\\n\\n    for epoch in range(num_epochs):\\n        for inputs, labels in dataloader:\\n            optimizer.zero_grad()\\n            pred = model(inputs)\\n            loss = criterion(pred, labels)\\n            loss.backward()\\n            optimizer.step()\\n        print(f\\\"epoch: {epoch}, loss: {loss.item()}\\\")\\n\\n\\nThis training function can be executed with:\\ntrain_func()\\n\\n\\nConvert this to a distributed multi-worker training function.\\nUse the ray.train.torch.prepare_model and\\nray.train.torch.prepare_data_loader utility functions to\\nset up your model and data for distributed training.\\nThis automatically wraps the model with DistributedDataParallel\\nand places it on the right device, and adds DistributedSampler to the DataLoaders.\\nimport ray.train.torch\\n\\ndef train_func_distributed():\\n    num_epochs = 3\\n    batch_size = 64\"], [\"Using Spark on Ray (RayDP)#\\nRayDP combines your Spark and Ray clusters, making it easy to do large scale\\ndata processing using the PySpark API and seamlessly use that data to train\\nyour models using TensorFlow and PyTorch.\\nFor more information and examples, see the RayDP Github page:\\noap-project/raydp\\n\\nInstalling RayDP#\\nRayDP can be installed from PyPI and supports PySpark 3.0 and 3.1.\\n\\nNote\\nRayDP requires ray >= 1.2.0\\n\\n\\nNote\\nIn order to run Spark, the head and worker nodes will need Java installed.\\n\\n\\n\\nCreating a Spark Session#\\nTo create a spark session, call raydp.init_spark\\nFor example,\\nimport ray\\nimport raydp\\n\\nray.init()\\nspark = raydp.init_spark(\\n  app_name = \\\"example\\\",\\n  num_executors = 10,\\n  executor_cores = 64,\\n  executor_memory = \\\"256GB\\\"\\n)\\n\\n\\n\\n\\nDeep Learning with a Spark DataFrame#\\n\\nTraining a Spark DataFrame with TensorFlow#\\nraydp.tf.TFEstimator provides an API for training with TensorFlow.\\nfrom pyspark.sql.functions import col\\ndf = spark.range(1, 1000)\\n# calculate z = x + 2y + 1000\\ndf = df.withColumn(\\\"x\\\", col(\\\"id\\\")*2)\\\\\\n  .withColumn(\\\"y\\\", col(\\\"id\\\") + 200)\\\\\\n  .withColumn(\\\"z\\\", col(\\\"x\\\") + 2*col(\\\"y\\\") + 1000)\\n\\nfrom raydp.utils import random_split\\ntrain_df, test_df = random_split(df, [0.7, 0.3])\\n\\n# TensorFlow code\\nfrom tensorflow import keras\\ninput_1 = keras.Input(shape=(1,))\\ninput_2 = keras.Input(shape=(1,))\\n\\nconcatenated = keras.layers.concatenate([input_1, input_2])\\noutput = keras.layers.Dense(1, activation='sigmoid')(concatenated)\\nmodel = keras.Model(inputs=[input_1, input_2],\\n                    outputs=output)\\n\\noptimizer = keras.optimizers.Adam(0.01)\\nloss = keras.losses.MeanSquaredError()\\n\\nfrom raydp.tf import TFEstimator\\nestimator = TFEstimator(\\n  num_workers=2,\\n  model=model,\\n  optimizer=optimizer,\\n  loss=loss,\\n  metrics=[\\\"accuracy\\\", \\\"mse\\\"],\\n  feature_columns=[\\\"x\\\", \\\"y\\\"],\\n  label_column=\\\"z\\\",\\n  batch_size=1000,\\n  num_epochs=2,\\n  use_gpu=False,\\n  config={\\\"fit_config\\\": {\\\"steps_per_epoch\\\": 2}})\\n\\nestimator.fit_on_spark(train_df, test_df)\\n\\ntensorflow_model = estimator.get_model()\\n\\nestimator.shutdown()\\n\\n\\n\\n\\nTraining a Spark DataFrame with PyTorch#\\nSimilarly, raydp.torch.TorchEstimator provides an API for training with\\nPyTorch.\\nfrom pyspark.sql.functions import col\\ndf = spark.range(1, 1000)\\n# calculate z = x + 2y + 1000\\ndf = df.withColumn(\\\"x\\\", col(\\\"id\\\")*2)\\\\\\n  .withColumn(\\\"y\\\", col(\\\"id\\\") + 200)\\\\\\n  .withColumn(\\\"z\\\", col(\\\"x\\\") + 2*col(\\\"y\\\") + 1000)\\n\\nfrom raydp.utils import random_split\\ntrain_df, test_df = random_split(df, [0.7, 0.3])\\n\\n# PyTorch Code\\nimport torch\\nclass LinearModel(torch.nn.Module):\\n    def __init__(self):\\n        super(LinearModel, self).__init__()\\n        self.linear = torch.nn.Linear(2, 1)\\n\\n    def forward(self, x, y):\\n        x = torch.cat([x, y], dim=1)\\n        return self.linear(x)\\n\\nmodel = LinearModel()\\noptimizer = torch.optim.Adam(model.parameters())\\nloss_fn = torch.nn.MSELoss()\\n\\ndef lr_scheduler_creator(optimizer, config):\\n    return torch.optim.lr_scheduler.MultiStepLR(\\n      optimizer, milestones=[150, 250, 350], gamma=0.1)\\n\\n# You can use the RayDP Estimator API or libraries like Ray Train for distributed training.\\nfrom raydp.torch import TorchEstimator\\nestimator = TorchEstimator(\\n  num_workers = 2,\\n  model = model,\\n  optimizer = optimizer,\\n  loss = loss_fn,\\n  lr_scheduler_creator=lr_scheduler_creator,\\n  feature_columns = [\\\"x\\\", \\\"y\\\"],\\n  label_column = [\\\"z\\\"],\\n  batch_size = 1000,\\n  num_epochs = 2\\n)\\n\\nestimator.fit_on_spark(train_df, test_df)\\n\\npytorch_model = estimator.get_model()\\n\\nestimator.shutdown()\", \"Ray Client#\\n\\nWarning\\nRay Client requires pip package ray[client]. If you installed the minimal Ray (e.g. pip install ray), please reinstall by executing pip install ray[client].\\n\\nWhat is the Ray Client?\\nThe Ray Client is an API that connects a Python script to a remote Ray cluster. Effectively, it allows you to leverage a remote Ray cluster just like you would with Ray running on your local machine.\\nBy changing ray.init() to ray.init(\\\"ray://<head_node_host>:<port>\\\"), you can connect from your laptop (or anywhere) directly to a remote cluster and scale-out your Ray code, while maintaining the ability to develop interactively in a Python shell. This will only work with Ray 1.5+.\\n# You can run this code outside of the Ray cluster!\\nimport ray\\n\\n# Starting the Ray client. This connects to a remote Ray cluster.\\nray.init(\\\"ray://<head_node_host>:10001\\\")\\n\\n# Normal Ray code follows\\n@ray.remote\\ndef do_work(x):\\n    return x ** x\\n\\ndo_work.remote(2)\\n#....\\n\\n\\n\\nWhen to use Ray Client#\\n\\nNote\\nRay Client has architectural limitations and may not work as expected when using Ray for ML workloads (like Ray Tune or Ray Train). Use Ray Jobs API for interactive development on ML projects.\\n\\nRay Client can be used when you want to connect an interactive Python shell to a remote cluster.\\n\\nUse ray.init(\\\"ray://<head_node_host>:10001\\\") (Ray Client) if you\\u2019ve set up a remote cluster at <head_node_host> and you want to do interactive work. This will connect your shell to the cluster. See the section on using Ray Client for more details on setting up your cluster.\\nUse ray.init() (non-client connection, no address specified) if you\\u2019re developing locally and want to connect to an existing cluster (i.e. ray start --head has already been run), or automatically create a local cluster and attach directly to it. This can also be used for Ray Job submission.\\n\\nRay Client is useful for developing interactively in a local Python shell. However, it requires a stable connection to the remote cluster and will terminate the workload if the connection is lost for more than 30 seconds. If you have a long running workload that you want to run on your cluster, we recommend using Ray Jobs instead.\\n\\n\\nClient arguments#\\nRay Client is used when the address passed into ray.init is prefixed with ray://. Besides the address, Client mode currently accepts two other arguments:\\n\\nnamespace (optional): Sets the namespace for the session.\\nruntime_env (optional): Sets the runtime environment for the session, allowing you to dynamically specify environment variables, packages, local files, and more.\\n\\n# Connects to an existing cluster at 1.2.3.4 listening on port 10001, using\\n# the namespace \\\"my_namespace\\\". The Ray workers will run inside a cluster-side\\n# copy of the local directory \\\"files/my_project\\\", in a Python environment with\\n# `toolz` and `requests` installed.\\nray.init(\\n    \\\"ray://1.2.3.4:10001\\\",\\n    namespace=\\\"my_namespace\\\",\\n    runtime_env={\\\"working_dir\\\": \\\"files/my_project\\\", \\\"pip\\\": [\\\"toolz\\\", \\\"requests\\\"]},\\n)\\n#....\\n\\n\\n\\n\\nHow do you use the Ray Client?#\\n\\nStep 1: Set up your Ray cluster#\\nIf you have a running Ray cluster (version >= 1.5), Ray Client server is likely already running on port 10001 of the head node by default. Otherwise, you\\u2019ll want to create a Ray cluster. To start a Ray cluster locally, you can run\\nray start --head\\n\\n\\nTo start a Ray cluster remotely, you can follow the directions in Getting Started.\\nIf necessary, you can modify the Ray Client server port to be other than 10001, by specifying --ray-client-server-port=... to the ray start command.\\n\\n\\nStep 2: Configure Access#\\nEnsure that your local machine can access the Ray Client port on the head node.\\nThe easiest way to accomplish this is to use SSH port forwarding or K8s port-forwarding.\\nThis allows you to connect to the Ray Client server on the head node via localhost.\\nFirst, open up an SSH connection with your Ray cluster and forward the\\nlistening port (10001). For Clusters launched with the Ray Cluster launcher this looks like:\\n$ ray up cluster.yaml\\n$ ray attach cluster.yaml -p 10001\\n\\n\\nThen connect to the Ray cluster from another terminal using  localhost as the\\nhead_node_host.\\nimport ray\\n\\n# This will connect to the cluster via the open SSH session.\\nray.init(\\\"ray://localhost:10001\\\")\\n\\n# Normal Ray code follows\\n@ray.remote\\ndef do_work(x):\\n    return x ** x\", \"Getting Started#\\nRay is an open source unified framework for scaling AI and Python applications. It provides a simple, universal API for building distributed applications that can scale from a laptop to a cluster.\\n\\nWhat\\u2019s Ray?#\\nRay simplifies distributed computing by providing:\\n\\nScalable compute primitives: Tasks and actors for painless parallel programming\\nSpecialized AI libraries: Tools for common ML workloads like data processing, model training, hyperparameter tuning, and model serving\\nUnified resource management: Seamless scaling from laptop to cloud with automatic resource handling\\n\\n\\n\\nChoose Your Path#\\nSelect the guide that matches your needs:\\n\\nScale ML workloads: Ray Libraries Quickstart\\nScale general Python applications: Ray Core Quickstart\\nDeploy to the cloud: Ray Clusters Quickstart\\nDebug and monitor applications: Debugging and Monitoring Quickstart\\n\\n\\n\\nRay AI Libraries Quickstart#\\nUse individual libraries for ML workloads. Each library specializes in a specific part of the ML workflow, from data processing to model serving. Click on the dropdowns for your workload below.\\n\\n\\n Data: Scalable Datasets for ML\\n\\n\\n\\n\\nRay Data provides distributed data processing optimized for machine learning and AI workloads. It efficiently streams data through data pipelines.\\nHere\\u2019s an example on how to scale offline inference and training ingest with Ray Data.\\n\\nNote\\nTo run this example, install Ray Data:\\npip install -U \\\"ray[data]\\\"\\n\\n\\n\\nfrom typing import Dict\\nimport numpy as np\\nimport ray\\n\\n# Create datasets from on-disk files, Python objects, and cloud storage like S3.\\nds = ray.data.read_csv(\\\"s3://anonymous@ray-example-data/iris.csv\\\")\\n\\n# Apply functions to transform data. Ray Data executes transformations in parallel.\\ndef compute_area(batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\\n    length = batch[\\\"petal length (cm)\\\"]\\n    width = batch[\\\"petal width (cm)\\\"]\\n    batch[\\\"petal area (cm^2)\\\"] = length * width\\n    return batch\\n\\ntransformed_ds = ds.map_batches(compute_area)\\n\\n# Iterate over batches of data.\\nfor batch in transformed_ds.iter_batches(batch_size=4):\\n    print(batch)\\n\\n# Save dataset contents to on-disk files or cloud storage.\\ntransformed_ds.write_parquet(\\\"local:///tmp/iris/\\\")\\n\\n\\nLearn more about Ray Data\\n\\n\\n\\n Train: Distributed Model Training\\n\\n\\n\\n\\nRay Train makes distributed model training simple. It abstracts away the complexity of setting up distributed training across popular frameworks like PyTorch and TensorFlow.\\n\\n\\n\\nPyTorch\\nThis example shows how you can use Ray Train with PyTorch.\\nTo run this example install Ray Train and PyTorch packages:\\n\\nNote\\npip install -U \\\"ray[train]\\\" torch torchvision\\n\\n\\n\\nSet up your dataset and model.\\nimport torch\\nimport torch.nn as nn\\nfrom torch.utils.data import DataLoader\\nfrom torchvision import datasets\\nfrom torchvision.transforms import ToTensor\\n\\ndef get_dataset():\\n    return datasets.FashionMNIST(\\n        root=\\\"/tmp/data\\\",\\n        train=True,\\n        download=True,\\n        transform=ToTensor(),\\n    )\\n\\nclass NeuralNetwork(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.flatten = nn.Flatten()\\n        self.linear_relu_stack = nn.Sequential(\\n            nn.Linear(28 * 28, 512),\\n            nn.ReLU(),\\n            nn.Linear(512, 512),\\n            nn.ReLU(),\\n            nn.Linear(512, 10),\\n        )\\n\\n    def forward(self, inputs):\\n        inputs = self.flatten(inputs)\\n        logits = self.linear_relu_stack(inputs)\\n        return logits\\n\\n\\nNow define your single-worker PyTorch training function.\\ndef train_func():\\n    num_epochs = 3\\n    batch_size = 64\\n\\n    dataset = get_dataset()\\n    dataloader = DataLoader(dataset, batch_size=batch_size)\\n\\n    model = NeuralNetwork()\\n\\n    criterion = nn.CrossEntropyLoss()\\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\\n\\n    for epoch in range(num_epochs):\\n        for inputs, labels in dataloader:\\n            optimizer.zero_grad()\\n            pred = model(inputs)\\n            loss = criterion(pred, labels)\\n            loss.backward()\\n            optimizer.step()\\n        print(f\\\"epoch: {epoch}, loss: {loss.item()}\\\")\\n\\n\\nThis training function can be executed with:\\ntrain_func()\\n\\n\\nConvert this to a distributed multi-worker training function.\\nUse the ray.train.torch.prepare_model and\\nray.train.torch.prepare_data_loader utility functions to\\nset up your model and data for distributed training.\\nThis automatically wraps the model with DistributedDataParallel\\nand places it on the right device, and adds DistributedSampler to the DataLoaders.\\nimport ray.train.torch\\n\\ndef train_func_distributed():\\n    num_epochs = 3\\n    batch_size = 64\", \"Security#\\nRay is an easy-to-use framework to run arbitrary code across one or more nodes in a Ray Cluster. Ray provides fault-tolerance, optimized scheduling, task orchestration, and auto-scaling to run a given workload.\\nTo achieve performant and distributed workloads, Ray components require intra-cluster communication. This communication includes central tenets like distributed memory and node-heartbeats, as well as auxiliary functions like metrics and logs. Ray leverages gRPC for a majority of this communication.\\nRay offers additional services to improve the developer experience. These services include Ray Dashboard (to allow for cluster introspection and debugging), Ray Jobs (hosted alongside the Dashboard, which services Ray Job submissions), and Ray Client (to allow for local, interactive development with a remote cluster). These services provide complete access to the Ray Cluster and the underlying compute resources.\\n\\nRay allows any clients to run arbitrary code. Be extremely careful about what is allowed to access your Ray Cluster\\nIf you expose these services (Ray Dashboard, Ray Jobs, Ray Client), anybody\\nwho can access the associated ports can execute arbitrary code on your Ray Cluster. This can happen:\\n\\nExplicitly: By submitting a Ray Job, or using the Ray Client\\nIndirectly: By calling the Dashboard REST APIs of these services\\nImplicitly: Ray extensively uses cloudpickle for serialization of arbitrary python objects. See the pickle documentation for more details on Pickle\\u2019s security model.\\n\\nThe Ray Dashboard, Ray Jobs and Ray Client are developer tools that you should\\nonly use with the necessary access controls in place to restrict access to trusted parties only.\\n\\n\\nPersonas#\\nWhen considering the security responsibilities of running Ray, think about the different personas interacting with Ray.\\n\\nRay Developers write code that relies on Ray. They either run a single-node Ray Cluster locally or multi-node Clusters remotely on provided compute infrastructure.\\nPlatform providers provide the compute environment on which Developers run Ray.\\nUsers interact with the output of Ray-powered applications.\\n\\n\\n\\nBest practices#\\nSecurity and isolation must be enforced outside of the Ray Cluster. Ray expects to run in a safe network environment and to act upon trusted code. Developers and platform providers must maintain the following invariants to ensure the safe operation of Ray Clusters.\\n\\nDeploy Ray Clusters in a controlled network environment#\\n\\nNetwork traffic between core Ray components and additional Ray components should always be in a controlled, isolated network. Access to additional services should be gated with strict network controls and/or external authentication/authorization proxies.\\ngRPC communication can be encrypted with TLS, but it\\u2019s not a replacement for network isolation.\\nPlatform providers are responsible for ensuring that Ray runs in sufficiently controlled network environments and that developers can access features like Ray Dashboard in a secure manner.\\n\\n\\n\\nOnly execute trusted code within Ray#\\n\\nRay faithfully executes code that is passed to it \\u2013 Ray doesn\\u2019t differentiate between a tuning experiment, a rootkit install, or an S3 bucket inspection.\\nRay developers are responsible for building their applications with this understanding in mind.\\n\\n\\n\\nEnforce isolation outside of Ray with multiple Ray Clusters#\\n\\nIf workloads require isolation from each other, use separate, isolated Ray Clusters. Ray can schedule multiple distinct Jobs in a single Cluster, but doesn\\u2019t attempt to enforce isolation between them. Similarly, Ray doesn\\u2019t implement access controls for developers interacting with a given cluster.\\nRay developers are responsible for determining which applications need to be separated and platform providers are responsible for providing this isolation.\", \"Core API#\\n\\n\\nray.init\\nConnect to an existing Ray cluster or start one and connect to it.\\n\\nray.shutdown\\nDisconnect the worker, and terminate processes started by ray.init().\\n\\nray.is_initialized\\nCheck if ray.init has been called yet.\\n\\nray.job_config.JobConfig\\nA class used to store the configurations of a job.\\n\\nray.LoggingConfig\\nLogging configuration for a Ray job.\\n\\n\\n\\n\\nTasks#\\n\\n\\nray.remote\\nDefines a remote function or an actor class.\\n\\nray.remote_function.RemoteFunction.options\\nConfigures and overrides the task invocation parameters.\\n\\nray.cancel\\nCancels a task.\\n\\n\\n\\n\\n\\nActors#\\n\\n\\nray.remote\\nDefines a remote function or an actor class.\\n\\nray.actor.ActorClass\\nAn actor class.\\n\\nray.actor.ActorClass.options\\nConfigures and overrides the actor instantiation parameters.\\n\\nray.actor.ActorMethod\\nA class used to invoke an actor method.\\n\\nray.actor.ActorHandle\\nA handle to an actor.\\n\\nray.actor.ActorClassInheritanceException\\n\\n\\nray.actor.exit_actor\\nIntentionally exit the current actor.\\n\\nray.method\\nAnnotate an actor method.\\n\\nray.get_actor\\nGet a handle to a named actor.\\n\\nray.kill\\nKill an actor forcefully.\\n\\n\\n\\n\\n\\nObjects#\\n\\n\\nray.get\\nGet a remote object or a list of remote objects from the object store.\\n\\nray.wait\\nReturn a list of IDs that are ready and a list of IDs that are not.\\n\\nray.put\\nStore an object in the object store.\\n\\n\\n\\n\\n\\nRuntime Context#\\n\\n\\nray.runtime_context.get_runtime_context\\nGet the runtime context of the current driver/worker.\\n\\nray.runtime_context.RuntimeContext\\nA class used for getting runtime context.\\n\\nray.get_gpu_ids\\nGet the IDs of the GPUs that are available to the worker.\\n\\n\\n\\n\\n\\nCross Language#\\n\\n\\nray.cross_language.java_function\\nDefine a Java function.\\n\\nray.cross_language.java_actor_class\\nDefine a Java actor class.\"], [\"Installing Ray#\\n\\n\\n\\nRay currently officially supports x86_64, aarch64 (ARM) for Linux, and Apple silicon (M1) hardware.\\nRay on Windows is currently in beta.\\n\\nOfficial Releases#\\n\\nFrom Wheels#\\nYou can install the latest official version of Ray from PyPI on Linux, Windows,\\nand macOS by choosing the option that best matches your use case.\\n\\n\\n\\nRecommended\\nFor machine learning applications\\npip install -U \\\"ray[data,train,tune,serve]\\\"\\n\\n# For reinforcement learning support, install RLlib instead.\\n# pip install -U \\\"ray[rllib]\\\"\\n\\n\\nFor general Python applications\\npip install -U \\\"ray[default]\\\"\\n\\n# If you don't want Ray Dashboard or Cluster Launcher, install Ray with minimal dependencies instead.\\n# pip install -U \\\"ray\\\"\\n\\n\\n\\n\\n\\nAdvanced\\n\\n\\n\\n\\n\\n\\nCommand\\nInstalled components\\n\\n\\n\\npip install -U \\\"ray\\\"\\nCore\\n\\npip install -U \\\"ray[default]\\\"\\nCore, Dashboard, Cluster Launcher\\n\\npip install -U \\\"ray[data]\\\"\\nCore, Data\\n\\npip install -U \\\"ray[train]\\\"\\nCore, Train\\n\\npip install -U \\\"ray[tune]\\\"\\nCore, Tune\\n\\npip install -U \\\"ray[serve]\\\"\\nCore, Dashboard, Cluster Launcher, Serve\\n\\npip install -U \\\"ray[serve-grpc]\\\"\\nCore, Dashboard, Cluster Launcher, Serve with gRPC support\\n\\npip install -U \\\"ray[rllib]\\\"\\nCore, Tune, RLlib\\n\\npip install -U \\\"ray[all]\\\"\\nCore, Dashboard, Cluster Launcher, Data, Train, Tune, Serve, RLlib. This option isn\\u2019t recommended. Specify the extras you need as shown below instead.\\n\\n\\n\\n\\nTip\\nYou can combine installation extras.\\nFor example, to install Ray with Dashboard, Cluster Launcher, and Train support, you can run:\\npip install -U \\\"ray[default,train]\\\"\\n\\n\\n\\n\\n\\n\\n\\n\\nDaily Releases (Nightlies)#\\nYou can install the nightly Ray wheels via the following links. These daily releases are tested via automated tests but do not go through the full release process. To install these wheels, use the following pip command and wheels:\\n# Clean removal of previous install\\npip uninstall -y ray\\n# Install Ray with support for the dashboard + cluster launcher\\npip install -U \\\"ray[default] @ LINK_TO_WHEEL.whl\\\"\\n\\n# Install Ray with minimal dependencies\\n# pip install -U LINK_TO_WHEEL.whl\\n\\n\\n\\n\\n\\nLinux\\n\\n\\nLinux (x86_64)\\nLinux (arm64/aarch64)\\n\\n\\n\\nLinux Python 3.9 (x86_64)\\nLinux Python 3.9 (aarch64)\\n\\nLinux Python 3.10 (x86_64)\\nLinux Python 3.10 (aarch64)\\n\\nLinux Python 3.11 (x86_64)\\nLinux Python 3.11 (aarch64)\\n\\nLinux Python 3.12 (x86_64)\\nLinux Python 3.12 (aarch64)\\n\\nLinux Python 3.13 (x86_64) (beta)\\nLinux Python 3.13 (aarch64) (beta)\\n\\n\\n\\n\\n\\n\\nMacOS\\n\\n\\nMacOS (x86_64)\\nMacOS (arm64)\\n\\n\\n\\nMacOS Python 3.9 (x86_64)\\nMacOS Python 3.9 (arm64)\\n\\nMacOS Python 3.10 (x86_64)\\nMacOS Python 3.10 (arm64)\\n\\nMacOS Python 3.11 (x86_64)\\nMacOS Python 3.11 (arm64)\\n\\nMacOS Python 3.12 (x86_64)\\nMacOS Python 3.12 (arm64)\\n\\nMacOS Python 3.13 (x86_64) (beta)\\nMacOS Python 3.13 (arm64) (beta)\\n\\n\\n\\n\\n\\n\\nWindows (beta)\\n\\n\\nWindows (beta)\\n\\n\\n\\nWindows Python 3.9\\n\\nWindows Python 3.10\\n\\nWindows Python 3.11\\n\\nWindows Python 3.12\\n\\n\\n\\n\\n\\n\\nNote\\nOn Windows, support for multi-node Ray clusters is currently experimental and untested.\\nIf you run into issues please file a report at ray-project/ray#issues.\\n\\n\\nNote\\nUsage stats collection is enabled by default (can be disabled) for nightly wheels including both local clusters started via ray.init() and remote clusters via cli.\\n\\n\\n\\nInstalling from a specific commit#\\nYou can install the Ray wheels of any particular commit on master with the following template. You need to specify the commit hash, Ray version, Operating System, and Python version:\\npip install https://s3-us-west-2.amazonaws.com/ray-wheels/master/{COMMIT_HASH}/ray-{RAY_VERSION}-{PYTHON_VERSION}-{PYTHON_VERSION}-{OS_VERSION}.whl\", \"Installing Ray#\\n\\n\\n\\nRay currently officially supports x86_64, aarch64 (ARM) for Linux, and Apple silicon (M1) hardware.\\nRay on Windows is currently in beta.\\n\\nOfficial Releases#\\n\\nFrom Wheels#\\nYou can install the latest official version of Ray from PyPI on Linux, Windows,\\nand macOS by choosing the option that best matches your use case.\\n\\n\\n\\nRecommended\\nFor machine learning applications\\npip install -U \\\"ray[data,train,tune,serve]\\\"\\n\\n# For reinforcement learning support, install RLlib instead.\\n# pip install -U \\\"ray[rllib]\\\"\\n\\n\\nFor general Python applications\\npip install -U \\\"ray[default]\\\"\\n\\n# If you don't want Ray Dashboard or Cluster Launcher, install Ray with minimal dependencies instead.\\n# pip install -U \\\"ray\\\"\\n\\n\\n\\n\\n\\nAdvanced\\n\\n\\n\\n\\n\\n\\nCommand\\nInstalled components\\n\\n\\n\\npip install -U \\\"ray\\\"\\nCore\\n\\npip install -U \\\"ray[default]\\\"\\nCore, Dashboard, Cluster Launcher\\n\\npip install -U \\\"ray[data]\\\"\\nCore, Data\\n\\npip install -U \\\"ray[train]\\\"\\nCore, Train\\n\\npip install -U \\\"ray[tune]\\\"\\nCore, Tune\\n\\npip install -U \\\"ray[serve]\\\"\\nCore, Dashboard, Cluster Launcher, Serve\\n\\npip install -U \\\"ray[serve-grpc]\\\"\\nCore, Dashboard, Cluster Launcher, Serve with gRPC support\\n\\npip install -U \\\"ray[rllib]\\\"\\nCore, Tune, RLlib\\n\\npip install -U \\\"ray[all]\\\"\\nCore, Dashboard, Cluster Launcher, Data, Train, Tune, Serve, RLlib. This option isn\\u2019t recommended. Specify the extras you need as shown below instead.\\n\\n\\n\\n\\nTip\\nYou can combine installation extras.\\nFor example, to install Ray with Dashboard, Cluster Launcher, and Train support, you can run:\\npip install -U \\\"ray[default,train]\\\"\\n\\n\\n\\n\\n\\n\\n\\n\\nDaily Releases (Nightlies)#\\nYou can install the nightly Ray wheels via the following links. These daily releases are tested via automated tests but do not go through the full release process. To install these wheels, use the following pip command and wheels:\\n# Clean removal of previous install\\npip uninstall -y ray\\n# Install Ray with support for the dashboard + cluster launcher\\npip install -U \\\"ray[default] @ LINK_TO_WHEEL.whl\\\"\\n\\n# Install Ray with minimal dependencies\\n# pip install -U LINK_TO_WHEEL.whl\\n\\n\\n\\n\\n\\nLinux\\n\\n\\nLinux (x86_64)\\nLinux (arm64/aarch64)\\n\\n\\n\\nLinux Python 3.9 (x86_64)\\nLinux Python 3.9 (aarch64)\\n\\nLinux Python 3.10 (x86_64)\\nLinux Python 3.10 (aarch64)\\n\\nLinux Python 3.11 (x86_64)\\nLinux Python 3.11 (aarch64)\\n\\nLinux Python 3.12 (x86_64)\\nLinux Python 3.12 (aarch64)\\n\\nLinux Python 3.13 (x86_64) (beta)\\nLinux Python 3.13 (aarch64) (beta)\\n\\n\\n\\n\\n\\n\\nMacOS\\n\\n\\nMacOS (x86_64)\\nMacOS (arm64)\\n\\n\\n\\nMacOS Python 3.9 (x86_64)\\nMacOS Python 3.9 (arm64)\\n\\nMacOS Python 3.10 (x86_64)\\nMacOS Python 3.10 (arm64)\\n\\nMacOS Python 3.11 (x86_64)\\nMacOS Python 3.11 (arm64)\\n\\nMacOS Python 3.12 (x86_64)\\nMacOS Python 3.12 (arm64)\\n\\nMacOS Python 3.13 (x86_64) (beta)\\nMacOS Python 3.13 (arm64) (beta)\\n\\n\\n\\n\\n\\n\\nWindows (beta)\\n\\n\\nWindows (beta)\\n\\n\\n\\nWindows Python 3.9\\n\\nWindows Python 3.10\\n\\nWindows Python 3.11\\n\\nWindows Python 3.12\\n\\n\\n\\n\\n\\n\\nNote\\nOn Windows, support for multi-node Ray clusters is currently experimental and untested.\\nIf you run into issues please file a report at ray-project/ray#issues.\\n\\n\\nNote\\nUsage stats collection is enabled by default (can be disabled) for nightly wheels including both local clusters started via ray.init() and remote clusters via cli.\\n\\n\\n\\nInstalling from a specific commit#\\nYou can install the Ray wheels of any particular commit on master with the following template. You need to specify the commit hash, Ray version, Operating System, and Python version:\\npip install https://s3-us-west-2.amazonaws.com/ray-wheels/master/{COMMIT_HASH}/ray-{RAY_VERSION}-{PYTHON_VERSION}-{PYTHON_VERSION}-{OS_VERSION}.whl\", \"Warning\\nDo not run pip uninstall ray or pip install -U (for Ray or Ray wheels) if setting up your environment this way. To uninstall or upgrade, you must first rm -rf the pip-installation site (usually a directory at the site-packages/ray location), then do a pip reinstall (see the command above), and finally run the above setup-dev.py script again.\\n\\n# To uninstall, delete the symlinks first.\\nrm -rf <package path>/site-packages/ray # Path will be in the output of `setup-dev.py`.\\npip uninstall ray # or `pip install -U <wheel>`\\n\\n\\n\\n\\nPreparing to build Ray on Linux#\\n\\nTip\\nIf you are only editing Tune/RLlib/Autoscaler files, follow instructions for Building Ray (Python Only) to avoid long build times.\\n\\nTo build Ray on Ubuntu, run the following commands:\\nsudo apt-get update\\nsudo apt-get install -y build-essential curl clang-12 pkg-config psmisc unzip\\n\\n# Install Bazelisk.\\nci/env/install-bazel.sh\\n\\n# Install node version manager and node 14\\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash\\nnvm install 14\\nnvm use 14\\n\\n\\n\\nNote\\nThe install-bazel.sh script installs bazelisk for building Ray.\\nNote that bazel is installed at $HOME/bin/bazel; make sure it\\u2019s on the executable PATH.\\nIf you prefer to use bazel, only version 6.5.0 is currently supported.\\n\\nFor RHELv8 (Redhat EL 8.0-64 Minimal), run the following commands:\\nsudo yum groupinstall 'Development Tools'\\nsudo yum install psmisc\\n\\n\\nIn RedHat, install Bazel manually from this link: https://docs.bazel.build/versions/main/install-redhat.html\\n\\n\\nPreparing to build Ray on MacOS#\\n\\nTip\\nAssuming you already have Brew and Bazel installed on your mac and you also have grpc and protobuf installed on your mac consider removing those (grpc and protobuf) for smooth build through the commands brew uninstall grpc, brew uninstall protobuf. If you have built the source code earlier and it still fails with errors like No such file or directory:, try cleaning previous builds on your host by running the commands brew uninstall binutils and bazel clean --expunge.\\n\\nTo build Ray on MacOS, first install these dependencies:\\nbrew update\\nbrew install wget\\n\\n# Install Bazel.\\nci/env/install-bazel.sh\\n\\n\\n\\n\\nBuilding Ray on Linux & MacOS (full)#\\nMake sure you have a local clone of Ray\\u2019s git repository as explained above. You will also need to install NodeJS to build the dashboard.\\nEnter into the project directory, for example:\\ncd ray\\n\\n\\nNow you can build the dashboard. From inside of your local Ray project directory enter into the dashboard client directory:\\ncd python/ray/dashboard/client\\n\\n\\nThen you can install the dependencies and build the dashboard:\\nnpm ci\\nnpm run build\\n\\n\\nAfter that, you can now move back to the top level Ray directory:\\ncd -\\n\\n\\nNow let\\u2019s build Ray for Python. Make sure you activate any Python virtual (or conda) environment you could be using as described above.\\nEnter into the python/ directory inside of the Ray project directory and install the project with pip:\\n# Install Ray.\\ncd python/\\n# Install required dependencies.\\npip install -r requirements.txt\\n# You may need to set the following two env vars if you have a macOS ARM64(M1) platform.\\n# See https://github.com/grpc/grpc/issues/25082 for more details.\\n# export GRPC_PYTHON_BUILD_SYSTEM_OPENSSL=1\\n# export GRPC_PYTHON_BUILD_SYSTEM_ZLIB=1\\npip install -e . --verbose  # Add --user if you see a permission denied error.\\n\\n\\nThe -e means \\u201ceditable\\u201d, so changes you make to files in the Ray\\ndirectory will take effect without reinstalling the package.\\n\\nWarning\\nif you run python setup.py install, files will be copied from the Ray directory to a directory of Python packages (/lib/python3.6/site-packages/ray). This means that changes you make to files in the Ray directory will not have any effect.\\n\\n\\nTip\\nIf your machine is running out of memory during the build or the build is causing other programs to crash, try adding the following line to ~/.bazelrc:\\nbuild --local_ram_resources=HOST_RAM*.5 --local_cpu_resources=4\\nThe build --disk_cache=~/bazel-cache option can be useful to speed up repeated builds too.\\n\\n\\nNote\\nWarning: If you run into an error building protobuf, switching from miniconda to anaconda might help.\", \"Installed Python dependencies#\\nOur docker images are shipped with pre-installed Python dependencies\\nrequired for Ray and its libraries.\\nWe publish the dependencies that are installed in our ray Docker images for Python 3.9.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInstall Ray Java with Maven#\\n\\nNote\\nAll Ray Java APIs are experimental and only supported by the community.\\n\\nBefore installing Ray Java with Maven, you should install Ray Python with pip install -U ray . Note that the versions of Ray Java and Ray Python must match.\\nNote that nightly Ray python wheels are also required if you want to install Ray Java snapshot version.\\nFind the latest Ray Java release in the central repository. To use the latest Ray Java release in your application, add the following entries in your pom.xml:\\n<dependency>\\n  <groupId>io.ray</groupId>\\n  <artifactId>ray-api</artifactId>\\n  <version>${ray.version}</version>\\n</dependency>\\n<dependency>\\n  <groupId>io.ray</groupId>\\n  <artifactId>ray-runtime</artifactId>\\n  <version>${ray.version}</version>\\n</dependency>\\n\\n\\nThe latest Ray Java snapshot can be found in sonatype repository. To use the latest Ray Java snapshot in your application, add the following entries in your pom.xml:\\n<!-- only needed for snapshot version of ray -->\\n<repositories>\\n  <repository>\\n    <id>sonatype</id>\\n    <url>https://oss.sonatype.org/content/repositories/snapshots/</url>\\n    <releases>\\n      <enabled>false</enabled>\\n    </releases>\\n    <snapshots>\\n      <enabled>true</enabled>\\n    </snapshots>\\n  </repository>\\n</repositories>\\n\\n<dependencies>\\n  <dependency>\\n    <groupId>io.ray</groupId>\\n    <artifactId>ray-api</artifactId>\\n    <version>${ray.version}</version>\\n  </dependency>\\n  <dependency>\\n    <groupId>io.ray</groupId>\\n    <artifactId>ray-runtime</artifactId>\\n    <version>${ray.version}</version>\\n  </dependency>\\n</dependencies>\\n\\n\\n\\nNote\\nWhen you run pip install to install Ray, Java jars are installed as well. The above dependencies are only used to build your Java code and to run your code in local mode.\\nIf you want to run your Java code in a multi-node Ray cluster, it\\u2019s better to exclude Ray jars when packaging your code to avoid jar conflicts if the versions (installed Ray with pip install and maven dependencies) don\\u2019t match.\\n\\n\\n\\nInstall Ray C++#\\n\\nNote\\nAll Ray C++ APIs are experimental and only supported by the community.\\n\\nYou can install and use Ray C++ API as follows.\\npip install -U ray[cpp]\\n\\n# Create a Ray C++ project template to start with.\\nray cpp --generate-bazel-project-template-to ray-template\\n\\n\\n\\nNote\\nIf you build Ray from source, remove the build option build --cxxopt=\\\"-D_GLIBCXX_USE_CXX11_ABI=0\\\" from the file cpp/example/.bazelrc before running your application. The related issue is this.\", \"A Gentle Introduction to Ray Core by Example#\\n\\n\\n\\nImplement a function in Ray Core to understand how Ray works and its basic concepts.\\nPython programmers from those with less experience to those who are interested in advanced tasks,\\ncan start working with distributed computing using Python by learning the Ray Core API.\\n\\nInstall Ray#\\nInstall Ray with the following command:\\n\\n\\n! pip install ray\\n\\n\\n\\n\\n\\n\\nRay Core#\\nStart a local cluster by running the following commands:\\n\\n\\nimport ray\\nray.init()\\n\\n\\n\\n\\nNote the following lines in the output:\\n... INFO services.py:1263 -- View the Ray dashboard at http://127.0.0.1:8265\\n{'node_ip_address': '192.168.1.41',\\n...\\n'node_id': '...'}\\n\\n\\nThese messages indicate that the Ray cluster is working as expected. In this example output, the address of the Ray dashboard is http://127.0.0.1:8265. Access the Ray dashboard at the address on the first line of your output. The Ray dashboard displays information such as the number of CPU cores available and the total utilization of the current Ray application.\\nThis is a typical output for a laptop:\\n{'CPU': 12.0,\\n'memory': 14203886388.0,\\n'node:127.0.0.1': 1.0,\\n'object_store_memory': 2147483648.0}\\n\\n\\nNext, is a brief introduction to the Ray Core API, which we refer to as the Ray API.\\nThe Ray API builds on concepts such as decorators, functions, and classes, that are familiar to Python programmers.\\nIt is a universal programming interface for distributed computing.\\nThe engine handles the complicated work, allowing developers to use Ray with existing Python libraries and systems.\\n\\n\\nYour First Ray API Example#\\nThe following function retrieves and processes\\ndata from a database. The dummy database is a plain Python list containing the\\nwords of the title of the \\u201cLearning Ray\\u201d book.\\nThe sleep function pauses for a certain amount of time to simulate the cost of accessing and processing data from the database.\\n\\n\\nimport time\\n\\ndatabase = [\\n    \\\"Learning\\\", \\\"Ray\\\",\\n    \\\"Flexible\\\", \\\"Distributed\\\", \\\"Python\\\", \\\"for\\\", \\\"Machine\\\", \\\"Learning\\\"\\n]\\n\\n\\ndef retrieve(item):\\n    time.sleep(item / 10.)\\n    return item, database[item]\\n\\n\\n\\n\\nIf the item with index 5 takes half a second (5 / 10.), an estimate of the total runtime to retrieve all eight items sequentially is (0+1+2+3+4+5+6+7)/10. = 2.8 seconds.\\nRun the following code to get the actual time:\\n\\n\\ndef print_runtime(input_data, start_time):\\n    print(f'Runtime: {time.time() - start_time:.2f} seconds, data:')\\n    print(*input_data, sep=\\\"\\\\n\\\")\\n\\n\\nstart = time.time()\\ndata = [retrieve(item) for item in range(8)]\\nprint_runtime(data, start)\\n\\n\\n\\n\\nRuntime: 2.82 seconds, data:\\n(0, 'Learning')\\n(1, 'Ray')\\n(2, 'Flexible')\\n(3, 'Distributed')\\n(4, 'Python')\\n(5, 'for')\\n(6, 'Machine')\\n(7, 'Learning')\\n\\n\\n\\n\\nThe total time to run the function is 2.82 seconds in this example, but time may be different for your computer.\\nNote that this basic Python version cannot run the function simultaneously.\\nYou may expect that Python list comprehensions are more efficient. The measured runtime of 2.8 seconds is actually the worst case scenario.\\nAlthough this program \\u201csleeps\\u201d for most of its runtime, it is slow because of the Global Interpreter Lock (GIL).\\n\\nRay Tasks#\\nThis task can benefit from parallelization. If it is perfectly distributed, the runtime should not take much longer than the slowest subtask,\\nthat is, 7/10. = 0.7 seconds.\\nTo extend this example to run in parallel on Ray, start by using the @ray.remote decorator:\\n\\n\\nimport ray \\n\\n\\n@ray.remote\\ndef retrieve_task(item):\\n    return retrieve(item)\\n\\n\\n\\n\\nWith the decorator, the function retrieve_task becomes a :ref:ray-remote-functions<Ray task>_.\\nA Ray task is a function that Ray executes on a different process from where\\nit was called, and possibly on a different machine.\\nRay is convenient to use because you can continue writing Python code,\\nwithout having to significantly change your approach or programming style.\\nUsing the :func:ray.remote()<@ray.remote> decorator on the retrieve function is the intended use of decorators,\\nand you did not modify the original code in this example.\\nTo retrieve database entries and measure performance, you do not need to make many changes to the code. Here\\u2019s an overview of the process:\"]]"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ROlb",
      "code_hash": "03945f1a9b92ef2023ced2c0ae71ebff",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "qnkX",
      "code_hash": "a4320779d1c31d06998a6e90f4b431aa",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Query: What is ray ?\n\nSemantically similar texts:\n\nText:\nSecurity# Ray is an easy-to-use framework to run arbitrary code across one or\nmore nodes in a Ray Cluster. Ray provides fault-tolerance, optimized scheduling,\ntask orchestration, and auto-scaling to run a given workload. To achieve\nperformant and distributed workloads, Ray components require intra-cluster\ncommunication. This communication includes central tenets like distributed\nmemory and node-heartbeats, as well as auxiliary functions like metrics and\nlogs. Ray leverages gRPC for a majority of this communication. Ray offers\nadditional services to improve the developer experience. These services include\nRay Dashboard (to allow for cluster introspection and debugging), Ray Jobs\n(hosted alongside the Dashboard, which services Ray Job submissions), and Ray\nClient (to allow for local, interactive development with a remote cluster).\nThese services provide complete access to the Ray Cluster and the underlying\ncompute resources.  Ray allows any clients to run arbitrary code. Be extremely\ncareful about what is allowed to access your Ray Cluster If you expose these\nservices (Ray Dashboard, Ray Jobs, Ray Client), anybody who can access the\nassociated ports can execute arbitrary code on your Ray Cluster. This can\nhappen:  Explicitly: By submitting a Ray Job, or using the Ray Client\nIndirectly: By calling the Dashboard REST APIs of these services Implicitly: Ray\nextensively uses cloudpickle for serialization of arbitrary python objects. See\nthe pickle documentation for more details on Pickle\u2019s security model.  The Ray\nDashboard, Ray Jobs and Ray Client are developer tools that you should only use\nwith the necessary access controls in place to restrict access to trusted\nparties only.   Personas# When considering the security responsibilities of\nrunning Ray, think about the different personas interacting with Ray.  Ray\nDevelopers write code that relies on Ray. They either run a single-node Ray\nCluster locally or multi-node Clusters remotely on provided compute\ninfrastructure. Platform providers provide the compute environment on which\nDevelopers run Ray. Users interact with the output of Ray-powered applications.\nBest practices# Security and isolation must be enforced outside of the Ray\nCluster. Ray expects to run in a safe network environment and to act upon\ntrusted code. Developers and platform providers must maintain the following\ninvariants to ensure the safe operation of Ray Clusters.  Deploy Ray Clusters in\na controlled network environment#  Network traffic between core Ray components\nand additional Ray components should always be in a controlled, isolated\nnetwork. Access to additional services should be gated with strict network\ncontrols and/or external authentication/authorization proxies. gRPC\ncommunication can be encrypted with TLS, but it\u2019s not a replacement for network\nisolation. Platform providers are responsible for ensuring that Ray runs in\nsufficiently controlled network environments and that developers can access\nfeatures like Ray Dashboard in a secure manner.    Only execute trusted code\nwithin Ray#  Ray faithfully executes code that is passed to it \u2013 Ray doesn\u2019t\ndifferentiate between a tuning experiment, a rootkit install, or an S3 bucket\ninspection. Ray developers are responsible for building their applications with\nthis understanding in mind.    Enforce isolation outside of Ray with multiple\nRay Clusters#  If workloads require isolation from each other, use separate,\nisolated Ray Clusters. Ray can schedule multiple distinct Jobs in a single\nCluster, but doesn\u2019t attempt to enforce isolation between them. Similarly, Ray\ndoesn\u2019t implement access controls for developers interacting with a given\ncluster. Ray developers are responsible for determining which applications need\nto be separated and platform providers are responsible for providing this\nisolation.\n\n\nText:\nRay Client#  Warning Ray Client requires pip package ray[client]. If you\ninstalled the minimal Ray (e.g. pip install ray), please reinstall by executing\npip install ray[client].  What is the Ray Client? The Ray Client is an API that\nconnects a Python script to a remote Ray cluster. Effectively, it allows you to\nleverage a remote Ray cluster just like you would with Ray running on your local\nmachine. By changing ray.init() to ray.init(\"ray://<head_node_host>:<port>\"),\nyou can connect from your laptop (or anywhere) directly to a remote cluster and\nscale-out your Ray code, while maintaining the ability to develop interactively\nin a Python shell. This will only work with Ray 1.5+. # You can run this code\noutside of the Ray cluster! import ray  # Starting the Ray client. This connects\nto a remote Ray cluster. ray.init(\"ray://<head_node_host>:10001\")  # Normal Ray\ncode follows @ray.remote def do_work(x):     return x ** x  do_work.remote(2)\n#....    When to use Ray Client#  Note Ray Client has architectural limitations\nand may not work as expected when using Ray for ML workloads (like Ray Tune or\nRay Train). Use Ray Jobs API for interactive development on ML projects.  Ray\nClient can be used when you want to connect an interactive Python shell to a\nremote cluster.  Use ray.init(\"ray://<head_node_host>:10001\") (Ray Client) if\nyou\u2019ve set up a remote cluster at <head_node_host> and you want to do\ninteractive work. This will connect your shell to the cluster. See the section\non using Ray Client for more details on setting up your cluster. Use ray.init()\n(non-client connection, no address specified) if you\u2019re developing locally and\nwant to connect to an existing cluster (i.e. ray start --head has already been\nrun), or automatically create a local cluster and attach directly to it. This\ncan also be used for Ray Job submission.  Ray Client is useful for developing\ninteractively in a local Python shell. However, it requires a stable connection\nto the remote cluster and will terminate the workload if the connection is lost\nfor more than 30 seconds. If you have a long running workload that you want to\nrun on your cluster, we recommend using Ray Jobs instead.   Client arguments#\nRay Client is used when the address passed into ray.init is prefixed with\nray://. Besides the address, Client mode currently accepts two other arguments:\nnamespace (optional): Sets the namespace for the session. runtime_env\n(optional): Sets the runtime environment for the session, allowing you to\ndynamically specify environment variables, packages, local files, and more.  #\nConnects to an existing cluster at 1.2.3.4 listening on port 10001, using # the\nnamespace \"my_namespace\". The Ray workers will run inside a cluster-side # copy\nof the local directory \"files/my_project\", in a Python environment with #\n`toolz` and `requests` installed. ray.init(     \"ray://1.2.3.4:10001\",\nnamespace=\"my_namespace\",     runtime_env={\"working_dir\": \"files/my_project\",\n\"pip\": [\"toolz\", \"requests\"]}, ) #....     How do you use the Ray Client?#  Step\n1: Set up your Ray cluster# If you have a running Ray cluster (version >= 1.5),\nRay Client server is likely already running on port 10001 of the head node by\ndefault. Otherwise, you\u2019ll want to create a Ray cluster. To start a Ray cluster\nlocally, you can run ray start --head   To start a Ray cluster remotely, you can\nfollow the directions in Getting Started. If necessary, you can modify the Ray\nClient server port to be other than 10001, by specifying --ray-client-server-\nport=... to the ray start command.   Step 2: Configure Access# Ensure that your\nlocal machine can access the Ray Client port on the head node. The easiest way\nto accomplish this is to use SSH port forwarding or K8s port-forwarding. This\nallows you to connect to the Ray Client server on the head node via localhost.\nFirst, open up an SSH connection with your Ray cluster and forward the listening\nport (10001). For Clusters launched with the Ray Cluster launcher this looks\nlike: $ ray up cluster.yaml $ ray attach cluster.yaml -p 10001   Then connect to\nthe Ray cluster from another terminal using  localhost as the head_node_host.\nimport ray  # This will connect to the cluster via the open SSH session.\nray.init(\"ray://localhost:10001\")  # Normal Ray code follows @ray.remote def\ndo_work(x):     return x ** x\n\n\nText:\nWhat\u2019s Ray Core?#   Ray Core is a powerful distributed computing framework that\nprovides a small set of essential primitives (tasks, actors, and objects) for\nbuilding and scaling distributed applications. This walk-through introduces you\nto these core concepts with simple examples that demonstrate how to transform\nyour Python functions and classes into distributed Ray tasks and actors, and how\nto work effectively with Ray objects.  Note Ray has introduced an experimental\nAPI for high-performance workloads that\u2019s especially well suited for\napplications using multiple GPUs. See Ray Compiled Graph for more details.\nGetting Started# To get started, install Ray using pip install -U ray. For\nadditional installation options, see Installing Ray. The first step is to import\nand initialize Ray: import ray  ray.init()    Note In recent versions of Ray\n(>=1.5), ray.init() is automatically called on the first use of a Ray remote\nAPI.    Running a Task# Tasks are the simplest way to parallelize your Python\nfunctions across a Ray cluster. To create a task:  Decorate your function with\n@ray.remote to indicate it should run remotely Call the function with .remote()\ninstead of a normal function call Use ray.get() to retrieve the result from the\nreturned future (Ray object reference)  Here\u2019s a simple example: # Define the\nsquare task. @ray.remote def square(x):     return x * x  # Launch four parallel\nsquare tasks. futures = [square.remote(i) for i in range(4)]  # Retrieve\nresults. print(ray.get(futures)) # -> [0, 1, 4, 9]     Calling an Actor# While\ntasks are stateless, Ray actors allow you to create stateful workers that\nmaintain their internal state between method calls. When you instantiate a Ray\nactor:  Ray starts a dedicated worker process somewhere in your cluster The\nactor\u2019s methods run on that specific worker and can access and modify its state\nThe actor executes method calls serially in the order it receives them,\npreserving consistency  Here\u2019s a simple Counter example: # Define the Counter\nactor. @ray.remote class Counter:     def __init__(self):         self.i = 0\ndef get(self):         return self.i      def incr(self, value):         self.i\n+= value  # Create a Counter actor. c = Counter.remote()  # Submit calls to the\nactor. These calls run asynchronously but in # submission order on the remote\nactor process. for _ in range(10):     c.incr.remote(1)  # Retrieve final actor\nstate. print(ray.get(c.get.remote())) # -> 10   The preceding example\ndemonstrates basic actor usage. For a more comprehensive example that combines\nboth tasks and actors, see the Monte Carlo Pi estimation example.   Passing\nObjects# Ray\u2019s distributed object store efficiently manages data across your\ncluster. There are three main ways to work with objects in Ray:  Implicit\ncreation: When tasks and actors return values, they are automatically stored in\nRay\u2019s distributed object store, returning object references that can be later\nretrieved. Explicit creation: Use ray.put() to directly place objects in the\nstore. Passing references: You can pass object references to other tasks and\nactors, avoiding unnecessary data copying and enabling lazy execution.  Here\u2019s\nan example showing these techniques: import numpy as np  # Define a task that\nsums the values in a matrix. @ray.remote def sum_matrix(matrix):     return\nnp.sum(matrix)  # Call the task with a literal argument value.\nprint(ray.get(sum_matrix.remote(np.ones((100, 100))))) # -> 10000.0  # Put a\nlarge array into the object store. matrix_ref = ray.put(np.ones((1000, 1000)))\n# Call the task with the object reference as an argument.\nprint(ray.get(sum_matrix.remote(matrix_ref))) # -> 1000000.0     Next Steps#\nTip To monitor your application\u2019s performance and resource usage, check out the\nRay dashboard.  You can combine Ray\u2019s simple primitives in powerful ways to\nexpress virtually any distributed computation pattern. To dive deeper into Ray\u2019s\nkey concepts, explore these user guides:       Using remote functions (Tasks)\nUsing remote classes (Actors)        Working with Ray Objects\n\n\nText:\nOverview# Ray is an open-source unified framework for scaling AI and Python\napplications like machine learning. It provides the compute layer for parallel\nprocessing so that you don\u2019t need to be a distributed systems expert. Ray\nminimizes the complexity of running your distributed individual and end-to-end\nmachine learning workflows with these components:  Scalable libraries for common\nmachine learning tasks such as data preprocessing, distributed training,\nhyperparameter tuning, reinforcement learning, and model serving. Pythonic\ndistributed computing primitives for parallelizing and scaling Python\napplications. Integrations and utilities for integrating and deploying a Ray\ncluster with existing tools and infrastructure such as Kubernetes, AWS, GCP, and\nAzure.  For data scientists and machine learning practitioners, Ray lets you\nscale jobs without needing infrastructure expertise:  Easily parallelize and\ndistribute ML workloads across multiple nodes and GPUs. Leverage the ML\necosystem with native and extensible integrations.  For ML platform builders and\nML engineers, Ray:  Provides compute abstractions for creating a scalable and\nrobust ML platform. Provides a unified ML API that simplifies onboarding and\nintegration with the broader ML ecosystem. Reduces friction between development\nand production by enabling the same Python code to scale seamlessly from a\nlaptop to a large cluster.  For distributed systems engineers, Ray automatically\nhandles key processes:  Orchestration\u2013Managing the various components of a\ndistributed system. Scheduling\u2013Coordinating when and where tasks are executed.\nFault tolerance\u2013Ensuring tasks complete regardless of inevitable points of\nfailure. Auto-scaling\u2013Adjusting the number of resources allocated to dynamic\ndemand.   What you can do with Ray# These are some common ML workloads that\nindividuals, organizations, and companies leverage Ray to build their AI\napplications:  Batch inference on CPUs and GPUs Model serving Distributed\ntraining of large models Parallel hyperparameter tuning experiments\nReinforcement learning ML platform    Ray framework#       Stack of Ray\nlibraries - unified toolkit for ML workloads.    Ray\u2019s unified compute framework\nconsists of three layers:  Ray AI Libraries\u2013An open-source, Python, domain-\nspecific set of libraries that equip ML engineers, data scientists, and\nresearchers with a scalable and unified toolkit for ML applications. Ray Core\u2013An\nopen-source, Python, general purpose, distributed computing library that enables\nML engineers and Python developers to scale Python applications and accelerate\nmachine learning workloads. Ray Clusters\u2013A set of worker nodes connected to a\ncommon Ray head node. Ray clusters can be fixed-size, or they can autoscale up\nand down according to the resources requested by applications running on the\ncluster.       Scale machine learning workloads   Build ML applications with a\ntoolkit of libraries for distributed data processing, model training, tuning,\nreinforcement learning, model serving, and more.   Ray AI Libraries       Build\ndistributed applications   Build and run distributed applications with a simple\nand flexible API. Parallelize single machine code with little to zero code\nchanges.   Ray Core       Deploy large-scale workloads   Deploy workloads on\nAWS, GCP, Azure or on premise. Use Ray cluster managers to run Ray on existing\nKubernetes, YARN, or Slurm clusters.   Ray Clusters      Each of Ray\u2019s five\nnative libraries distributes a specific ML task:  Data: Scalable, framework-\nagnostic data loading and transformation across training, tuning, and\nprediction. Train: Distributed multi-node and multi-core model training with\nfault tolerance that integrates with popular training libraries. Tune: Scalable\nhyperparameter tuning to optimize model performance. Serve: Scalable and\nprogrammable serving to deploy models for online inference, with optional\nmicrobatching to improve performance. RLlib: Scalable distributed reinforcement\nlearning workloads.  Ray\u2019s libraries are for both data scientists and ML\nengineers alike. For data scientists, these libraries can be used to scale\nindividual workloads, and also end-to-end ML applications. For ML Engineers,\nthese libraries provides scalable platform abstractions that can be used to\neasily onboard and integrate tooling from the broader ML ecosystem. For custom\napplications, the Ray Core library enables Python developers to easily build\nscalable, distributed systems that can run on a laptop, cluster, cloud, or\nKubernetes. It\u2019s the foundation that Ray AI libraries and third-party\nintegrations (Ray ecosystem) are built on. Ray runs on any machine, cluster,\ncloud provider, and Kubernetes, and features a growing ecosystem of community\nintegrations.\n\n\nText:\nGetting Started# Ray is an open source unified framework for scaling AI and\nPython applications. It provides a simple, universal API for building\ndistributed applications that can scale from a laptop to a cluster.  What\u2019s\nRay?# Ray simplifies distributed computing by providing:  Scalable compute\nprimitives: Tasks and actors for painless parallel programming Specialized AI\nlibraries: Tools for common ML workloads like data processing, model training,\nhyperparameter tuning, and model serving Unified resource management: Seamless\nscaling from laptop to cloud with automatic resource handling    Choose Your\nPath# Select the guide that matches your needs:  Scale ML workloads: Ray\nLibraries Quickstart Scale general Python applications: Ray Core Quickstart\nDeploy to the cloud: Ray Clusters Quickstart Debug and monitor applications:\nDebugging and Monitoring Quickstart    Ray AI Libraries Quickstart# Use\nindividual libraries for ML workloads. Each library specializes in a specific\npart of the ML workflow, from data processing to model serving. Click on the\ndropdowns for your workload below.    Data: Scalable Datasets for ML     Ray\nData provides distributed data processing optimized for machine learning and AI\nworkloads. It efficiently streams data through data pipelines. Here\u2019s an example\non how to scale offline inference and training ingest with Ray Data.  Note To\nrun this example, install Ray Data: pip install -U \"ray[data]\"    from typing\nimport Dict import numpy as np import ray  # Create datasets from on-disk files,\nPython objects, and cloud storage like S3. ds =\nray.data.read_csv(\"s3://anonymous@ray-example-data/iris.csv\")  # Apply functions\nto transform data. Ray Data executes transformations in parallel. def\ncompute_area(batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:     length\n= batch[\"petal length (cm)\"]     width = batch[\"petal width (cm)\"]\nbatch[\"petal area (cm^2)\"] = length * width     return batch  transformed_ds =\nds.map_batches(compute_area)  # Iterate over batches of data. for batch in\ntransformed_ds.iter_batches(batch_size=4):     print(batch)  # Save dataset\ncontents to on-disk files or cloud storage.\ntransformed_ds.write_parquet(\"local:///tmp/iris/\")   Learn more about Ray Data\nTrain: Distributed Model Training     Ray Train makes distributed model training\nsimple. It abstracts away the complexity of setting up distributed training\nacross popular frameworks like PyTorch and TensorFlow.    PyTorch This example\nshows how you can use Ray Train with PyTorch. To run this example install Ray\nTrain and PyTorch packages:  Note pip install -U \"ray[train]\" torch torchvision\nSet up your dataset and model. import torch import torch.nn as nn from\ntorch.utils.data import DataLoader from torchvision import datasets from\ntorchvision.transforms import ToTensor  def get_dataset():     return\ndatasets.FashionMNIST(         root=\"/tmp/data\",         train=True,\ndownload=True,         transform=ToTensor(),     )  class\nNeuralNetwork(nn.Module):     def __init__(self):         super().__init__()\nself.flatten = nn.Flatten()         self.linear_relu_stack = nn.Sequential(\nnn.Linear(28 * 28, 512),             nn.ReLU(),             nn.Linear(512, 512),\nnn.ReLU(),             nn.Linear(512, 10),         )      def forward(self,\ninputs):         inputs = self.flatten(inputs)         logits =\nself.linear_relu_stack(inputs)         return logits   Now define your single-\nworker PyTorch training function. def train_func():     num_epochs = 3\nbatch_size = 64      dataset = get_dataset()     dataloader =\nDataLoader(dataset, batch_size=batch_size)      model = NeuralNetwork()\ncriterion = nn.CrossEntropyLoss()     optimizer =\ntorch.optim.SGD(model.parameters(), lr=0.01)      for epoch in\nrange(num_epochs):         for inputs, labels in dataloader:\noptimizer.zero_grad()             pred = model(inputs)             loss =\ncriterion(pred, labels)             loss.backward()             optimizer.step()\nprint(f\"epoch: {epoch}, loss: {loss.item()}\")   This training function can be\nexecuted with: train_func()   Convert this to a distributed multi-worker\ntraining function. Use the ray.train.torch.prepare_model and\nray.train.torch.prepare_data_loader utility functions to set up your model and\ndata for distributed training. This automatically wraps the model with\nDistributedDataParallel and places it on the right device, and adds\nDistributedSampler to the DataLoaders. import ray.train.torch  def\ntrain_func_distributed():     num_epochs = 3     batch_size = 64\n\n\n"
        }
      ]
    },
    {
      "id": "TqIu",
      "code_hash": "c8c31d8bbb63cbeb39c757a28f0d4887",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"llm-for-local-generation\">LLM for local generation</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Npga",
      "code_hash": "b7601a583b3b6ba22c519cb4a2e259e4",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Available GPU memory: 6 GB\n"
        }
      ]
    },
    {
      "id": "skeG",
      "code_hash": "0997d8cf445d0254c476e4bf95b29d4f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"checking-local-gpu-memory-availability\">Checking local GPU memory availability</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "XPsO",
      "code_hash": "d5534e4362ad954c5edf236da218460d",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"adaptive-quantization-configuration-based-on-current-hardware\">Adaptive quantization configuration based on current hardware</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "zwXI",
      "code_hash": "7382fd3672147dd91376801853e3dfab",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "GPU memory: 6 | Recommended model: LLaMA 2 7B or LLaMA 3 8B in 4-bit quantization.\nuse_quantization_config set to: True\nmodel_id set to: meta-llama/Llama-2-7b-chat-hf\n"
        }
      ]
    },
    {
      "id": "HLVH",
      "code_hash": "8205a08299c64cfeb1fedb338714e5a9",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"loading-an-llm-locally\">Loading an LLM locally</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "nmxE",
      "code_hash": "b745e58a9d56c42f76578418b921a3fb",
      "outputs": [
        {
          "type": "error",
          "ename": "interruption",
          "evalue": "This cell was interrupted and needs to be re-run",
          "traceback": []
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "[INFO] Using attention implementation: sdpa\n[INFO] Using model_id: meta-llama/Llama-2-7b-chat-hf\n[INFO] Using quantization config?: YES\n"
        },
        {
          "type": "stream",
          "name": "stderr",
          "text": "\rFetching 2 files:   0%|                             | 0/2 [00:00<?, ?it/s]"
        },
        {
          "type": "stream",
          "name": "stderr",
          "text": "Cancellation requested; stopping current tasks.\n"
        },
        {
          "type": "stream",
          "name": "stderr",
          "text": "\rFetching 2 files:   0%|                             | 0/2 [00:24<?, ?it/s]\n"
        },
        {
          "type": "stream",
          "name": "stderr",
          "text": "<span class=\"codehilite\"><div class=\"highlight\"><pre><span></span><span class=\"gt\">Traceback (most recent call last):</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/marimo/_runtime/executor.py&quot;</span>, line <span class=\"m\">138</span>, in <span class=\"n\">execute_cell</span>\n<span class=\"w\">    </span><span class=\"n\">exec</span><span class=\"p\">(</span><span class=\"n\">cell</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">,</span> <span class=\"n\">glbls</span><span class=\"p\">)</span>\n  File <span class=\"nb\">&quot;/tmp/marimo_8540/__marimo__cell_nmxE_.py&quot;</span>, line <span class=\"m\">23</span>, in <span class=\"n\">&lt;module&gt;</span>\n<span class=\"w\">    </span><span class=\"n\">llm_model</span> <span class=\"o\">=</span> <span class=\"n\">AutoModelForCausalLM</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span>\n<span class=\"w\">                </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py&quot;</span>, line <span class=\"m\">571</span>, in <span class=\"n\">from_pretrained</span>\n<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">model_class</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span>\n<span class=\"w\">           </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py&quot;</span>, line <span class=\"m\">279</span>, in <span class=\"n\">_wrapper</span>\n<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">func</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n<span class=\"w\">           </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py&quot;</span>, line <span class=\"m\">4260</span>, in <span class=\"n\">from_pretrained</span>\n<span class=\"w\">    </span><span class=\"n\">checkpoint_files</span><span class=\"p\">,</span> <span class=\"n\">sharded_metadata</span> <span class=\"o\">=</span> <span class=\"n\">_get_resolved_checkpoint_files</span><span class=\"p\">(</span>\n<span class=\"w\">                                         </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py&quot;</span>, line <span class=\"m\">1152</span>, in <span class=\"n\">_get_resolved_checkpoint_files</span>\n<span class=\"w\">    </span><span class=\"n\">checkpoint_files</span><span class=\"p\">,</span> <span class=\"n\">sharded_metadata</span> <span class=\"o\">=</span> <span class=\"n\">get_checkpoint_shard_files</span><span class=\"p\">(</span>\n<span class=\"w\">                                         </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/transformers/utils/hub.py&quot;</span>, line <span class=\"m\">1115</span>, in <span class=\"n\">get_checkpoint_shard_files</span>\n<span class=\"w\">    </span><span class=\"n\">cached_filenames</span> <span class=\"o\">=</span> <span class=\"n\">cached_files</span><span class=\"p\">(</span>\n<span class=\"w\">                       </span><span class=\"pm\">^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/transformers/utils/hub.py&quot;</span>, line <span class=\"m\">439</span>, in <span class=\"n\">cached_files</span>\n<span class=\"w\">    </span><span class=\"n\">snapshot_download</span><span class=\"p\">(</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py&quot;</span>, line <span class=\"m\">114</span>, in <span class=\"n\">_inner_fn</span>\n<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">fn</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n<span class=\"w\">           </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/huggingface_hub/_snapshot_download.py&quot;</span>, line <span class=\"m\">297</span>, in <span class=\"n\">snapshot_download</span>\n<span class=\"w\">    </span><span class=\"n\">thread_map</span><span class=\"p\">(</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/tqdm/contrib/concurrent.py&quot;</span>, line <span class=\"m\">69</span>, in <span class=\"n\">thread_map</span>\n<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">_executor_map</span><span class=\"p\">(</span><span class=\"n\">ThreadPoolExecutor</span><span class=\"p\">,</span> <span class=\"n\">fn</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">iterables</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">tqdm_kwargs</span><span class=\"p\">)</span>\n<span class=\"w\">           </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/tqdm/contrib/concurrent.py&quot;</span>, line <span class=\"m\">51</span>, in <span class=\"n\">_executor_map</span>\n<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">tqdm_class</span><span class=\"p\">(</span><span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"n\">fn</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">iterables</span><span class=\"p\">,</span> <span class=\"n\">chunksize</span><span class=\"o\">=</span><span class=\"n\">chunksize</span><span class=\"p\">),</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">))</span>\n<span class=\"w\">           </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/tqdm/std.py&quot;</span>, line <span class=\"m\">1181</span>, in <span class=\"n\">__iter__</span>\n<span class=\"w\">    </span><span class=\"k\">for</span> <span class=\"n\">obj</span> <span class=\"ow\">in</span> <span class=\"n\">iterable</span><span class=\"p\">:</span>\n  File <span class=\"nb\">&quot;/home/saladass/.local/share/uv/python/cpython-3.11.5-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py&quot;</span>, line <span class=\"m\">619</span>, in <span class=\"n\">result_iterator</span>\n<span class=\"w\">    </span><span class=\"k\">yield</span> <span class=\"n\">_result_or_cancel</span><span class=\"p\">(</span><span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">())</span>\n<span class=\"w\">          </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/.local/share/uv/python/cpython-3.11.5-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py&quot;</span>, line <span class=\"m\">317</span>, in <span class=\"n\">_result_or_cancel</span>\n<span class=\"w\">    </span><span class=\"k\">return</span> <span class=\"n\">fut</span><span class=\"o\">.</span><span class=\"n\">result</span><span class=\"p\">(</span><span class=\"n\">timeout</span><span class=\"p\">)</span>\n<span class=\"w\">           </span><span class=\"pm\">^^^^^^^^^^^^^^^^^^^</span>\n  File <span class=\"nb\">&quot;/home/saladass/.local/share/uv/python/cpython-3.11.5-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py&quot;</span>, line <span class=\"m\">451</span>, in <span class=\"n\">result</span>\n<span class=\"w\">    </span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_condition</span><span class=\"o\">.</span><span class=\"n\">wait</span><span class=\"p\">(</span><span class=\"n\">timeout</span><span class=\"p\">)</span>\n  File <span class=\"nb\">&quot;/home/saladass/.local/share/uv/python/cpython-3.11.5-linux-x86_64-gnu/lib/python3.11/threading.py&quot;</span>, line <span class=\"m\">320</span>, in <span class=\"n\">wait</span>\n<span class=\"w\">    </span><span class=\"n\">waiter</span><span class=\"o\">.</span><span class=\"n\">acquire</span><span class=\"p\">()</span>\n  File <span class=\"nb\">&quot;/home/saladass/crafts/rag-int14124-final/.venv/lib/python3.11/site-packages/marimo/_runtime/handlers.py&quot;</span>, line <span class=\"m\">32</span>, in <span class=\"n\">interrupt_handler</span>\n<span class=\"w\">    </span><span class=\"k\">raise</span> <span class=\"n\">MarimoInterrupt</span>\n<span class=\"gr\">KeyboardInterrupt</span>\n</pre></div>\n</span>"
        }
      ]
    },
    {
      "id": "qSuF",
      "code_hash": "da9784ffb449e84df163f61a6e43db57",
      "outputs": [
        {
          "type": "error",
          "ename": "exception",
          "evalue": "An ancestor raised an exception (KeyboardInterrupt): ",
          "traceback": []
        }
      ],
      "console": []
    },
    {
      "id": "ejXV",
      "code_hash": "3e2e46805b97f0ddbfca99e4bc844d57",
      "outputs": [
        {
          "type": "error",
          "ename": "exception",
          "evalue": "An ancestor raised an exception (KeyboardInterrupt): ",
          "traceback": []
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Query: Do Ray clusters support multi-tenancy\n\n"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "<s>[INST] <<SYS>>\nBased on the following context items, please answer the query.\nMake sure your answers are as explanatory as possible.\nIf you don't know the answer just return <NONE>, don't make things up\n<</SYS>>\n\nNow use the following context items to answer the user query:\n- FAQ#\nThese are some Frequently Asked Questions for Ray clusters.\nIf you still have questions after reading this FAQ, reach out on the\nRay Discourse forum.\n\nDo Ray clusters support multi-tenancy?#\nYes, you can run multiple jobs from different users simultaneously in a Ray cluster\nbut it\u2019s not recommended in production.\nSome Ray features are still missing for multi-tenancy in production:\n\nRay doesn\u2019t provide strong resource isolation:\nRay resources are logical and they don\u2019t limit the physical resources a task or actor can use while running.\nThis means simultaneous jobs can interfere with each other and makes them less reliable to run in production.\nRay doesn\u2019t support priorities: All jobs, tasks and actors have the same priority so there is no way to prioritize important jobs under load.\nRay doesn\u2019t support access control: Jobs have full access to a Ray cluster and all of the resources within it.\n\nOn the other hand, you can run the same job multiple times using the same cluster to save the cluster startup time.\n\nNote\nA Ray namespace is just a logical grouping of jobs and named actors. Unlike a Kubernetes namespace, it doesn\u2019t provide any other multi-tenancy functions like resource quotas.\n\n\n\nI have multiple Ray users. What\u2019s the right way to deploy Ray for them?#\nStart a Ray cluster for each user to isolate their workloads.\n\n\nWhat\u2019s the difference between --node-ip-address and --address?#\nWhen starting a head node on a machine with more than one network address, you\nmay need to specify the externally available address so worker nodes can\nconnect. Use this command:\nray start --head --node-ip-address xx.xx.xx.xx --port nnnn``\n\n\nThen when starting the worker node, use this command to connect to the head node:\nray start --address xx.xx.xx.xx:nnnn\n\n\n\n\nWhat does a worker node failure to connect look like?#\nIf the worker node can\u2019t connect to the head node, you should see this error:\n\nUnable to connect to GCS at xx.xx.xx.xx:nnnn. Check that (1) Ray GCS with\nmatching version started successfully at the specified address, and (2)\nthere is no firewall setting preventing access.\n\nThe most likely cause is that the worker node can\u2019t access the IP address\ngiven. You can use ip route get xx.xx.xx.xx on the worker node to start\ndebugging routing issues.\nYou may also see failures in the log like:\n\nThis node has an IP address of xx.xx.xx.xx, while we can not found the\nmatched Raylet address. This maybe come from when you connect the Ray\ncluster with a different IP address or connect a container.\n\nThe cause of this error may be the head node overloading with too many simultaneous\nconnections. The solution for this problem is to start the worker nodes more slowly.\n\n\nProblems getting a SLURM cluster to work#\nA class of issues exist with starting Ray on SLURM clusters. While the exact causes aren\u2019t understood, (as of June 2023), some Ray\nimprovements mitigate some of the resource contention. Some of the issues\nreported are as follows:\n\nUsing a machine with a large number of CPUs, and starting one worker per CPU\ntogether with OpenBLAS (as used in NumPy) may allocate too many threads. This\nissue is a known OpenBLAS limitation. You can mitigate it by limiting OpenBLAS\nto one thread per process as explained in the link.\nResource allocation isn\u2019t as expected: usually the configuration has too many CPUs allocated per node. The best practice is to verify the SLURM configuration without\nstarting Ray to verify that the allocations are as expected. For more\ndetailed information see Deploying on Slurm.\n\n\n\nWhere does my Ray Job entrypoint script run? On the head node or worker nodes?#\nBy default, jobs submitted using the Ray Job API run\ntheir entrypoint script on the head node. You can change this by specifying\nany of the options --entrypoint-num-cpus, --entrypoint-num-gpus,\n--entrypoint-resources or --entrypoint-memory to ray job submit, or the\ncorresponding arguments if using the Python SDK. If these are specified, the\njob entrypoint will be scheduled on a node that has the requested resources\navailable.\n- Ray Clusters Overview#\n\n\nRay enables seamless scaling of workloads from a laptop to a large cluster. While Ray\nworks out of the box on single machines with just a call to ray.init, to run Ray\napplications on multiple nodes you must first deploy a Ray cluster.\nA Ray cluster is a set of worker nodes connected to a common Ray head node.\nRay clusters can be fixed-size, or they may autoscale up and down according\nto the resources requested by applications running on the cluster.\n\nWhere can I deploy Ray clusters?#\nRay provides native cluster deployment support on the following technology stacks:\n\nOn AWS and GCP. Community-supported Azure, Aliyun and vSphere integrations also exist.\nOn Kubernetes, via the officially supported KubeRay project.\nOn Anyscale, a fully managed Ray platform by the creators of Ray. You can either bring an existing AWS, GCP, Azure and Kubernetes clusters, or use the Anyscale hosted compute layer.\n\nAdvanced users may want to deploy Ray manually\nor onto platforms not listed here.\n\nNote\nMulti-node Ray clusters are only supported on Linux. At your own risk, you\nmay deploy Windows and OSX clusters by setting the environment variable\nRAY_ENABLE_WINDOWS_OR_OSX_CLUSTER=1 during deployment.\n\n\n\nWhat\u2019s next?#\n\n\n\n\n\nI want to learn key Ray cluster concepts\n\n\nUnderstand the key concepts and main ways of interacting with a Ray cluster.\n\n\nLearn Key Concepts\n\n\n\n\n\n\nI want to run Ray on Kubernetes\n\n\nDeploy a Ray application to a Kubernetes cluster. You can run the tutorial on a\nKubernetes cluster or on your laptop via Kind.\n\n\nGet Started with Ray on Kubernetes\n\n\n\n\n\n\nI want to run Ray on a cloud provider\n\n\nTake a sample application designed to run on a laptop and scale it up in the\ncloud. Access to an AWS or GCP account is required.\n\n\nGet Started with Ray on VMs\n\n\n\n\n\n\nI want to run my application on an existing Ray cluster\n\n\nGuide to submitting applications as Jobs to existing Ray clusters.\n\n\nJob Submission\n- Ray on Cloud VMs#\n\n\n\nOverview#\nIn this section we cover how to launch Ray clusters on Cloud VMs. Ray ships with built-in support\nfor launching AWS and GCP clusters, and also has community-maintained integrations for Azure, Aliyun and vSphere.\nEach Ray cluster consists of a head node and a collection of worker nodes. Optional\nautoscaling support allows the Ray cluster to be sized according to the\nrequirements of your Ray workload, adding and removing worker nodes as needed. Ray supports\nclusters composed of multiple heterogeneous compute nodes (including GPU nodes).\nConcretely, you will learn how to:\n\nSet up and configure Ray in public clouds\nDeploy applications and monitor your cluster\n\n\n\nLearn More#\nThe Ray docs present all the information you need to start running Ray workloads on VMs.\n\n\n\n\n\nGetting Started\n\n\nLearn how to start a Ray cluster and deploy Ray applications in the cloud.\n\n\nGet Started with Ray on Cloud VMs\n\n\n\n\n\n\nExamples\n\n\nTry example Ray workloads in the Cloud\n\n\nTry example workloads\n\n\n\n\n\n\nUser Guides\n\n\nLearn best practices for configuring cloud clusters\n\n\nRead the User Guides\n\n\n\n\n\n\nAPI Reference\n\n\nFind API references for cloud clusters\n\n\nCheck API references\n- Community Supported Cluster Managers#\n\n\n\nNote\nIf you\u2019re using AWS, Azure, GCP or vSphere you can use the Ray cluster launcher to simplify the cluster setup process.\n\nThe following is a list of community supported cluster managers.\n\n\nDeploying on YARN\nSkein Configuration\nPackaging Dependencies\nRay Setup in YARN\nRunning a Job\nCleaning Up\nQuestions or Issues?\n\n\nDeploying on Slurm\nWalkthrough using Ray with SLURM\nPython-interface SLURM scripts\nExamples and templates\n\n\nDeploying on LSF\nDeploying on Spark Standalone cluster\nRunning a basic example\nCreating a long running ray cluster on spark cluster\nRay on Spark APIs\n\n\n\n\n\n\nUsing a custom cloud or cluster manager#\nThe Ray cluster launcher currently supports AWS, Azure, GCP, Aliyun, vSphere and KubeRay out of the box. To use the Ray cluster launcher and Autoscaler on other cloud providers or cluster managers, you can implement the node_provider.py interface (100 LOC).\nOnce the node provider is implemented, you can register it in the provider section of the cluster launcher config.\nprovider:\n  type: \"external\"\n  module: \"my.module.MyCustomNodeProvider\"\n\n\n\nYou can refer to AWSNodeProvider, KubeRayNodeProvider andLocalNodeProvider for more examples.\n- API References#\nThe following pages provide reference documentation for using Ray Clusters on virtual machines.\n\nReference documentation for Ray Clusters on VMs:\n\nCluster Launcher Commands\nLaunching a cluster (ray up)\nUpdating an existing cluster (ray up)\nRunning shell commands on the cluster (ray exec)\nRunning Ray scripts on the cluster (ray submit)\nAttaching to a running cluster (ray attach)\nSynchronizing files from the cluster (ray rsync-up/down)\nMonitoring cluster status (ray dashboard/status)\nCommon Workflow: Syncing git branches\n\n\nCluster YAML Configuration Options\nSyntax\nCustom types\nProperties and Definitions\nExamples\n\nRelevant passages: <extract relevant passages from the context here>\nUser query: Do Ray clusters support multi-tenancy\nAnswer: [/INST]\n"
        }
      ]
    },
    {
      "id": "GVzU",
      "code_hash": "35696f317d7d5e6088edd0dda40a7559",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "GHDg",
      "code_hash": "0246dc03beb55810712354f916e80e8c",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<marimo-ui-element object-id='GHDg-2' random-id='d3bb0908-251c-7e5c-728e-424f2d564f93'><marimo-form data-initial-value='null' data-label='null' data-element-id='&quot;GHDg-1&quot;' data-loading='false' data-bordered='true' data-submit-button-label='&quot;Submit&quot;' data-submit-button-disabled='false' data-clear-on-submit='false' data-show-clear-button='false' data-clear-button-label='&quot;Clear&quot;' data-should-validate='false'><marimo-ui-element object-id='GHDg-1' random-id='5938ac17-2a5d-8097-a600-c40b3e9b8913'><marimo-text-area data-initial-value='&quot;&quot;' data-label='null' data-placeholder='&quot;&quot;' data-disabled='false' data-debounce='true' data-full-width='false'></marimo-text-area></marimo-ui-element></marimo-form></marimo-ui-element>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "KhLV",
      "code_hash": "cd5d06b9dd6cfb0d1f0b7de9d7d045a0",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">RAG System Answer: Hi mom</span></span>"
          }
        }
      ],
      "console": []
    }
  ]
}